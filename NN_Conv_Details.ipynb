{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc701ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be3f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8008c",
   "metadata": {},
   "source": [
    "### Parsing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8d643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "files = os.listdir('sv_traces/')\n",
    "\n",
    "### reads an sv_trace file into 2 structures:\n",
    "### pcs: a list of 1001 16-bit pc values\n",
    "### mem: a list of 1001 65542-byte memory vectors\n",
    "def read_trace(sv_file):\n",
    "    with open(sv_file, 'rb') as f:\n",
    "        lines = f.read()\n",
    "        lines = np.frombuffer(lines, dtype=np.uint8)\n",
    "        lines = lines.reshape(1001,-1)\n",
    "        pcs = lines[:, 0:2]\n",
    "        mem = lines[:, :]\n",
    "        return mem, pcs\n",
    "    \n",
    "### reads trace data into a dataset of mem-to-pc mappings, where\n",
    "### mem_current: partial memory trace &\n",
    "### pcs_current: full pcs trace\n",
    "def read_dataset(file):\n",
    "    mem_trace = dict_traces[file][0]\n",
    "    mem_current = mem_trace[:]\n",
    "    pcs_trace = dict_traces[file][1]\n",
    "    pcs_current = pcs_trace[:]\n",
    "    return mem_current, pcs_current\n",
    "\n",
    "### dict_traces[file][0]: memory trace of <file>\n",
    "### dict_traces[file][1]: pc trace of <file>\n",
    "dict_traces = {}\n",
    "for file in files[0:20]:\n",
    "    dict_traces[file] = read_trace(os.path.join('sv_traces/', file))\n",
    "    \n",
    "### dict_dataset[file][0]: memory trace of <file>\n",
    "### dict_dataset[file][1]: pc trace of <file>\n",
    "dict_dataset = {}\n",
    "for trace in dict_traces:\n",
    "    dict_dataset[trace] = read_dataset(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c977f",
   "metadata": {},
   "source": [
    "### Defining Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c54eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data points =  10010\n",
      "# features =  600\n"
     ]
    }
   ],
   "source": [
    "features, labels = dict_dataset[list(dict_dataset.keys())[0]]\n",
    "for file in list(dict_dataset.keys())[1:10]:\n",
    "    features = np.append(features, dict_dataset[file][0], axis=0)\n",
    "    labels = np.append(labels, dict_dataset[file][1], axis=0)\n",
    "\n",
    "features_test, labels_test = dict_dataset[list(dict_dataset.keys())[10]]\n",
    "for file in list(dict_dataset.keys())[11:13]:\n",
    "    features_test = np.append(features_test, dict_dataset[file][0], axis=0)\n",
    "    labels_test = np.append(labels_test, dict_dataset[file][1], axis=0)\n",
    "    \n",
    "partial_mem_trace = features[: , 0:600]\n",
    "features = partial_mem_trace\n",
    "\n",
    "partial_mem_trace_test = features_test[: , 0:600]\n",
    "features_test = partial_mem_trace_test\n",
    "\n",
    "    \n",
    "print(\"# data points = \", features.shape[0])\n",
    "print(\"# features = \", features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe7d2e",
   "metadata": {},
   "source": [
    "### Generating Synthetic Dataset\n",
    "#### This will reflect how well the network learns indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1de66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate N vectors of 600 bytes\n",
    "# learn indexing into second byte\n",
    "def gen_data(N=1000, d=600, low=0, high=127, target_idx=1):\n",
    "    data = np.random.randint(low=low, high=high, size=(N,d))\n",
    "    return data, data[:, target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c062a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9  23  52 ...  88  16  37]\n",
      " [122  36 105 ...   2  67  81]\n",
      " [119  78  81 ...  10   1 119]]\n",
      "[23 36 78]\n",
      "[[89 80 99 ...  3 73 31]\n",
      " [58 73 13 ... 84  8  4]\n",
      " [11 60 42 ... 20 30 59]]\n",
      "[80 73 60]\n"
     ]
    }
   ],
   "source": [
    "data = gen_data()\n",
    "#print(data)\n",
    "features = data[0]\n",
    "print(features[0:3])\n",
    "labels = data[1]\n",
    "print(labels[0:3])\n",
    "test_data = gen_data(N=200)\n",
    "features_test = test_data[0]\n",
    "print(features_test[0:3])\n",
    "labels_test = test_data[1]\n",
    "print(labels_test[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befb36b",
   "metadata": {},
   "source": [
    "### Defining Conv. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3edc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(1, 8, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(8, 16, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(16, 32, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b2df9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18528])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.from_numpy(features[0]).unsqueeze(0).unsqueeze(0).unsqueeze(0).float()).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49f55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(1, 8, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(8, 16, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(16, 32, kernel_size=(1,8), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(18528, 1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe3cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error between real and predicted 2 16-bit values\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648990c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601b895",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abaaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, test_data, test_target, net_type=None):\n",
    "    net = net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_data_torch = torch.from_numpy(test_data).float().to(device)\n",
    "        test_target_torch = torch.from_numpy(test_target).float().to(device)\n",
    "\n",
    "        if net_type=='conv':\n",
    "            test_data_torch = test_data_torch.unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        test_pred = np.rint(net(test_data_torch).detach().numpy())\n",
    "        test_accuracy = (test_target_torch.detach().numpy() == test_pred).mean()\n",
    "\n",
    "        test_rmse = (np.sqrt((test_pred-test_target_torch.detach().numpy())**2).mean())\n",
    "\n",
    "    return test_accuracy, test_rmse\n",
    "\n",
    "def train_net(net, train_data, train_target, test_data, test_target, N_epochs=10, print_freq=100, net_type=None):\n",
    "    net = net.to(device)\n",
    "    train_data_torch = torch.from_numpy(train_data).float().to(device)\n",
    "    train_target_torch = torch.from_numpy(train_target).to(device)\n",
    "    \n",
    "    if net_type=='conv':\n",
    "        train_data_torch = train_data_torch.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    net = net.train()\n",
    "    for i in range(N_epochs):\n",
    "        pred = net(train_data_torch.float())\n",
    "        loss = criterion(pred, train_target_torch.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            train_accuracy, train_rmse = validate(net, train_data, train_target, net_type=net_type)\n",
    "            test_accuracy, test_rmse = validate(net, test_data, test_target, net_type=net_type)\n",
    "            net = net.train()\n",
    "            pred = np.rint(pred.detach().numpy())\n",
    "            print(\"pred: \", pred[i], \"target: \", train_target[i])\n",
    "            print(f'Epoch = {i} loss={loss} train_acc = {train_accuracy:.3f} test_acc = {test_accuracy:.3f} train_rmse = {train_rmse:.3f}  test_rmse = {test_rmse:.3f}')\n",
    "            \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f43c88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [65.] target:  23\n",
      "Epoch = 0 loss=1325.8577880859375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [63.] target:  25\n",
      "Epoch = 10 loss=1325.854736328125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [63.] target:  94\n",
      "Epoch = 20 loss=1325.8516845703125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [65.] target:  54\n",
      "Epoch = 30 loss=1325.8482666015625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [63.] target:  46\n",
      "Epoch = 40 loss=1325.84521484375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [64.] target:  102\n",
      "Epoch = 50 loss=1325.8419189453125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [65.] target:  83\n",
      "Epoch = 60 loss=1325.838623046875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [58.] target:  70\n",
      "Epoch = 70 loss=1325.8350830078125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [65.] target:  122\n",
      "Epoch = 80 loss=1325.83154296875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [63.] target:  114\n",
      "Epoch = 90 loss=1325.8282470703125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [63.] target:  9\n",
      "Epoch = 100 loss=1325.8245849609375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [64.] target:  3\n",
      "Epoch = 110 loss=1325.8209228515625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [65.] target:  120\n",
      "Epoch = 120 loss=1325.8172607421875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.041\n",
      "pred:  [62.] target:  4\n",
      "Epoch = 130 loss=1325.8134765625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [60.] target:  8\n",
      "Epoch = 140 loss=1325.8096923828125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [65.] target:  79\n",
      "Epoch = 150 loss=1325.8057861328125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [62.] target:  103\n",
      "Epoch = 160 loss=1325.802001953125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [62.] target:  74\n",
      "Epoch = 170 loss=1325.7979736328125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [63.] target:  49\n",
      "Epoch = 180 loss=1325.7939453125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [63.] target:  24\n",
      "Epoch = 190 loss=1325.7896728515625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [62.] target:  109\n",
      "Epoch = 200 loss=1325.7857666015625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [61.] target:  42\n",
      "Epoch = 210 loss=1325.7813720703125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [66.] target:  86\n",
      "Epoch = 220 loss=1325.77685546875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [67.] target:  20\n",
      "Epoch = 230 loss=1325.7725830078125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.043\n",
      "pred:  [63.] target:  52\n",
      "Epoch = 240 loss=1325.7679443359375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.043\n",
      "pred:  [64.] target:  55\n",
      "Epoch = 250 loss=1325.7633056640625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.043\n",
      "pred:  [68.] target:  20\n",
      "Epoch = 260 loss=1325.7586669921875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.043\n",
      "pred:  [62.] target:  65\n",
      "Epoch = 270 loss=1325.7537841796875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [64.] target:  25\n",
      "Epoch = 280 loss=1325.7489013671875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.042\n",
      "pred:  [62.] target:  59\n",
      "Epoch = 290 loss=1325.7437744140625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.044\n",
      "pred:  [65.] target:  12\n",
      "Epoch = 300 loss=1325.738525390625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.045\n",
      "pred:  [67.] target:  104\n",
      "Epoch = 310 loss=1325.7333984375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.045\n",
      "pred:  [62.] target:  82\n",
      "Epoch = 320 loss=1325.72802734375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.045\n",
      "pred:  [59.] target:  110\n",
      "Epoch = 330 loss=1325.72265625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [65.] target:  62\n",
      "Epoch = 340 loss=1325.7171630859375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [62.] target:  126\n",
      "Epoch = 350 loss=1325.7115478515625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [66.] target:  59\n",
      "Epoch = 360 loss=1325.7054443359375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [67.] target:  102\n",
      "Epoch = 370 loss=1325.6995849609375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [65.] target:  66\n",
      "Epoch = 380 loss=1325.6932373046875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.423  test_rmse = 29.046\n",
      "pred:  [66.] target:  9\n",
      "Epoch = 390 loss=1325.6866455078125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.046\n",
      "pred:  [66.] target:  6\n",
      "Epoch = 400 loss=1325.6796875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.048\n",
      "pred:  [66.] target:  9\n",
      "Epoch = 410 loss=1325.6727294921875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.048\n",
      "pred:  [61.] target:  61\n",
      "Epoch = 420 loss=1325.665283203125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.048\n",
      "pred:  [62.] target:  61\n",
      "Epoch = 430 loss=1325.6573486328125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.048\n",
      "pred:  [64.] target:  125\n",
      "Epoch = 440 loss=1325.649169921875 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.050\n",
      "pred:  [65.] target:  5\n",
      "Epoch = 450 loss=1325.640380859375 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.051\n",
      "pred:  [63.] target:  104\n",
      "Epoch = 460 loss=1325.63134765625 train_acc = 0.006 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.051\n",
      "pred:  [65.] target:  13\n",
      "Epoch = 470 loss=1325.6219482421875 train_acc = 0.006 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.050\n",
      "pred:  [65.] target:  31\n",
      "Epoch = 480 loss=1325.6119384765625 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.052\n",
      "pred:  [65.] target:  100\n",
      "Epoch = 490 loss=1325.6016845703125 train_acc = 0.007 test_acc = 0.005 train_rmse = 31.422  test_rmse = 29.055\n"
     ]
    }
   ],
   "source": [
    "net = train_net(net, features, labels, features_test, labels_test, N_epochs=500, print_freq=10, net_type='conv')\n",
    "\n",
    "torch.save(net, \"conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0abc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
