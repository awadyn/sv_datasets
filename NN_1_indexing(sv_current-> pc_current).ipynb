{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10977213",
   "metadata": {},
   "source": [
    "## Preparing SV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79a0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#np.set_printoptions(formatter={'int':hex})\n",
    "\n",
    "import os\n",
    "files = os.listdir('sv_traces/')\n",
    "\n",
    "### reads an sv_trace file into 2 structures:\n",
    "### pcs: a list of 1001 16-bit pc values\n",
    "### mem: a list of 1001 65542-byte memory vectors\n",
    "def read_trace(sv_file):\n",
    "    with open(sv_file, 'rb') as f:\n",
    "        lines = f.read()\n",
    "        lines = np.frombuffer(lines, dtype=np.uint8)\n",
    "        lines = lines.reshape(1001,-1)\n",
    "        pcs = lines[:, 0:2]\n",
    "        mem = lines[:, :]\n",
    "        #pcs = [np.uint16(i[1]<<8 | i[0]) for i in pcs]\n",
    "        return mem, pcs\n",
    "    \n",
    "### reads trace data into a dataset of mem-to-pc mappings, where\n",
    "### mem_current: partial memory trace &\n",
    "### pcs_current: full pcs trace\n",
    "def read_dataset(file):\n",
    "    mem_trace = dict_traces[file][0]\n",
    "    mem_current = mem_trace[:]\n",
    "    pcs_trace = dict_traces[file][1]\n",
    "    pcs_current = pcs_trace[:]\n",
    "    return mem_current, pcs_current\n",
    "\n",
    "### dict_traces[file][0]: memory trace of <file>\n",
    "### dict_traces[file][1]: pc trace of <file>\n",
    "dict_traces = {}\n",
    "for file in files[0:20]:\n",
    "    dict_traces[file] = read_trace(os.path.join('sv_traces/', file))\n",
    "    \n",
    "### dict_dataset[file][0]: memory trace of <file>\n",
    "### dict_dataset[file][1]: pc trace of <file>\n",
    "dict_dataset = {}\n",
    "for trace in dict_traces:\n",
    "    dict_dataset[trace] = read_dataset(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b038ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'167:149:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 126, ...,   2,   0,   0],\n",
       "         [  5,   2,  20, ...,   2,   0,   0],\n",
       "         [  7,   2,  20, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '121:187:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  2, 50, ...,  2,  0,  0],\n",
       "         [10,  2, 50, ...,  2,  0,  0],\n",
       "         [11,  2, 50, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '144:101:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  9,   2, 243, ...,   2,   0,   0],\n",
       "         [ 10,   2, 243, ...,   2,   0,   0],\n",
       "         [ 11,   2, 243, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '91:117:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  41, ...,   2,   0,   0],\n",
       "         [  5,   2, 159, ...,   2,   0,   0],\n",
       "         [  7,   2, 159, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '308:221:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 12,   2, 220, ...,   2,   0,   0],\n",
       "         [ 13,   2, 220, ...,   2,   0,   0],\n",
       "         [ 14,   2, 220, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '387:118:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [10,  2, 38, ...,  2,  0,  0],\n",
       "         [11,  2, 38, ...,  2,  0,  0],\n",
       "         [12,  2, 38, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '391:23:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 174, ...,   2,   0,   0],\n",
       "         [ 11,   2, 174, ...,   2,   0,   0],\n",
       "         [ 12,   2, 174, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '103:2:11.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 144, ...,   2,   0,   0],\n",
       "         [  8,   2, 144, ...,   2,   0,   0],\n",
       "         [  9,   2, 144, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '387:177:6.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [12,  2, 11, ...,  2,  0,  0],\n",
       "         [13,  2, 11, ...,  2,  0,  0],\n",
       "         [14,  2, 11, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '221:53:2.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  5,   2, 145, ...,   2,   0,   0],\n",
       "         [  7,   2, 145, ...,   2,   0,   0],\n",
       "         [  8,   2, 145, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [5, 2],\n",
       "         [7, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '347:229:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 136, ...,   2,   0,   0],\n",
       "         [  5,   2, 110, ...,   2,   0,   0],\n",
       "         [  8,   2, 110, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '245:222:0.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,   8, ...,   2,   0,   0],\n",
       "         [  5,   2, 231, ...,   2,   0,   0],\n",
       "         [  7,   2, 231, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '317:48:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 135, ...,   2,   0,   0],\n",
       "         [ 11,   2, 135, ...,   2,   0,   0],\n",
       "         [ 12,   2, 135, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '151:96:12.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [11,  2, 56, ...,  2,  0,  0],\n",
       "         [12,  2, 56, ...,  2,  0,  0],\n",
       "         [13,  2, 56, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '232:123:4.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 249, ...,   2,   0,   0],\n",
       "         [  8,   2, 249, ...,   2,   0,   0],\n",
       "         [  9,   2, 249, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '276:162:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 104, ...,   2,   0,   0],\n",
       "         [ 11,   2, 104, ...,   2,   0,   0],\n",
       "         [ 12,   2, 104, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '21:209:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 148, ...,   2,   0,   0],\n",
       "         [ 12,   2, 148, ...,   2,   0,   0],\n",
       "         [ 13,   2, 148, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '322:139:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 123, ...,   2,   0,   0],\n",
       "         [  5,   2,   7, ...,   2,   0,   0],\n",
       "         [  8,   2,   7, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '150:162:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 207, ...,   2,   0,   0],\n",
       "         [ 12,   2, 207, ...,   2,   0,   0],\n",
       "         [ 13,   2, 207, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '117:148:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  87, ...,   2,   0,   0],\n",
       "         [  5,   2, 236, ...,   2,   0,   0],\n",
       "         [  7,   2, 236, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8))}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86a39d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'167:149:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 126, ...,   2,   0,   0],\n",
       "         [  5,   2,  20, ...,   2,   0,   0],\n",
       "         [  7,   2,  20, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '121:187:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  2, 50, ...,  2,  0,  0],\n",
       "         [10,  2, 50, ...,  2,  0,  0],\n",
       "         [11,  2, 50, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '144:101:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  9,   2, 243, ...,   2,   0,   0],\n",
       "         [ 10,   2, 243, ...,   2,   0,   0],\n",
       "         [ 11,   2, 243, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '91:117:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  41, ...,   2,   0,   0],\n",
       "         [  5,   2, 159, ...,   2,   0,   0],\n",
       "         [  7,   2, 159, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '308:221:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 12,   2, 220, ...,   2,   0,   0],\n",
       "         [ 13,   2, 220, ...,   2,   0,   0],\n",
       "         [ 14,   2, 220, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '387:118:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [10,  2, 38, ...,  2,  0,  0],\n",
       "         [11,  2, 38, ...,  2,  0,  0],\n",
       "         [12,  2, 38, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '391:23:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 174, ...,   2,   0,   0],\n",
       "         [ 11,   2, 174, ...,   2,   0,   0],\n",
       "         [ 12,   2, 174, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '103:2:11.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 144, ...,   2,   0,   0],\n",
       "         [  8,   2, 144, ...,   2,   0,   0],\n",
       "         [  9,   2, 144, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '387:177:6.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [12,  2, 11, ...,  2,  0,  0],\n",
       "         [13,  2, 11, ...,  2,  0,  0],\n",
       "         [14,  2, 11, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '221:53:2.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  5,   2, 145, ...,   2,   0,   0],\n",
       "         [  7,   2, 145, ...,   2,   0,   0],\n",
       "         [  8,   2, 145, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [5, 2],\n",
       "         [7, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '347:229:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 136, ...,   2,   0,   0],\n",
       "         [  5,   2, 110, ...,   2,   0,   0],\n",
       "         [  8,   2, 110, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '245:222:0.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,   8, ...,   2,   0,   0],\n",
       "         [  5,   2, 231, ...,   2,   0,   0],\n",
       "         [  7,   2, 231, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '317:48:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 135, ...,   2,   0,   0],\n",
       "         [ 11,   2, 135, ...,   2,   0,   0],\n",
       "         [ 12,   2, 135, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '151:96:12.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [11,  2, 56, ...,  2,  0,  0],\n",
       "         [12,  2, 56, ...,  2,  0,  0],\n",
       "         [13,  2, 56, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '232:123:4.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 249, ...,   2,   0,   0],\n",
       "         [  8,   2, 249, ...,   2,   0,   0],\n",
       "         [  9,   2, 249, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '276:162:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 104, ...,   2,   0,   0],\n",
       "         [ 11,   2, 104, ...,   2,   0,   0],\n",
       "         [ 12,   2, 104, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '21:209:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 148, ...,   2,   0,   0],\n",
       "         [ 12,   2, 148, ...,   2,   0,   0],\n",
       "         [ 13,   2, 148, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '322:139:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 123, ...,   2,   0,   0],\n",
       "         [  5,   2,   7, ...,   2,   0,   0],\n",
       "         [  8,   2,   7, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '150:162:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 207, ...,   2,   0,   0],\n",
       "         [ 12,   2, 207, ...,   2,   0,   0],\n",
       "         [ 13,   2, 207, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '117:148:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  87, ...,   2,   0,   0],\n",
       "         [  5,   2, 236, ...,   2,   0,   0],\n",
       "         [  7,   2, 236, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8))}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997a46d",
   "metadata": {},
   "source": [
    "## Defining Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4145c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdccbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_label(l, width=16):\n",
    "    val = bin(l)[2:]\n",
    "    N = len(val)\n",
    "    return [0.] * (width-N) + [float(i) for i in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a45607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_label(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256108b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = dict_dataset[list(dict_dataset.keys())[0]]\n",
    "for file in list(dict_dataset.keys())[1:10]:\n",
    "    features = np.append(features, dict_dataset[file][0], axis=0)\n",
    "    labels = np.append(labels, dict_dataset[file][1], axis=0)\n",
    "\n",
    "features_test, labels_test = dict_dataset[list(dict_dataset.keys())[10]]\n",
    "for file in list(dict_dataset.keys())[11:13]:\n",
    "    features_test = np.append(features_test, dict_dataset[file][0], axis=0)\n",
    "    labels_test = np.append(labels_test, dict_dataset[file][1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8063235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, labels = dict_dataset[list(dict_dataset.keys())[0]]\n",
    "#features_test, labels_test = dict_dataset[list(dict_dataset.keys())[1]]\n",
    "#features = features - features.mean(axis=0)\n",
    "# temp\n",
    "features_temp = features#[9:15, ]\n",
    "labels_temp = labels#[9:15]\n",
    "# end temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6178cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 1  2]\n",
      " [ 3  2]\n",
      " [ 5  2]\n",
      " [ 8  2]\n",
      " [ 9  2]\n",
      " [10  2]\n",
      " [11  2]\n",
      " [12  2]\n",
      " [13  2]\n",
      " [14  2]\n",
      " [15  2]\n",
      " [16  2]\n",
      " [17  2]\n",
      " [ 3  2]\n",
      " [ 5  2]]\n",
      "[[ 0  2]\n",
      " [ 1  2]\n",
      " [ 3  2]\n",
      " [ 5  2]\n",
      " [ 7  2]\n",
      " [ 8  2]\n",
      " [ 9  2]\n",
      " [10  2]\n",
      " [11  2]\n",
      " [12  2]\n",
      " [13  2]\n",
      " [14  2]\n",
      " [15  2]\n",
      " [16  2]\n",
      " [ 3  2]\n",
      " [ 5  2]]\n"
     ]
    }
   ],
   "source": [
    "print(labels_test[0:16])\n",
    "print(labels_temp[0:16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206ca5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29da65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10010\n",
      "10010\n",
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "partial_mem_trace = features_temp[: , 0:600]\n",
    "#partial_mem_trace = features_temp[: , 0:1024]\n",
    "features_temp = partial_mem_trace # all rows are identical here\n",
    "\n",
    "partial_mem_trace_test = features_test[: , 0:600]\n",
    "#partial_mem_trace_test = features_test[: , 0:1024]\n",
    "features_test = partial_mem_trace_test # all rows are identical here\n",
    "\n",
    "    \n",
    "print(partial_mem_trace.shape[0])\n",
    "print(features_temp.shape[0])\n",
    "print(partial_mem_trace.shape[1])\n",
    "print(features_temp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08cf5f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        24, 169,   0, 105, 149, 133, 167, 234, 234, 234, 234, 234, 234,\n",
       "       234, 234, 234,  76,   3,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5bea2",
   "metadata": {},
   "source": [
    "### Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e94e92e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(features_temp.shape[1], 2**8),\n",
    "    nn.ReLU(), #rectified linear unit\n",
    "    nn.Linear(2**8, 2**12),\n",
    "    nn.ReLU(),\n",
    "    #nn.Linear(2**8, 2**4),\n",
    "    #nn.ReLU(),\n",
    "    nn.Linear(2**12, 2),\n",
    "    #nn.Sigmoid()\n",
    ")\n",
    "\n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(n_epochs, net, features, labels, criterion, optimizer, freq=1, debug=False):\n",
    "    for i in range(n_epochs): #number of passes over full dataset\n",
    "        #step 1: get features and use net to make predictions\n",
    "        preds = net(torch.from_numpy(features).float())\n",
    "        \n",
    "        #step 2: compute loss/error\n",
    "        labels_torch = torch.tensor(torch.from_numpy(np.array(labels)).float())\n",
    "        if debug: print('\\n------')\n",
    "        if debug: print(preds)\n",
    "        #loss = np.sqrt(((np.rint(preds.detach().numpy()) - labels_torch.detach().numpy())**2).mean())\n",
    "        loss = criterion(preds, labels_torch)\n",
    "        if i % freq == 0:\n",
    "            print('epoch:', i, 'loss:', loss)\n",
    "\n",
    "        #step 3: backprop to update weights\n",
    "        # compute gradients/derivatives - backprop\n",
    "        # use gradients to update weights - gradient descent - w = w - 0.1 * deriv. loss w.r.t. w\n",
    "\n",
    "        optimizer.zero_grad() #set previous buffers to zero\n",
    "        loss.backward() #backprop\n",
    "        optimizer.step() #update weights        \n",
    "        \n",
    "    return net\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-6)\n",
    "print(features_temp)\n",
    "#net = train(1000, net, features_temp, labels_temp, criterion, optimizer, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91831b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5af8506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109417/2880589121.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_torch = torch.tensor(torch.from_numpy(np.array(labels)).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(95.9756, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1 loss: tensor(89.6505, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2 loss: tensor(83.5865, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3 loss: tensor(77.7861, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4 loss: tensor(72.2498, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5 loss: tensor(66.9761, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6 loss: tensor(61.9637, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7 loss: tensor(57.2113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8 loss: tensor(52.7171, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9 loss: tensor(48.4797, grad_fn=<MseLossBackward0>)\n",
      "epoch: 10 loss: tensor(44.4979, grad_fn=<MseLossBackward0>)\n",
      "epoch: 11 loss: tensor(40.7705, grad_fn=<MseLossBackward0>)\n",
      "epoch: 12 loss: tensor(37.2952, grad_fn=<MseLossBackward0>)\n",
      "epoch: 13 loss: tensor(34.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch: 14 loss: tensor(31.0885, grad_fn=<MseLossBackward0>)\n",
      "epoch: 15 loss: tensor(28.3491, grad_fn=<MseLossBackward0>)\n",
      "epoch: 16 loss: tensor(25.8450, grad_fn=<MseLossBackward0>)\n",
      "epoch: 17 loss: tensor(23.5697, grad_fn=<MseLossBackward0>)\n",
      "epoch: 18 loss: tensor(21.5154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 19 loss: tensor(19.6732, grad_fn=<MseLossBackward0>)\n",
      "epoch: 20 loss: tensor(18.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch: 21 loss: tensor(16.5857, grad_fn=<MseLossBackward0>)\n",
      "epoch: 22 loss: tensor(15.3189, grad_fn=<MseLossBackward0>)\n",
      "epoch: 23 loss: tensor(14.2217, grad_fn=<MseLossBackward0>)\n",
      "epoch: 24 loss: tensor(13.2819, grad_fn=<MseLossBackward0>)\n",
      "epoch: 25 loss: tensor(12.4875, grad_fn=<MseLossBackward0>)\n",
      "epoch: 26 loss: tensor(11.8261, grad_fn=<MseLossBackward0>)\n",
      "epoch: 27 loss: tensor(11.2849, grad_fn=<MseLossBackward0>)\n",
      "epoch: 28 loss: tensor(10.8513, grad_fn=<MseLossBackward0>)\n",
      "epoch: 29 loss: tensor(10.5128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 30 loss: tensor(10.2569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 31 loss: tensor(10.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch: 32 loss: tensor(9.9453, grad_fn=<MseLossBackward0>)\n",
      "epoch: 33 loss: tensor(9.8672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 34 loss: tensor(9.8272, grad_fn=<MseLossBackward0>)\n",
      "epoch: 35 loss: tensor(9.8160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 36 loss: tensor(9.8255, grad_fn=<MseLossBackward0>)\n",
      "epoch: 37 loss: tensor(9.8485, grad_fn=<MseLossBackward0>)\n",
      "epoch: 38 loss: tensor(9.8788, grad_fn=<MseLossBackward0>)\n",
      "epoch: 39 loss: tensor(9.9114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 40 loss: tensor(9.9421, grad_fn=<MseLossBackward0>)\n",
      "epoch: 41 loss: tensor(9.9677, grad_fn=<MseLossBackward0>)\n",
      "epoch: 42 loss: tensor(9.9857, grad_fn=<MseLossBackward0>)\n",
      "epoch: 43 loss: tensor(9.9946, grad_fn=<MseLossBackward0>)\n",
      "epoch: 44 loss: tensor(9.9934, grad_fn=<MseLossBackward0>)\n",
      "epoch: 45 loss: tensor(9.9819, grad_fn=<MseLossBackward0>)\n",
      "epoch: 46 loss: tensor(9.9604, grad_fn=<MseLossBackward0>)\n",
      "epoch: 47 loss: tensor(9.9295, grad_fn=<MseLossBackward0>)\n",
      "epoch: 48 loss: tensor(9.8902, grad_fn=<MseLossBackward0>)\n",
      "epoch: 49 loss: tensor(9.8437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 50 loss: tensor(9.7915, grad_fn=<MseLossBackward0>)\n",
      "epoch: 51 loss: tensor(9.7351, grad_fn=<MseLossBackward0>)\n",
      "epoch: 52 loss: tensor(9.6758, grad_fn=<MseLossBackward0>)\n",
      "epoch: 53 loss: tensor(9.6150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 54 loss: tensor(9.5540, grad_fn=<MseLossBackward0>)\n",
      "epoch: 55 loss: tensor(9.4941, grad_fn=<MseLossBackward0>)\n",
      "epoch: 56 loss: tensor(9.4361, grad_fn=<MseLossBackward0>)\n",
      "epoch: 57 loss: tensor(9.3808, grad_fn=<MseLossBackward0>)\n",
      "epoch: 58 loss: tensor(9.3291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 59 loss: tensor(9.2812, grad_fn=<MseLossBackward0>)\n",
      "epoch: 60 loss: tensor(9.2376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 61 loss: tensor(9.1984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 62 loss: tensor(9.1635, grad_fn=<MseLossBackward0>)\n",
      "epoch: 63 loss: tensor(9.1330, grad_fn=<MseLossBackward0>)\n",
      "epoch: 64 loss: tensor(9.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 65 loss: tensor(9.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch: 66 loss: tensor(9.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch: 67 loss: tensor(9.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch: 68 loss: tensor(9.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch: 69 loss: tensor(9.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch: 70 loss: tensor(9.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 71 loss: tensor(9.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 72 loss: tensor(8.9991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 73 loss: tensor(8.9930, grad_fn=<MseLossBackward0>)\n",
      "epoch: 74 loss: tensor(8.9874, grad_fn=<MseLossBackward0>)\n",
      "epoch: 75 loss: tensor(8.9822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 76 loss: tensor(8.9771, grad_fn=<MseLossBackward0>)\n",
      "epoch: 77 loss: tensor(8.9720, grad_fn=<MseLossBackward0>)\n",
      "epoch: 78 loss: tensor(8.9668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 79 loss: tensor(8.9615, grad_fn=<MseLossBackward0>)\n",
      "epoch: 80 loss: tensor(8.9560, grad_fn=<MseLossBackward0>)\n",
      "epoch: 81 loss: tensor(8.9503, grad_fn=<MseLossBackward0>)\n",
      "epoch: 82 loss: tensor(8.9444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 83 loss: tensor(8.9384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 84 loss: tensor(8.9323, grad_fn=<MseLossBackward0>)\n",
      "epoch: 85 loss: tensor(8.9262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 86 loss: tensor(8.9200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 87 loss: tensor(8.9140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 88 loss: tensor(8.9080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 89 loss: tensor(8.9022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 90 loss: tensor(8.8965, grad_fn=<MseLossBackward0>)\n",
      "epoch: 91 loss: tensor(8.8911, grad_fn=<MseLossBackward0>)\n",
      "epoch: 92 loss: tensor(8.8860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 93 loss: tensor(8.8810, grad_fn=<MseLossBackward0>)\n",
      "epoch: 94 loss: tensor(8.8764, grad_fn=<MseLossBackward0>)\n",
      "epoch: 95 loss: tensor(8.8719, grad_fn=<MseLossBackward0>)\n",
      "epoch: 96 loss: tensor(8.8677, grad_fn=<MseLossBackward0>)\n",
      "epoch: 97 loss: tensor(8.8637, grad_fn=<MseLossBackward0>)\n",
      "epoch: 98 loss: tensor(8.8600, grad_fn=<MseLossBackward0>)\n",
      "epoch: 99 loss: tensor(8.8564, grad_fn=<MseLossBackward0>)\n",
      "epoch: 100 loss: tensor(8.8530, grad_fn=<MseLossBackward0>)\n",
      "epoch: 101 loss: tensor(8.8497, grad_fn=<MseLossBackward0>)\n",
      "epoch: 102 loss: tensor(8.8465, grad_fn=<MseLossBackward0>)\n",
      "epoch: 103 loss: tensor(8.8435, grad_fn=<MseLossBackward0>)\n",
      "epoch: 104 loss: tensor(8.8405, grad_fn=<MseLossBackward0>)\n",
      "epoch: 105 loss: tensor(8.8376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 106 loss: tensor(8.8348, grad_fn=<MseLossBackward0>)\n",
      "epoch: 107 loss: tensor(8.8319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 108 loss: tensor(8.8291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 109 loss: tensor(8.8263, grad_fn=<MseLossBackward0>)\n",
      "epoch: 110 loss: tensor(8.8236, grad_fn=<MseLossBackward0>)\n",
      "epoch: 111 loss: tensor(8.8208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 112 loss: tensor(8.8181, grad_fn=<MseLossBackward0>)\n",
      "epoch: 113 loss: tensor(8.8154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 114 loss: tensor(8.8128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 115 loss: tensor(8.8102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 116 loss: tensor(8.8076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 117 loss: tensor(8.8050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 118 loss: tensor(8.8025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 119 loss: tensor(8.8000, grad_fn=<MseLossBackward0>)\n",
      "epoch: 120 loss: tensor(8.7975, grad_fn=<MseLossBackward0>)\n",
      "epoch: 121 loss: tensor(8.7951, grad_fn=<MseLossBackward0>)\n",
      "epoch: 122 loss: tensor(8.7928, grad_fn=<MseLossBackward0>)\n",
      "epoch: 123 loss: tensor(8.7905, grad_fn=<MseLossBackward0>)\n",
      "epoch: 124 loss: tensor(8.7882, grad_fn=<MseLossBackward0>)\n",
      "epoch: 125 loss: tensor(8.7860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 126 loss: tensor(8.7838, grad_fn=<MseLossBackward0>)\n",
      "epoch: 127 loss: tensor(8.7816, grad_fn=<MseLossBackward0>)\n",
      "epoch: 128 loss: tensor(8.7795, grad_fn=<MseLossBackward0>)\n",
      "epoch: 129 loss: tensor(8.7774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 130 loss: tensor(8.7754, grad_fn=<MseLossBackward0>)\n",
      "epoch: 131 loss: tensor(8.7733, grad_fn=<MseLossBackward0>)\n",
      "epoch: 132 loss: tensor(8.7713, grad_fn=<MseLossBackward0>)\n",
      "epoch: 133 loss: tensor(8.7693, grad_fn=<MseLossBackward0>)\n",
      "epoch: 134 loss: tensor(8.7673, grad_fn=<MseLossBackward0>)\n",
      "epoch: 135 loss: tensor(8.7653, grad_fn=<MseLossBackward0>)\n",
      "epoch: 136 loss: tensor(8.7633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 137 loss: tensor(8.7614, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138 loss: tensor(8.7595, grad_fn=<MseLossBackward0>)\n",
      "epoch: 139 loss: tensor(8.7577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 140 loss: tensor(8.7558, grad_fn=<MseLossBackward0>)\n",
      "epoch: 141 loss: tensor(8.7539, grad_fn=<MseLossBackward0>)\n",
      "epoch: 142 loss: tensor(8.7521, grad_fn=<MseLossBackward0>)\n",
      "epoch: 143 loss: tensor(8.7502, grad_fn=<MseLossBackward0>)\n",
      "epoch: 144 loss: tensor(8.7484, grad_fn=<MseLossBackward0>)\n",
      "epoch: 145 loss: tensor(8.7466, grad_fn=<MseLossBackward0>)\n",
      "epoch: 146 loss: tensor(8.7448, grad_fn=<MseLossBackward0>)\n",
      "epoch: 147 loss: tensor(8.7430, grad_fn=<MseLossBackward0>)\n",
      "epoch: 148 loss: tensor(8.7412, grad_fn=<MseLossBackward0>)\n",
      "epoch: 149 loss: tensor(8.7394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 150 loss: tensor(8.7377, grad_fn=<MseLossBackward0>)\n",
      "epoch: 151 loss: tensor(8.7359, grad_fn=<MseLossBackward0>)\n",
      "epoch: 152 loss: tensor(8.7342, grad_fn=<MseLossBackward0>)\n",
      "epoch: 153 loss: tensor(8.7325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 154 loss: tensor(8.7308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 155 loss: tensor(8.7292, grad_fn=<MseLossBackward0>)\n",
      "epoch: 156 loss: tensor(8.7275, grad_fn=<MseLossBackward0>)\n",
      "epoch: 157 loss: tensor(8.7258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 158 loss: tensor(8.7242, grad_fn=<MseLossBackward0>)\n",
      "epoch: 159 loss: tensor(8.7225, grad_fn=<MseLossBackward0>)\n",
      "epoch: 160 loss: tensor(8.7208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 161 loss: tensor(8.7192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 162 loss: tensor(8.7175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 163 loss: tensor(8.7159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 164 loss: tensor(8.7142, grad_fn=<MseLossBackward0>)\n",
      "epoch: 165 loss: tensor(8.7126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 166 loss: tensor(8.7110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 167 loss: tensor(8.7094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 168 loss: tensor(8.7078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 169 loss: tensor(8.7063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 170 loss: tensor(8.7047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 171 loss: tensor(8.7031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 172 loss: tensor(8.7016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 173 loss: tensor(8.7000, grad_fn=<MseLossBackward0>)\n",
      "epoch: 174 loss: tensor(8.6985, grad_fn=<MseLossBackward0>)\n",
      "epoch: 175 loss: tensor(8.6969, grad_fn=<MseLossBackward0>)\n",
      "epoch: 176 loss: tensor(8.6954, grad_fn=<MseLossBackward0>)\n",
      "epoch: 177 loss: tensor(8.6939, grad_fn=<MseLossBackward0>)\n",
      "epoch: 178 loss: tensor(8.6923, grad_fn=<MseLossBackward0>)\n",
      "epoch: 179 loss: tensor(8.6908, grad_fn=<MseLossBackward0>)\n",
      "epoch: 180 loss: tensor(8.6893, grad_fn=<MseLossBackward0>)\n",
      "epoch: 181 loss: tensor(8.6877, grad_fn=<MseLossBackward0>)\n",
      "epoch: 182 loss: tensor(8.6862, grad_fn=<MseLossBackward0>)\n",
      "epoch: 183 loss: tensor(8.6847, grad_fn=<MseLossBackward0>)\n",
      "epoch: 184 loss: tensor(8.6831, grad_fn=<MseLossBackward0>)\n",
      "epoch: 185 loss: tensor(8.6816, grad_fn=<MseLossBackward0>)\n",
      "epoch: 186 loss: tensor(8.6801, grad_fn=<MseLossBackward0>)\n",
      "epoch: 187 loss: tensor(8.6786, grad_fn=<MseLossBackward0>)\n",
      "epoch: 188 loss: tensor(8.6770, grad_fn=<MseLossBackward0>)\n",
      "epoch: 189 loss: tensor(8.6755, grad_fn=<MseLossBackward0>)\n",
      "epoch: 190 loss: tensor(8.6740, grad_fn=<MseLossBackward0>)\n",
      "epoch: 191 loss: tensor(8.6725, grad_fn=<MseLossBackward0>)\n",
      "epoch: 192 loss: tensor(8.6710, grad_fn=<MseLossBackward0>)\n",
      "epoch: 193 loss: tensor(8.6695, grad_fn=<MseLossBackward0>)\n",
      "epoch: 194 loss: tensor(8.6680, grad_fn=<MseLossBackward0>)\n",
      "epoch: 195 loss: tensor(8.6666, grad_fn=<MseLossBackward0>)\n",
      "epoch: 196 loss: tensor(8.6651, grad_fn=<MseLossBackward0>)\n",
      "epoch: 197 loss: tensor(8.6636, grad_fn=<MseLossBackward0>)\n",
      "epoch: 198 loss: tensor(8.6621, grad_fn=<MseLossBackward0>)\n",
      "epoch: 199 loss: tensor(8.6605, grad_fn=<MseLossBackward0>)\n",
      "epoch: 200 loss: tensor(8.6590, grad_fn=<MseLossBackward0>)\n",
      "epoch: 201 loss: tensor(8.6575, grad_fn=<MseLossBackward0>)\n",
      "epoch: 202 loss: tensor(8.6560, grad_fn=<MseLossBackward0>)\n",
      "epoch: 203 loss: tensor(8.6545, grad_fn=<MseLossBackward0>)\n",
      "epoch: 204 loss: tensor(8.6531, grad_fn=<MseLossBackward0>)\n",
      "epoch: 205 loss: tensor(8.6516, grad_fn=<MseLossBackward0>)\n",
      "epoch: 206 loss: tensor(8.6501, grad_fn=<MseLossBackward0>)\n",
      "epoch: 207 loss: tensor(8.6487, grad_fn=<MseLossBackward0>)\n",
      "epoch: 208 loss: tensor(8.6472, grad_fn=<MseLossBackward0>)\n",
      "epoch: 209 loss: tensor(8.6457, grad_fn=<MseLossBackward0>)\n",
      "epoch: 210 loss: tensor(8.6443, grad_fn=<MseLossBackward0>)\n",
      "epoch: 211 loss: tensor(8.6428, grad_fn=<MseLossBackward0>)\n",
      "epoch: 212 loss: tensor(8.6413, grad_fn=<MseLossBackward0>)\n",
      "epoch: 213 loss: tensor(8.6399, grad_fn=<MseLossBackward0>)\n",
      "epoch: 214 loss: tensor(8.6384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 215 loss: tensor(8.6369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 216 loss: tensor(8.6354, grad_fn=<MseLossBackward0>)\n",
      "epoch: 217 loss: tensor(8.6340, grad_fn=<MseLossBackward0>)\n",
      "epoch: 218 loss: tensor(8.6325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 219 loss: tensor(8.6311, grad_fn=<MseLossBackward0>)\n",
      "epoch: 220 loss: tensor(8.6297, grad_fn=<MseLossBackward0>)\n",
      "epoch: 221 loss: tensor(8.6283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 222 loss: tensor(8.6269, grad_fn=<MseLossBackward0>)\n",
      "epoch: 223 loss: tensor(8.6254, grad_fn=<MseLossBackward0>)\n",
      "epoch: 224 loss: tensor(8.6240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 225 loss: tensor(8.6226, grad_fn=<MseLossBackward0>)\n",
      "epoch: 226 loss: tensor(8.6212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 227 loss: tensor(8.6198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 228 loss: tensor(8.6184, grad_fn=<MseLossBackward0>)\n",
      "epoch: 229 loss: tensor(8.6169, grad_fn=<MseLossBackward0>)\n",
      "epoch: 230 loss: tensor(8.6155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 231 loss: tensor(8.6141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 232 loss: tensor(8.6127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 233 loss: tensor(8.6114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 234 loss: tensor(8.6100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 235 loss: tensor(8.6086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 236 loss: tensor(8.6072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 237 loss: tensor(8.6058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 238 loss: tensor(8.6044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 239 loss: tensor(8.6030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 240 loss: tensor(8.6016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 241 loss: tensor(8.6002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 242 loss: tensor(8.5988, grad_fn=<MseLossBackward0>)\n",
      "epoch: 243 loss: tensor(8.5974, grad_fn=<MseLossBackward0>)\n",
      "epoch: 244 loss: tensor(8.5960, grad_fn=<MseLossBackward0>)\n",
      "epoch: 245 loss: tensor(8.5945, grad_fn=<MseLossBackward0>)\n",
      "epoch: 246 loss: tensor(8.5931, grad_fn=<MseLossBackward0>)\n",
      "epoch: 247 loss: tensor(8.5917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 248 loss: tensor(8.5902, grad_fn=<MseLossBackward0>)\n",
      "epoch: 249 loss: tensor(8.5888, grad_fn=<MseLossBackward0>)\n",
      "epoch: 250 loss: tensor(8.5873, grad_fn=<MseLossBackward0>)\n",
      "epoch: 251 loss: tensor(8.5858, grad_fn=<MseLossBackward0>)\n",
      "epoch: 252 loss: tensor(8.5844, grad_fn=<MseLossBackward0>)\n",
      "epoch: 253 loss: tensor(8.5829, grad_fn=<MseLossBackward0>)\n",
      "epoch: 254 loss: tensor(8.5814, grad_fn=<MseLossBackward0>)\n",
      "epoch: 255 loss: tensor(8.5799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 256 loss: tensor(8.5784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 257 loss: tensor(8.5768, grad_fn=<MseLossBackward0>)\n",
      "epoch: 258 loss: tensor(8.5751, grad_fn=<MseLossBackward0>)\n",
      "epoch: 259 loss: tensor(8.5733, grad_fn=<MseLossBackward0>)\n",
      "epoch: 260 loss: tensor(8.5715, grad_fn=<MseLossBackward0>)\n",
      "epoch: 261 loss: tensor(8.5697, grad_fn=<MseLossBackward0>)\n",
      "epoch: 262 loss: tensor(8.5679, grad_fn=<MseLossBackward0>)\n",
      "epoch: 263 loss: tensor(8.5662, grad_fn=<MseLossBackward0>)\n",
      "epoch: 264 loss: tensor(8.5645, grad_fn=<MseLossBackward0>)\n",
      "epoch: 265 loss: tensor(8.5628, grad_fn=<MseLossBackward0>)\n",
      "epoch: 266 loss: tensor(8.5612, grad_fn=<MseLossBackward0>)\n",
      "epoch: 267 loss: tensor(8.5596, grad_fn=<MseLossBackward0>)\n",
      "epoch: 268 loss: tensor(8.5580, grad_fn=<MseLossBackward0>)\n",
      "epoch: 269 loss: tensor(8.5564, grad_fn=<MseLossBackward0>)\n",
      "epoch: 270 loss: tensor(8.5548, grad_fn=<MseLossBackward0>)\n",
      "epoch: 271 loss: tensor(8.5533, grad_fn=<MseLossBackward0>)\n",
      "epoch: 272 loss: tensor(8.5517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 273 loss: tensor(8.5502, grad_fn=<MseLossBackward0>)\n",
      "epoch: 274 loss: tensor(8.5486, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 275 loss: tensor(8.5471, grad_fn=<MseLossBackward0>)\n",
      "epoch: 276 loss: tensor(8.5456, grad_fn=<MseLossBackward0>)\n",
      "epoch: 277 loss: tensor(8.5440, grad_fn=<MseLossBackward0>)\n",
      "epoch: 278 loss: tensor(8.5425, grad_fn=<MseLossBackward0>)\n",
      "epoch: 279 loss: tensor(8.5409, grad_fn=<MseLossBackward0>)\n",
      "epoch: 280 loss: tensor(8.5394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 281 loss: tensor(8.5378, grad_fn=<MseLossBackward0>)\n",
      "epoch: 282 loss: tensor(8.5362, grad_fn=<MseLossBackward0>)\n",
      "epoch: 283 loss: tensor(8.5347, grad_fn=<MseLossBackward0>)\n",
      "epoch: 284 loss: tensor(8.5331, grad_fn=<MseLossBackward0>)\n",
      "epoch: 285 loss: tensor(8.5316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 286 loss: tensor(8.5300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 287 loss: tensor(8.5284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 288 loss: tensor(8.5269, grad_fn=<MseLossBackward0>)\n",
      "epoch: 289 loss: tensor(8.5253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 290 loss: tensor(8.5238, grad_fn=<MseLossBackward0>)\n",
      "epoch: 291 loss: tensor(8.5222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 292 loss: tensor(8.5206, grad_fn=<MseLossBackward0>)\n",
      "epoch: 293 loss: tensor(8.5190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 294 loss: tensor(8.5174, grad_fn=<MseLossBackward0>)\n",
      "epoch: 295 loss: tensor(8.5157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 296 loss: tensor(8.5139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 297 loss: tensor(8.5120, grad_fn=<MseLossBackward0>)\n",
      "epoch: 298 loss: tensor(8.5100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 299 loss: tensor(8.5081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 300 loss: tensor(8.5061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 301 loss: tensor(8.5043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 302 loss: tensor(8.5025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 303 loss: tensor(8.5008, grad_fn=<MseLossBackward0>)\n",
      "epoch: 304 loss: tensor(8.4991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 305 loss: tensor(8.4975, grad_fn=<MseLossBackward0>)\n",
      "epoch: 306 loss: tensor(8.4958, grad_fn=<MseLossBackward0>)\n",
      "epoch: 307 loss: tensor(8.4942, grad_fn=<MseLossBackward0>)\n",
      "epoch: 308 loss: tensor(8.4926, grad_fn=<MseLossBackward0>)\n",
      "epoch: 309 loss: tensor(8.4910, grad_fn=<MseLossBackward0>)\n",
      "epoch: 310 loss: tensor(8.4895, grad_fn=<MseLossBackward0>)\n",
      "epoch: 311 loss: tensor(8.4879, grad_fn=<MseLossBackward0>)\n",
      "epoch: 312 loss: tensor(8.4864, grad_fn=<MseLossBackward0>)\n",
      "epoch: 313 loss: tensor(8.4849, grad_fn=<MseLossBackward0>)\n",
      "epoch: 314 loss: tensor(8.4834, grad_fn=<MseLossBackward0>)\n",
      "epoch: 315 loss: tensor(8.4819, grad_fn=<MseLossBackward0>)\n",
      "epoch: 316 loss: tensor(8.4805, grad_fn=<MseLossBackward0>)\n",
      "epoch: 317 loss: tensor(8.4790, grad_fn=<MseLossBackward0>)\n",
      "epoch: 318 loss: tensor(8.4775, grad_fn=<MseLossBackward0>)\n",
      "epoch: 319 loss: tensor(8.4760, grad_fn=<MseLossBackward0>)\n",
      "epoch: 320 loss: tensor(8.4745, grad_fn=<MseLossBackward0>)\n",
      "epoch: 321 loss: tensor(8.4730, grad_fn=<MseLossBackward0>)\n",
      "epoch: 322 loss: tensor(8.4715, grad_fn=<MseLossBackward0>)\n",
      "epoch: 323 loss: tensor(8.4700, grad_fn=<MseLossBackward0>)\n",
      "epoch: 324 loss: tensor(8.4685, grad_fn=<MseLossBackward0>)\n",
      "epoch: 325 loss: tensor(8.4669, grad_fn=<MseLossBackward0>)\n",
      "epoch: 326 loss: tensor(8.4654, grad_fn=<MseLossBackward0>)\n",
      "epoch: 327 loss: tensor(8.4638, grad_fn=<MseLossBackward0>)\n",
      "epoch: 328 loss: tensor(8.4622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 329 loss: tensor(8.4606, grad_fn=<MseLossBackward0>)\n",
      "epoch: 330 loss: tensor(8.4590, grad_fn=<MseLossBackward0>)\n",
      "epoch: 331 loss: tensor(8.4574, grad_fn=<MseLossBackward0>)\n",
      "epoch: 332 loss: tensor(8.4558, grad_fn=<MseLossBackward0>)\n",
      "epoch: 333 loss: tensor(8.4542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 334 loss: tensor(8.4526, grad_fn=<MseLossBackward0>)\n",
      "epoch: 335 loss: tensor(8.4510, grad_fn=<MseLossBackward0>)\n",
      "epoch: 336 loss: tensor(8.4495, grad_fn=<MseLossBackward0>)\n",
      "epoch: 337 loss: tensor(8.4479, grad_fn=<MseLossBackward0>)\n",
      "epoch: 338 loss: tensor(8.4463, grad_fn=<MseLossBackward0>)\n",
      "epoch: 339 loss: tensor(8.4447, grad_fn=<MseLossBackward0>)\n",
      "epoch: 340 loss: tensor(8.4432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 341 loss: tensor(8.4416, grad_fn=<MseLossBackward0>)\n",
      "epoch: 342 loss: tensor(8.4400, grad_fn=<MseLossBackward0>)\n",
      "epoch: 343 loss: tensor(8.4384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 344 loss: tensor(8.4368, grad_fn=<MseLossBackward0>)\n",
      "epoch: 345 loss: tensor(8.4352, grad_fn=<MseLossBackward0>)\n",
      "epoch: 346 loss: tensor(8.4337, grad_fn=<MseLossBackward0>)\n",
      "epoch: 347 loss: tensor(8.4321, grad_fn=<MseLossBackward0>)\n",
      "epoch: 348 loss: tensor(8.4305, grad_fn=<MseLossBackward0>)\n",
      "epoch: 349 loss: tensor(8.4290, grad_fn=<MseLossBackward0>)\n",
      "epoch: 350 loss: tensor(8.4274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 351 loss: tensor(8.4259, grad_fn=<MseLossBackward0>)\n",
      "epoch: 352 loss: tensor(8.4243, grad_fn=<MseLossBackward0>)\n",
      "epoch: 353 loss: tensor(8.4227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 354 loss: tensor(8.4211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 355 loss: tensor(8.4195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 356 loss: tensor(8.4179, grad_fn=<MseLossBackward0>)\n",
      "epoch: 357 loss: tensor(8.4163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 358 loss: tensor(8.4148, grad_fn=<MseLossBackward0>)\n",
      "epoch: 359 loss: tensor(8.4132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 360 loss: tensor(8.4117, grad_fn=<MseLossBackward0>)\n",
      "epoch: 361 loss: tensor(8.4102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 362 loss: tensor(8.4087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 363 loss: tensor(8.4072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 364 loss: tensor(8.4057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 365 loss: tensor(8.4042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 366 loss: tensor(8.4027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 367 loss: tensor(8.4012, grad_fn=<MseLossBackward0>)\n",
      "epoch: 368 loss: tensor(8.3997, grad_fn=<MseLossBackward0>)\n",
      "epoch: 369 loss: tensor(8.3982, grad_fn=<MseLossBackward0>)\n",
      "epoch: 370 loss: tensor(8.3967, grad_fn=<MseLossBackward0>)\n",
      "epoch: 371 loss: tensor(8.3952, grad_fn=<MseLossBackward0>)\n",
      "epoch: 372 loss: tensor(8.3936, grad_fn=<MseLossBackward0>)\n",
      "epoch: 373 loss: tensor(8.3921, grad_fn=<MseLossBackward0>)\n",
      "epoch: 374 loss: tensor(8.3905, grad_fn=<MseLossBackward0>)\n",
      "epoch: 375 loss: tensor(8.3890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 376 loss: tensor(8.3874, grad_fn=<MseLossBackward0>)\n",
      "epoch: 377 loss: tensor(8.3859, grad_fn=<MseLossBackward0>)\n",
      "epoch: 378 loss: tensor(8.3843, grad_fn=<MseLossBackward0>)\n",
      "epoch: 379 loss: tensor(8.3828, grad_fn=<MseLossBackward0>)\n",
      "epoch: 380 loss: tensor(8.3812, grad_fn=<MseLossBackward0>)\n",
      "epoch: 381 loss: tensor(8.3797, grad_fn=<MseLossBackward0>)\n",
      "epoch: 382 loss: tensor(8.3781, grad_fn=<MseLossBackward0>)\n",
      "epoch: 383 loss: tensor(8.3766, grad_fn=<MseLossBackward0>)\n",
      "epoch: 384 loss: tensor(8.3750, grad_fn=<MseLossBackward0>)\n",
      "epoch: 385 loss: tensor(8.3734, grad_fn=<MseLossBackward0>)\n",
      "epoch: 386 loss: tensor(8.3718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 387 loss: tensor(8.3702, grad_fn=<MseLossBackward0>)\n",
      "epoch: 388 loss: tensor(8.3687, grad_fn=<MseLossBackward0>)\n",
      "epoch: 389 loss: tensor(8.3671, grad_fn=<MseLossBackward0>)\n",
      "epoch: 390 loss: tensor(8.3656, grad_fn=<MseLossBackward0>)\n",
      "epoch: 391 loss: tensor(8.3640, grad_fn=<MseLossBackward0>)\n",
      "epoch: 392 loss: tensor(8.3625, grad_fn=<MseLossBackward0>)\n",
      "epoch: 393 loss: tensor(8.3609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 394 loss: tensor(8.3594, grad_fn=<MseLossBackward0>)\n",
      "epoch: 395 loss: tensor(8.3578, grad_fn=<MseLossBackward0>)\n",
      "epoch: 396 loss: tensor(8.3563, grad_fn=<MseLossBackward0>)\n",
      "epoch: 397 loss: tensor(8.3548, grad_fn=<MseLossBackward0>)\n",
      "epoch: 398 loss: tensor(8.3533, grad_fn=<MseLossBackward0>)\n",
      "epoch: 399 loss: tensor(8.3517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 400 loss: tensor(8.3502, grad_fn=<MseLossBackward0>)\n",
      "epoch: 401 loss: tensor(8.3487, grad_fn=<MseLossBackward0>)\n",
      "epoch: 402 loss: tensor(8.3471, grad_fn=<MseLossBackward0>)\n",
      "epoch: 403 loss: tensor(8.3456, grad_fn=<MseLossBackward0>)\n",
      "epoch: 404 loss: tensor(8.3441, grad_fn=<MseLossBackward0>)\n",
      "epoch: 405 loss: tensor(8.3425, grad_fn=<MseLossBackward0>)\n",
      "epoch: 406 loss: tensor(8.3410, grad_fn=<MseLossBackward0>)\n",
      "epoch: 407 loss: tensor(8.3394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 408 loss: tensor(8.3379, grad_fn=<MseLossBackward0>)\n",
      "epoch: 409 loss: tensor(8.3363, grad_fn=<MseLossBackward0>)\n",
      "epoch: 410 loss: tensor(8.3347, grad_fn=<MseLossBackward0>)\n",
      "epoch: 411 loss: tensor(8.3332, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 412 loss: tensor(8.3316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 413 loss: tensor(8.3300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 414 loss: tensor(8.3284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 415 loss: tensor(8.3269, grad_fn=<MseLossBackward0>)\n",
      "epoch: 416 loss: tensor(8.3253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 417 loss: tensor(8.3237, grad_fn=<MseLossBackward0>)\n",
      "epoch: 418 loss: tensor(8.3222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 419 loss: tensor(8.3206, grad_fn=<MseLossBackward0>)\n",
      "epoch: 420 loss: tensor(8.3190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 421 loss: tensor(8.3175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 422 loss: tensor(8.3159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 423 loss: tensor(8.3143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 424 loss: tensor(8.3127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 425 loss: tensor(8.3111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 426 loss: tensor(8.3095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 427 loss: tensor(8.3080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 428 loss: tensor(8.3064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 429 loss: tensor(8.3048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 430 loss: tensor(8.3032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 431 loss: tensor(8.3016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 432 loss: tensor(8.3000, grad_fn=<MseLossBackward0>)\n",
      "epoch: 433 loss: tensor(8.2984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 434 loss: tensor(8.2968, grad_fn=<MseLossBackward0>)\n",
      "epoch: 435 loss: tensor(8.2952, grad_fn=<MseLossBackward0>)\n",
      "epoch: 436 loss: tensor(8.2936, grad_fn=<MseLossBackward0>)\n",
      "epoch: 437 loss: tensor(8.2920, grad_fn=<MseLossBackward0>)\n",
      "epoch: 438 loss: tensor(8.2904, grad_fn=<MseLossBackward0>)\n",
      "epoch: 439 loss: tensor(8.2888, grad_fn=<MseLossBackward0>)\n",
      "epoch: 440 loss: tensor(8.2871, grad_fn=<MseLossBackward0>)\n",
      "epoch: 441 loss: tensor(8.2855, grad_fn=<MseLossBackward0>)\n",
      "epoch: 442 loss: tensor(8.2838, grad_fn=<MseLossBackward0>)\n",
      "epoch: 443 loss: tensor(8.2822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 444 loss: tensor(8.2805, grad_fn=<MseLossBackward0>)\n",
      "epoch: 445 loss: tensor(8.2788, grad_fn=<MseLossBackward0>)\n",
      "epoch: 446 loss: tensor(8.2771, grad_fn=<MseLossBackward0>)\n",
      "epoch: 447 loss: tensor(8.2755, grad_fn=<MseLossBackward0>)\n",
      "epoch: 448 loss: tensor(8.2738, grad_fn=<MseLossBackward0>)\n",
      "epoch: 449 loss: tensor(8.2722, grad_fn=<MseLossBackward0>)\n",
      "epoch: 450 loss: tensor(8.2705, grad_fn=<MseLossBackward0>)\n",
      "epoch: 451 loss: tensor(8.2689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 452 loss: tensor(8.2672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 453 loss: tensor(8.2656, grad_fn=<MseLossBackward0>)\n",
      "epoch: 454 loss: tensor(8.2639, grad_fn=<MseLossBackward0>)\n",
      "epoch: 455 loss: tensor(8.2622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 456 loss: tensor(8.2606, grad_fn=<MseLossBackward0>)\n",
      "epoch: 457 loss: tensor(8.2589, grad_fn=<MseLossBackward0>)\n",
      "epoch: 458 loss: tensor(8.2572, grad_fn=<MseLossBackward0>)\n",
      "epoch: 459 loss: tensor(8.2556, grad_fn=<MseLossBackward0>)\n",
      "epoch: 460 loss: tensor(8.2539, grad_fn=<MseLossBackward0>)\n",
      "epoch: 461 loss: tensor(8.2522, grad_fn=<MseLossBackward0>)\n",
      "epoch: 462 loss: tensor(8.2505, grad_fn=<MseLossBackward0>)\n",
      "epoch: 463 loss: tensor(8.2488, grad_fn=<MseLossBackward0>)\n",
      "epoch: 464 loss: tensor(8.2471, grad_fn=<MseLossBackward0>)\n",
      "epoch: 465 loss: tensor(8.2454, grad_fn=<MseLossBackward0>)\n",
      "epoch: 466 loss: tensor(8.2437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 467 loss: tensor(8.2420, grad_fn=<MseLossBackward0>)\n",
      "epoch: 468 loss: tensor(8.2404, grad_fn=<MseLossBackward0>)\n",
      "epoch: 469 loss: tensor(8.2387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 470 loss: tensor(8.2370, grad_fn=<MseLossBackward0>)\n",
      "epoch: 471 loss: tensor(8.2352, grad_fn=<MseLossBackward0>)\n",
      "epoch: 472 loss: tensor(8.2335, grad_fn=<MseLossBackward0>)\n",
      "epoch: 473 loss: tensor(8.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch: 474 loss: tensor(8.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 475 loss: tensor(8.2283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 476 loss: tensor(8.2265, grad_fn=<MseLossBackward0>)\n",
      "epoch: 477 loss: tensor(8.2247, grad_fn=<MseLossBackward0>)\n",
      "epoch: 478 loss: tensor(8.2229, grad_fn=<MseLossBackward0>)\n",
      "epoch: 479 loss: tensor(8.2211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 480 loss: tensor(8.2193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 481 loss: tensor(8.2175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 482 loss: tensor(8.2158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 483 loss: tensor(8.2140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 484 loss: tensor(8.2122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 485 loss: tensor(8.2104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 486 loss: tensor(8.2086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 487 loss: tensor(8.2068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 488 loss: tensor(8.2049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 489 loss: tensor(8.2030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 490 loss: tensor(8.2012, grad_fn=<MseLossBackward0>)\n",
      "epoch: 491 loss: tensor(8.1993, grad_fn=<MseLossBackward0>)\n",
      "epoch: 492 loss: tensor(8.1974, grad_fn=<MseLossBackward0>)\n",
      "epoch: 493 loss: tensor(8.1956, grad_fn=<MseLossBackward0>)\n",
      "epoch: 494 loss: tensor(8.1937, grad_fn=<MseLossBackward0>)\n",
      "epoch: 495 loss: tensor(8.1918, grad_fn=<MseLossBackward0>)\n",
      "epoch: 496 loss: tensor(8.1900, grad_fn=<MseLossBackward0>)\n",
      "epoch: 497 loss: tensor(8.1882, grad_fn=<MseLossBackward0>)\n",
      "epoch: 498 loss: tensor(8.1864, grad_fn=<MseLossBackward0>)\n",
      "epoch: 499 loss: tensor(8.1846, grad_fn=<MseLossBackward0>)\n",
      "epoch: 500 loss: tensor(8.1829, grad_fn=<MseLossBackward0>)\n",
      "epoch: 501 loss: tensor(8.1811, grad_fn=<MseLossBackward0>)\n",
      "epoch: 502 loss: tensor(8.1792, grad_fn=<MseLossBackward0>)\n",
      "epoch: 503 loss: tensor(8.1774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 504 loss: tensor(8.1755, grad_fn=<MseLossBackward0>)\n",
      "epoch: 505 loss: tensor(8.1735, grad_fn=<MseLossBackward0>)\n",
      "epoch: 506 loss: tensor(8.1715, grad_fn=<MseLossBackward0>)\n",
      "epoch: 507 loss: tensor(8.1696, grad_fn=<MseLossBackward0>)\n",
      "epoch: 508 loss: tensor(8.1677, grad_fn=<MseLossBackward0>)\n",
      "epoch: 509 loss: tensor(8.1660, grad_fn=<MseLossBackward0>)\n",
      "epoch: 510 loss: tensor(8.1642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 511 loss: tensor(8.1624, grad_fn=<MseLossBackward0>)\n",
      "epoch: 512 loss: tensor(8.1606, grad_fn=<MseLossBackward0>)\n",
      "epoch: 513 loss: tensor(8.1587, grad_fn=<MseLossBackward0>)\n",
      "epoch: 514 loss: tensor(8.1569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 515 loss: tensor(8.1551, grad_fn=<MseLossBackward0>)\n",
      "epoch: 516 loss: tensor(8.1532, grad_fn=<MseLossBackward0>)\n",
      "epoch: 517 loss: tensor(8.1514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 518 loss: tensor(8.1496, grad_fn=<MseLossBackward0>)\n",
      "epoch: 519 loss: tensor(8.1478, grad_fn=<MseLossBackward0>)\n",
      "epoch: 520 loss: tensor(8.1459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 521 loss: tensor(8.1441, grad_fn=<MseLossBackward0>)\n",
      "epoch: 522 loss: tensor(8.1422, grad_fn=<MseLossBackward0>)\n",
      "epoch: 523 loss: tensor(8.1403, grad_fn=<MseLossBackward0>)\n",
      "epoch: 524 loss: tensor(8.1384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 525 loss: tensor(8.1364, grad_fn=<MseLossBackward0>)\n",
      "epoch: 526 loss: tensor(8.1345, grad_fn=<MseLossBackward0>)\n",
      "epoch: 527 loss: tensor(8.1327, grad_fn=<MseLossBackward0>)\n",
      "epoch: 528 loss: tensor(8.1308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 529 loss: tensor(8.1289, grad_fn=<MseLossBackward0>)\n",
      "epoch: 530 loss: tensor(8.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch: 531 loss: tensor(8.1252, grad_fn=<MseLossBackward0>)\n",
      "epoch: 532 loss: tensor(8.1234, grad_fn=<MseLossBackward0>)\n",
      "epoch: 533 loss: tensor(8.1215, grad_fn=<MseLossBackward0>)\n",
      "epoch: 534 loss: tensor(8.1196, grad_fn=<MseLossBackward0>)\n",
      "epoch: 535 loss: tensor(8.1178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 536 loss: tensor(8.1159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 537 loss: tensor(8.1140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 538 loss: tensor(8.1122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 539 loss: tensor(8.1103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 540 loss: tensor(8.1084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 541 loss: tensor(8.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 542 loss: tensor(8.1047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 543 loss: tensor(8.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 544 loss: tensor(8.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch: 545 loss: tensor(8.0991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 546 loss: tensor(8.0973, grad_fn=<MseLossBackward0>)\n",
      "epoch: 547 loss: tensor(8.0954, grad_fn=<MseLossBackward0>)\n",
      "epoch: 548 loss: tensor(8.0936, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 549 loss: tensor(8.0917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 550 loss: tensor(8.0898, grad_fn=<MseLossBackward0>)\n",
      "epoch: 551 loss: tensor(8.0879, grad_fn=<MseLossBackward0>)\n",
      "epoch: 552 loss: tensor(8.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 553 loss: tensor(8.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch: 554 loss: tensor(8.0822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 555 loss: tensor(8.0803, grad_fn=<MseLossBackward0>)\n",
      "epoch: 556 loss: tensor(8.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 557 loss: tensor(8.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch: 558 loss: tensor(8.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch: 559 loss: tensor(8.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch: 560 loss: tensor(8.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 561 loss: tensor(8.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch: 562 loss: tensor(8.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 563 loss: tensor(8.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch: 564 loss: tensor(8.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch: 565 loss: tensor(8.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 566 loss: tensor(8.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch: 567 loss: tensor(8.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 568 loss: tensor(8.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch: 569 loss: tensor(8.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch: 570 loss: tensor(8.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch: 571 loss: tensor(8.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch: 572 loss: tensor(8.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch: 573 loss: tensor(8.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch: 574 loss: tensor(8.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch: 575 loss: tensor(8.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch: 576 loss: tensor(8.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch: 577 loss: tensor(8.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 578 loss: tensor(8.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch: 579 loss: tensor(8.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch: 580 loss: tensor(8.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch: 581 loss: tensor(8.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch: 582 loss: tensor(8.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch: 583 loss: tensor(8.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch: 584 loss: tensor(8.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch: 585 loss: tensor(8.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 586 loss: tensor(8.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch: 587 loss: tensor(8.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch: 588 loss: tensor(8.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 589 loss: tensor(8.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 590 loss: tensor(8.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 591 loss: tensor(8.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 592 loss: tensor(8.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 593 loss: tensor(8.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 594 loss: tensor(8.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 595 loss: tensor(8.0004, grad_fn=<MseLossBackward0>)\n",
      "epoch: 596 loss: tensor(7.9984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 597 loss: tensor(7.9963, grad_fn=<MseLossBackward0>)\n",
      "epoch: 598 loss: tensor(7.9943, grad_fn=<MseLossBackward0>)\n",
      "epoch: 599 loss: tensor(7.9922, grad_fn=<MseLossBackward0>)\n",
      "epoch: 600 loss: tensor(7.9901, grad_fn=<MseLossBackward0>)\n",
      "epoch: 601 loss: tensor(7.9881, grad_fn=<MseLossBackward0>)\n",
      "epoch: 602 loss: tensor(7.9860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 603 loss: tensor(7.9839, grad_fn=<MseLossBackward0>)\n",
      "epoch: 604 loss: tensor(7.9818, grad_fn=<MseLossBackward0>)\n",
      "epoch: 605 loss: tensor(7.9796, grad_fn=<MseLossBackward0>)\n",
      "epoch: 606 loss: tensor(7.9774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 607 loss: tensor(7.9752, grad_fn=<MseLossBackward0>)\n",
      "epoch: 608 loss: tensor(7.9731, grad_fn=<MseLossBackward0>)\n",
      "epoch: 609 loss: tensor(7.9710, grad_fn=<MseLossBackward0>)\n",
      "epoch: 610 loss: tensor(7.9689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 611 loss: tensor(7.9668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 612 loss: tensor(7.9647, grad_fn=<MseLossBackward0>)\n",
      "epoch: 613 loss: tensor(7.9626, grad_fn=<MseLossBackward0>)\n",
      "epoch: 614 loss: tensor(7.9605, grad_fn=<MseLossBackward0>)\n",
      "epoch: 615 loss: tensor(7.9583, grad_fn=<MseLossBackward0>)\n",
      "epoch: 616 loss: tensor(7.9561, grad_fn=<MseLossBackward0>)\n",
      "epoch: 617 loss: tensor(7.9540, grad_fn=<MseLossBackward0>)\n",
      "epoch: 618 loss: tensor(7.9518, grad_fn=<MseLossBackward0>)\n",
      "epoch: 619 loss: tensor(7.9497, grad_fn=<MseLossBackward0>)\n",
      "epoch: 620 loss: tensor(7.9475, grad_fn=<MseLossBackward0>)\n",
      "epoch: 621 loss: tensor(7.9454, grad_fn=<MseLossBackward0>)\n",
      "epoch: 622 loss: tensor(7.9432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 623 loss: tensor(7.9410, grad_fn=<MseLossBackward0>)\n",
      "epoch: 624 loss: tensor(7.9389, grad_fn=<MseLossBackward0>)\n",
      "epoch: 625 loss: tensor(7.9367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 626 loss: tensor(7.9345, grad_fn=<MseLossBackward0>)\n",
      "epoch: 627 loss: tensor(7.9323, grad_fn=<MseLossBackward0>)\n",
      "epoch: 628 loss: tensor(7.9301, grad_fn=<MseLossBackward0>)\n",
      "epoch: 629 loss: tensor(7.9280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 630 loss: tensor(7.9258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 631 loss: tensor(7.9236, grad_fn=<MseLossBackward0>)\n",
      "epoch: 632 loss: tensor(7.9214, grad_fn=<MseLossBackward0>)\n",
      "epoch: 633 loss: tensor(7.9192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 634 loss: tensor(7.9169, grad_fn=<MseLossBackward0>)\n",
      "epoch: 635 loss: tensor(7.9147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 636 loss: tensor(7.9125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 637 loss: tensor(7.9103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 638 loss: tensor(7.9080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 639 loss: tensor(7.9058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 640 loss: tensor(7.9036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 641 loss: tensor(7.9013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 642 loss: tensor(7.8991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 643 loss: tensor(7.8968, grad_fn=<MseLossBackward0>)\n",
      "epoch: 644 loss: tensor(7.8944, grad_fn=<MseLossBackward0>)\n",
      "epoch: 645 loss: tensor(7.8922, grad_fn=<MseLossBackward0>)\n",
      "epoch: 646 loss: tensor(7.8899, grad_fn=<MseLossBackward0>)\n",
      "epoch: 647 loss: tensor(7.8876, grad_fn=<MseLossBackward0>)\n",
      "epoch: 648 loss: tensor(7.8853, grad_fn=<MseLossBackward0>)\n",
      "epoch: 649 loss: tensor(7.8829, grad_fn=<MseLossBackward0>)\n",
      "epoch: 650 loss: tensor(7.8806, grad_fn=<MseLossBackward0>)\n",
      "epoch: 651 loss: tensor(7.8783, grad_fn=<MseLossBackward0>)\n",
      "epoch: 652 loss: tensor(7.8759, grad_fn=<MseLossBackward0>)\n",
      "epoch: 653 loss: tensor(7.8735, grad_fn=<MseLossBackward0>)\n",
      "epoch: 654 loss: tensor(7.8712, grad_fn=<MseLossBackward0>)\n",
      "epoch: 655 loss: tensor(7.8688, grad_fn=<MseLossBackward0>)\n",
      "epoch: 656 loss: tensor(7.8664, grad_fn=<MseLossBackward0>)\n",
      "epoch: 657 loss: tensor(7.8640, grad_fn=<MseLossBackward0>)\n",
      "epoch: 658 loss: tensor(7.8617, grad_fn=<MseLossBackward0>)\n",
      "epoch: 659 loss: tensor(7.8593, grad_fn=<MseLossBackward0>)\n",
      "epoch: 660 loss: tensor(7.8568, grad_fn=<MseLossBackward0>)\n",
      "epoch: 661 loss: tensor(7.8544, grad_fn=<MseLossBackward0>)\n",
      "epoch: 662 loss: tensor(7.8519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 663 loss: tensor(7.8495, grad_fn=<MseLossBackward0>)\n",
      "epoch: 664 loss: tensor(7.8471, grad_fn=<MseLossBackward0>)\n",
      "epoch: 665 loss: tensor(7.8447, grad_fn=<MseLossBackward0>)\n",
      "epoch: 666 loss: tensor(7.8422, grad_fn=<MseLossBackward0>)\n",
      "epoch: 667 loss: tensor(7.8398, grad_fn=<MseLossBackward0>)\n",
      "epoch: 668 loss: tensor(7.8374, grad_fn=<MseLossBackward0>)\n",
      "epoch: 669 loss: tensor(7.8350, grad_fn=<MseLossBackward0>)\n",
      "epoch: 670 loss: tensor(7.8326, grad_fn=<MseLossBackward0>)\n",
      "epoch: 671 loss: tensor(7.8301, grad_fn=<MseLossBackward0>)\n",
      "epoch: 672 loss: tensor(7.8277, grad_fn=<MseLossBackward0>)\n",
      "epoch: 673 loss: tensor(7.8252, grad_fn=<MseLossBackward0>)\n",
      "epoch: 674 loss: tensor(7.8228, grad_fn=<MseLossBackward0>)\n",
      "epoch: 675 loss: tensor(7.8203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 676 loss: tensor(7.8178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 677 loss: tensor(7.8154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 678 loss: tensor(7.8129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 679 loss: tensor(7.8104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 680 loss: tensor(7.8079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 681 loss: tensor(7.8054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 682 loss: tensor(7.8030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 683 loss: tensor(7.8005, grad_fn=<MseLossBackward0>)\n",
      "epoch: 684 loss: tensor(7.7979, grad_fn=<MseLossBackward0>)\n",
      "epoch: 685 loss: tensor(7.7954, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 686 loss: tensor(7.7928, grad_fn=<MseLossBackward0>)\n",
      "epoch: 687 loss: tensor(7.7903, grad_fn=<MseLossBackward0>)\n",
      "epoch: 688 loss: tensor(7.7877, grad_fn=<MseLossBackward0>)\n",
      "epoch: 689 loss: tensor(7.7851, grad_fn=<MseLossBackward0>)\n",
      "epoch: 690 loss: tensor(7.7825, grad_fn=<MseLossBackward0>)\n",
      "epoch: 691 loss: tensor(7.7798, grad_fn=<MseLossBackward0>)\n",
      "epoch: 692 loss: tensor(7.7772, grad_fn=<MseLossBackward0>)\n",
      "epoch: 693 loss: tensor(7.7746, grad_fn=<MseLossBackward0>)\n",
      "epoch: 694 loss: tensor(7.7720, grad_fn=<MseLossBackward0>)\n",
      "epoch: 695 loss: tensor(7.7693, grad_fn=<MseLossBackward0>)\n",
      "epoch: 696 loss: tensor(7.7668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 697 loss: tensor(7.7642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 698 loss: tensor(7.7616, grad_fn=<MseLossBackward0>)\n",
      "epoch: 699 loss: tensor(7.7590, grad_fn=<MseLossBackward0>)\n",
      "epoch: 700 loss: tensor(7.7564, grad_fn=<MseLossBackward0>)\n",
      "epoch: 701 loss: tensor(7.7537, grad_fn=<MseLossBackward0>)\n",
      "epoch: 702 loss: tensor(7.7511, grad_fn=<MseLossBackward0>)\n",
      "epoch: 703 loss: tensor(7.7485, grad_fn=<MseLossBackward0>)\n",
      "epoch: 704 loss: tensor(7.7459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 705 loss: tensor(7.7432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 706 loss: tensor(7.7405, grad_fn=<MseLossBackward0>)\n",
      "epoch: 707 loss: tensor(7.7379, grad_fn=<MseLossBackward0>)\n",
      "epoch: 708 loss: tensor(7.7352, grad_fn=<MseLossBackward0>)\n",
      "epoch: 709 loss: tensor(7.7325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 710 loss: tensor(7.7299, grad_fn=<MseLossBackward0>)\n",
      "epoch: 711 loss: tensor(7.7272, grad_fn=<MseLossBackward0>)\n",
      "epoch: 712 loss: tensor(7.7246, grad_fn=<MseLossBackward0>)\n",
      "epoch: 713 loss: tensor(7.7220, grad_fn=<MseLossBackward0>)\n",
      "epoch: 714 loss: tensor(7.7193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 715 loss: tensor(7.7166, grad_fn=<MseLossBackward0>)\n",
      "epoch: 716 loss: tensor(7.7140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 717 loss: tensor(7.7113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 718 loss: tensor(7.7086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 719 loss: tensor(7.7059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 720 loss: tensor(7.7032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 721 loss: tensor(7.7004, grad_fn=<MseLossBackward0>)\n",
      "epoch: 722 loss: tensor(7.6977, grad_fn=<MseLossBackward0>)\n",
      "epoch: 723 loss: tensor(7.6950, grad_fn=<MseLossBackward0>)\n",
      "epoch: 724 loss: tensor(7.6923, grad_fn=<MseLossBackward0>)\n",
      "epoch: 725 loss: tensor(7.6895, grad_fn=<MseLossBackward0>)\n",
      "epoch: 726 loss: tensor(7.6867, grad_fn=<MseLossBackward0>)\n",
      "epoch: 727 loss: tensor(7.6839, grad_fn=<MseLossBackward0>)\n",
      "epoch: 728 loss: tensor(7.6810, grad_fn=<MseLossBackward0>)\n",
      "epoch: 729 loss: tensor(7.6782, grad_fn=<MseLossBackward0>)\n",
      "epoch: 730 loss: tensor(7.6754, grad_fn=<MseLossBackward0>)\n",
      "epoch: 731 loss: tensor(7.6725, grad_fn=<MseLossBackward0>)\n",
      "epoch: 732 loss: tensor(7.6696, grad_fn=<MseLossBackward0>)\n",
      "epoch: 733 loss: tensor(7.6667, grad_fn=<MseLossBackward0>)\n",
      "epoch: 734 loss: tensor(7.6637, grad_fn=<MseLossBackward0>)\n",
      "epoch: 735 loss: tensor(7.6606, grad_fn=<MseLossBackward0>)\n",
      "epoch: 736 loss: tensor(7.6577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 737 loss: tensor(7.6548, grad_fn=<MseLossBackward0>)\n",
      "epoch: 738 loss: tensor(7.6520, grad_fn=<MseLossBackward0>)\n",
      "epoch: 739 loss: tensor(7.6493, grad_fn=<MseLossBackward0>)\n",
      "epoch: 740 loss: tensor(7.6465, grad_fn=<MseLossBackward0>)\n",
      "epoch: 741 loss: tensor(7.6438, grad_fn=<MseLossBackward0>)\n",
      "epoch: 742 loss: tensor(7.6411, grad_fn=<MseLossBackward0>)\n",
      "epoch: 743 loss: tensor(7.6384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 744 loss: tensor(7.6357, grad_fn=<MseLossBackward0>)\n",
      "epoch: 745 loss: tensor(7.6329, grad_fn=<MseLossBackward0>)\n",
      "epoch: 746 loss: tensor(7.6302, grad_fn=<MseLossBackward0>)\n",
      "epoch: 747 loss: tensor(7.6274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 748 loss: tensor(7.6246, grad_fn=<MseLossBackward0>)\n",
      "epoch: 749 loss: tensor(7.6218, grad_fn=<MseLossBackward0>)\n",
      "epoch: 750 loss: tensor(7.6191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 751 loss: tensor(7.6163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 752 loss: tensor(7.6136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 753 loss: tensor(7.6108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 754 loss: tensor(7.6080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 755 loss: tensor(7.6053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 756 loss: tensor(7.6025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 757 loss: tensor(7.5998, grad_fn=<MseLossBackward0>)\n",
      "epoch: 758 loss: tensor(7.5970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 759 loss: tensor(7.5942, grad_fn=<MseLossBackward0>)\n",
      "epoch: 760 loss: tensor(7.5914, grad_fn=<MseLossBackward0>)\n",
      "epoch: 761 loss: tensor(7.5886, grad_fn=<MseLossBackward0>)\n",
      "epoch: 762 loss: tensor(7.5857, grad_fn=<MseLossBackward0>)\n",
      "epoch: 763 loss: tensor(7.5828, grad_fn=<MseLossBackward0>)\n",
      "epoch: 764 loss: tensor(7.5800, grad_fn=<MseLossBackward0>)\n",
      "epoch: 765 loss: tensor(7.5771, grad_fn=<MseLossBackward0>)\n",
      "epoch: 766 loss: tensor(7.5742, grad_fn=<MseLossBackward0>)\n",
      "epoch: 767 loss: tensor(7.5713, grad_fn=<MseLossBackward0>)\n",
      "epoch: 768 loss: tensor(7.5684, grad_fn=<MseLossBackward0>)\n",
      "epoch: 769 loss: tensor(7.5656, grad_fn=<MseLossBackward0>)\n",
      "epoch: 770 loss: tensor(7.5627, grad_fn=<MseLossBackward0>)\n",
      "epoch: 771 loss: tensor(7.5599, grad_fn=<MseLossBackward0>)\n",
      "epoch: 772 loss: tensor(7.5571, grad_fn=<MseLossBackward0>)\n",
      "epoch: 773 loss: tensor(7.5542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 774 loss: tensor(7.5513, grad_fn=<MseLossBackward0>)\n",
      "epoch: 775 loss: tensor(7.5485, grad_fn=<MseLossBackward0>)\n",
      "epoch: 776 loss: tensor(7.5455, grad_fn=<MseLossBackward0>)\n",
      "epoch: 777 loss: tensor(7.5426, grad_fn=<MseLossBackward0>)\n",
      "epoch: 778 loss: tensor(7.5396, grad_fn=<MseLossBackward0>)\n",
      "epoch: 779 loss: tensor(7.5367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 780 loss: tensor(7.5339, grad_fn=<MseLossBackward0>)\n",
      "epoch: 781 loss: tensor(7.5310, grad_fn=<MseLossBackward0>)\n",
      "epoch: 782 loss: tensor(7.5281, grad_fn=<MseLossBackward0>)\n",
      "epoch: 783 loss: tensor(7.5252, grad_fn=<MseLossBackward0>)\n",
      "epoch: 784 loss: tensor(7.5223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 785 loss: tensor(7.5194, grad_fn=<MseLossBackward0>)\n",
      "epoch: 786 loss: tensor(7.5164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 787 loss: tensor(7.5133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 788 loss: tensor(7.5103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 789 loss: tensor(7.5073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 790 loss: tensor(7.5044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 791 loss: tensor(7.5014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 792 loss: tensor(7.4984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 793 loss: tensor(7.4954, grad_fn=<MseLossBackward0>)\n",
      "epoch: 794 loss: tensor(7.4924, grad_fn=<MseLossBackward0>)\n",
      "epoch: 795 loss: tensor(7.4894, grad_fn=<MseLossBackward0>)\n",
      "epoch: 796 loss: tensor(7.4863, grad_fn=<MseLossBackward0>)\n",
      "epoch: 797 loss: tensor(7.4833, grad_fn=<MseLossBackward0>)\n",
      "epoch: 798 loss: tensor(7.4804, grad_fn=<MseLossBackward0>)\n",
      "epoch: 799 loss: tensor(7.4774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 800 loss: tensor(7.4744, grad_fn=<MseLossBackward0>)\n",
      "epoch: 801 loss: tensor(7.4714, grad_fn=<MseLossBackward0>)\n",
      "epoch: 802 loss: tensor(7.4684, grad_fn=<MseLossBackward0>)\n",
      "epoch: 803 loss: tensor(7.4654, grad_fn=<MseLossBackward0>)\n",
      "epoch: 804 loss: tensor(7.4623, grad_fn=<MseLossBackward0>)\n",
      "epoch: 805 loss: tensor(7.4593, grad_fn=<MseLossBackward0>)\n",
      "epoch: 806 loss: tensor(7.4562, grad_fn=<MseLossBackward0>)\n",
      "epoch: 807 loss: tensor(7.4531, grad_fn=<MseLossBackward0>)\n",
      "epoch: 808 loss: tensor(7.4500, grad_fn=<MseLossBackward0>)\n",
      "epoch: 809 loss: tensor(7.4470, grad_fn=<MseLossBackward0>)\n",
      "epoch: 810 loss: tensor(7.4439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 811 loss: tensor(7.4408, grad_fn=<MseLossBackward0>)\n",
      "epoch: 812 loss: tensor(7.4378, grad_fn=<MseLossBackward0>)\n",
      "epoch: 813 loss: tensor(7.4347, grad_fn=<MseLossBackward0>)\n",
      "epoch: 814 loss: tensor(7.4316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 815 loss: tensor(7.4285, grad_fn=<MseLossBackward0>)\n",
      "epoch: 816 loss: tensor(7.4253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 817 loss: tensor(7.4222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 818 loss: tensor(7.4190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 819 loss: tensor(7.4158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 820 loss: tensor(7.4127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 821 loss: tensor(7.4095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 822 loss: tensor(7.4063, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 823 loss: tensor(7.4031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 824 loss: tensor(7.3999, grad_fn=<MseLossBackward0>)\n",
      "epoch: 825 loss: tensor(7.3967, grad_fn=<MseLossBackward0>)\n",
      "epoch: 826 loss: tensor(7.3935, grad_fn=<MseLossBackward0>)\n",
      "epoch: 827 loss: tensor(7.3903, grad_fn=<MseLossBackward0>)\n",
      "epoch: 828 loss: tensor(7.3871, grad_fn=<MseLossBackward0>)\n",
      "epoch: 829 loss: tensor(7.3839, grad_fn=<MseLossBackward0>)\n",
      "epoch: 830 loss: tensor(7.3807, grad_fn=<MseLossBackward0>)\n",
      "epoch: 831 loss: tensor(7.3774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 832 loss: tensor(7.3742, grad_fn=<MseLossBackward0>)\n",
      "epoch: 833 loss: tensor(7.3709, grad_fn=<MseLossBackward0>)\n",
      "epoch: 834 loss: tensor(7.3676, grad_fn=<MseLossBackward0>)\n",
      "epoch: 835 loss: tensor(7.3642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 836 loss: tensor(7.3609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 837 loss: tensor(7.3575, grad_fn=<MseLossBackward0>)\n",
      "epoch: 838 loss: tensor(7.3542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 839 loss: tensor(7.3510, grad_fn=<MseLossBackward0>)\n",
      "epoch: 840 loss: tensor(7.3478, grad_fn=<MseLossBackward0>)\n",
      "epoch: 841 loss: tensor(7.3445, grad_fn=<MseLossBackward0>)\n",
      "epoch: 842 loss: tensor(7.3413, grad_fn=<MseLossBackward0>)\n",
      "epoch: 843 loss: tensor(7.3380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 844 loss: tensor(7.3347, grad_fn=<MseLossBackward0>)\n",
      "epoch: 845 loss: tensor(7.3315, grad_fn=<MseLossBackward0>)\n",
      "epoch: 846 loss: tensor(7.3282, grad_fn=<MseLossBackward0>)\n",
      "epoch: 847 loss: tensor(7.3249, grad_fn=<MseLossBackward0>)\n",
      "epoch: 848 loss: tensor(7.3216, grad_fn=<MseLossBackward0>)\n",
      "epoch: 849 loss: tensor(7.3183, grad_fn=<MseLossBackward0>)\n",
      "epoch: 850 loss: tensor(7.3149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 851 loss: tensor(7.3116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 852 loss: tensor(7.3082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 853 loss: tensor(7.3048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 854 loss: tensor(7.3014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 855 loss: tensor(7.2980, grad_fn=<MseLossBackward0>)\n",
      "epoch: 856 loss: tensor(7.2947, grad_fn=<MseLossBackward0>)\n",
      "epoch: 857 loss: tensor(7.2912, grad_fn=<MseLossBackward0>)\n",
      "epoch: 858 loss: tensor(7.2878, grad_fn=<MseLossBackward0>)\n",
      "epoch: 859 loss: tensor(7.2844, grad_fn=<MseLossBackward0>)\n",
      "epoch: 860 loss: tensor(7.2809, grad_fn=<MseLossBackward0>)\n",
      "epoch: 861 loss: tensor(7.2774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 862 loss: tensor(7.2740, grad_fn=<MseLossBackward0>)\n",
      "epoch: 863 loss: tensor(7.2706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 864 loss: tensor(7.2672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 865 loss: tensor(7.2637, grad_fn=<MseLossBackward0>)\n",
      "epoch: 866 loss: tensor(7.2603, grad_fn=<MseLossBackward0>)\n",
      "epoch: 867 loss: tensor(7.2568, grad_fn=<MseLossBackward0>)\n",
      "epoch: 868 loss: tensor(7.2533, grad_fn=<MseLossBackward0>)\n",
      "epoch: 869 loss: tensor(7.2498, grad_fn=<MseLossBackward0>)\n",
      "epoch: 870 loss: tensor(7.2463, grad_fn=<MseLossBackward0>)\n",
      "epoch: 871 loss: tensor(7.2429, grad_fn=<MseLossBackward0>)\n",
      "epoch: 872 loss: tensor(7.2394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 873 loss: tensor(7.2359, grad_fn=<MseLossBackward0>)\n",
      "epoch: 874 loss: tensor(7.2325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 875 loss: tensor(7.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch: 876 loss: tensor(7.2255, grad_fn=<MseLossBackward0>)\n",
      "epoch: 877 loss: tensor(7.2220, grad_fn=<MseLossBackward0>)\n",
      "epoch: 878 loss: tensor(7.2185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 879 loss: tensor(7.2149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 880 loss: tensor(7.2114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 881 loss: tensor(7.2078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 882 loss: tensor(7.2041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 883 loss: tensor(7.2005, grad_fn=<MseLossBackward0>)\n",
      "epoch: 884 loss: tensor(7.1969, grad_fn=<MseLossBackward0>)\n",
      "epoch: 885 loss: tensor(7.1933, grad_fn=<MseLossBackward0>)\n",
      "epoch: 886 loss: tensor(7.1898, grad_fn=<MseLossBackward0>)\n",
      "epoch: 887 loss: tensor(7.1862, grad_fn=<MseLossBackward0>)\n",
      "epoch: 888 loss: tensor(7.1826, grad_fn=<MseLossBackward0>)\n",
      "epoch: 889 loss: tensor(7.1790, grad_fn=<MseLossBackward0>)\n",
      "epoch: 890 loss: tensor(7.1753, grad_fn=<MseLossBackward0>)\n",
      "epoch: 891 loss: tensor(7.1717, grad_fn=<MseLossBackward0>)\n",
      "epoch: 892 loss: tensor(7.1680, grad_fn=<MseLossBackward0>)\n",
      "epoch: 893 loss: tensor(7.1642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 894 loss: tensor(7.1605, grad_fn=<MseLossBackward0>)\n",
      "epoch: 895 loss: tensor(7.1567, grad_fn=<MseLossBackward0>)\n",
      "epoch: 896 loss: tensor(7.1529, grad_fn=<MseLossBackward0>)\n",
      "epoch: 897 loss: tensor(7.1491, grad_fn=<MseLossBackward0>)\n",
      "epoch: 898 loss: tensor(7.1453, grad_fn=<MseLossBackward0>)\n",
      "epoch: 899 loss: tensor(7.1416, grad_fn=<MseLossBackward0>)\n",
      "epoch: 900 loss: tensor(7.1379, grad_fn=<MseLossBackward0>)\n",
      "epoch: 901 loss: tensor(7.1342, grad_fn=<MseLossBackward0>)\n",
      "epoch: 902 loss: tensor(7.1306, grad_fn=<MseLossBackward0>)\n",
      "epoch: 903 loss: tensor(7.1269, grad_fn=<MseLossBackward0>)\n",
      "epoch: 904 loss: tensor(7.1233, grad_fn=<MseLossBackward0>)\n",
      "epoch: 905 loss: tensor(7.1197, grad_fn=<MseLossBackward0>)\n",
      "epoch: 906 loss: tensor(7.1160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 907 loss: tensor(7.1124, grad_fn=<MseLossBackward0>)\n",
      "epoch: 908 loss: tensor(7.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 909 loss: tensor(7.1051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 910 loss: tensor(7.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 911 loss: tensor(7.0977, grad_fn=<MseLossBackward0>)\n",
      "epoch: 912 loss: tensor(7.0940, grad_fn=<MseLossBackward0>)\n",
      "epoch: 913 loss: tensor(7.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch: 914 loss: tensor(7.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch: 915 loss: tensor(7.0826, grad_fn=<MseLossBackward0>)\n",
      "epoch: 916 loss: tensor(7.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch: 917 loss: tensor(7.0748, grad_fn=<MseLossBackward0>)\n",
      "epoch: 918 loss: tensor(7.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch: 919 loss: tensor(7.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 920 loss: tensor(7.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 921 loss: tensor(7.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch: 922 loss: tensor(7.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch: 923 loss: tensor(7.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch: 924 loss: tensor(7.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch: 925 loss: tensor(7.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 926 loss: tensor(7.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch: 927 loss: tensor(7.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch: 928 loss: tensor(7.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch: 929 loss: tensor(7.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 930 loss: tensor(7.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 931 loss: tensor(7.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 932 loss: tensor(7.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch: 933 loss: tensor(7.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 934 loss: tensor(7.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 935 loss: tensor(7.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 936 loss: tensor(6.9984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 937 loss: tensor(6.9941, grad_fn=<MseLossBackward0>)\n",
      "epoch: 938 loss: tensor(6.9899, grad_fn=<MseLossBackward0>)\n",
      "epoch: 939 loss: tensor(6.9856, grad_fn=<MseLossBackward0>)\n",
      "epoch: 940 loss: tensor(6.9813, grad_fn=<MseLossBackward0>)\n",
      "epoch: 941 loss: tensor(6.9770, grad_fn=<MseLossBackward0>)\n",
      "epoch: 942 loss: tensor(6.9726, grad_fn=<MseLossBackward0>)\n",
      "epoch: 943 loss: tensor(6.9680, grad_fn=<MseLossBackward0>)\n",
      "epoch: 944 loss: tensor(6.9632, grad_fn=<MseLossBackward0>)\n",
      "epoch: 945 loss: tensor(6.9584, grad_fn=<MseLossBackward0>)\n",
      "epoch: 946 loss: tensor(6.9534, grad_fn=<MseLossBackward0>)\n",
      "epoch: 947 loss: tensor(6.9484, grad_fn=<MseLossBackward0>)\n",
      "epoch: 948 loss: tensor(6.9433, grad_fn=<MseLossBackward0>)\n",
      "epoch: 949 loss: tensor(6.9383, grad_fn=<MseLossBackward0>)\n",
      "epoch: 950 loss: tensor(6.9331, grad_fn=<MseLossBackward0>)\n",
      "epoch: 951 loss: tensor(6.9278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 952 loss: tensor(6.9225, grad_fn=<MseLossBackward0>)\n",
      "epoch: 953 loss: tensor(6.9175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 954 loss: tensor(6.9126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 955 loss: tensor(6.9077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 956 loss: tensor(6.9029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 957 loss: tensor(6.8981, grad_fn=<MseLossBackward0>)\n",
      "epoch: 958 loss: tensor(6.8934, grad_fn=<MseLossBackward0>)\n",
      "epoch: 959 loss: tensor(6.8888, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 960 loss: tensor(6.8842, grad_fn=<MseLossBackward0>)\n",
      "epoch: 961 loss: tensor(6.8795, grad_fn=<MseLossBackward0>)\n",
      "epoch: 962 loss: tensor(6.8747, grad_fn=<MseLossBackward0>)\n",
      "epoch: 963 loss: tensor(6.8698, grad_fn=<MseLossBackward0>)\n",
      "epoch: 964 loss: tensor(6.8649, grad_fn=<MseLossBackward0>)\n",
      "epoch: 965 loss: tensor(6.8601, grad_fn=<MseLossBackward0>)\n",
      "epoch: 966 loss: tensor(6.8554, grad_fn=<MseLossBackward0>)\n",
      "epoch: 967 loss: tensor(6.8507, grad_fn=<MseLossBackward0>)\n",
      "epoch: 968 loss: tensor(6.8460, grad_fn=<MseLossBackward0>)\n",
      "epoch: 969 loss: tensor(6.8414, grad_fn=<MseLossBackward0>)\n",
      "epoch: 970 loss: tensor(6.8367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 971 loss: tensor(6.8321, grad_fn=<MseLossBackward0>)\n",
      "epoch: 972 loss: tensor(6.8274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 973 loss: tensor(6.8227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 974 loss: tensor(6.8180, grad_fn=<MseLossBackward0>)\n",
      "epoch: 975 loss: tensor(6.8132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 976 loss: tensor(6.8086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 977 loss: tensor(6.8039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 978 loss: tensor(6.7993, grad_fn=<MseLossBackward0>)\n",
      "epoch: 979 loss: tensor(6.7945, grad_fn=<MseLossBackward0>)\n",
      "epoch: 980 loss: tensor(6.7898, grad_fn=<MseLossBackward0>)\n",
      "epoch: 981 loss: tensor(6.7850, grad_fn=<MseLossBackward0>)\n",
      "epoch: 982 loss: tensor(6.7803, grad_fn=<MseLossBackward0>)\n",
      "epoch: 983 loss: tensor(6.7754, grad_fn=<MseLossBackward0>)\n",
      "epoch: 984 loss: tensor(6.7706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 985 loss: tensor(6.7658, grad_fn=<MseLossBackward0>)\n",
      "epoch: 986 loss: tensor(6.7609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 987 loss: tensor(6.7562, grad_fn=<MseLossBackward0>)\n",
      "epoch: 988 loss: tensor(6.7514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 989 loss: tensor(6.7466, grad_fn=<MseLossBackward0>)\n",
      "epoch: 990 loss: tensor(6.7418, grad_fn=<MseLossBackward0>)\n",
      "epoch: 991 loss: tensor(6.7369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 992 loss: tensor(6.7320, grad_fn=<MseLossBackward0>)\n",
      "epoch: 993 loss: tensor(6.7271, grad_fn=<MseLossBackward0>)\n",
      "epoch: 994 loss: tensor(6.7222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 995 loss: tensor(6.7173, grad_fn=<MseLossBackward0>)\n",
      "epoch: 996 loss: tensor(6.7124, grad_fn=<MseLossBackward0>)\n",
      "epoch: 997 loss: tensor(6.7074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 998 loss: tensor(6.7023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 999 loss: tensor(6.6972, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1000 loss: tensor(6.6920, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1001 loss: tensor(6.6868, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1002 loss: tensor(6.6815, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1003 loss: tensor(6.6760, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1004 loss: tensor(6.6703, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1005 loss: tensor(6.6643, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1006 loss: tensor(6.6580, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1007 loss: tensor(6.6526, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1008 loss: tensor(6.6474, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1009 loss: tensor(6.6421, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1010 loss: tensor(6.6364, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1011 loss: tensor(6.6303, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1012 loss: tensor(6.6240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1013 loss: tensor(6.6174, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1014 loss: tensor(6.6116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1015 loss: tensor(6.6063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1016 loss: tensor(6.6010, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1017 loss: tensor(6.5955, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1018 loss: tensor(6.5898, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1019 loss: tensor(6.5840, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1020 loss: tensor(6.5784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1021 loss: tensor(6.5730, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1022 loss: tensor(6.5676, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1023 loss: tensor(6.5623, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1024 loss: tensor(6.5570, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1025 loss: tensor(6.5517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1026 loss: tensor(6.5464, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1027 loss: tensor(6.5411, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1028 loss: tensor(6.5359, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1029 loss: tensor(6.5306, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1030 loss: tensor(6.5253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1031 loss: tensor(6.5201, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1032 loss: tensor(6.5149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1033 loss: tensor(6.5096, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1034 loss: tensor(6.5044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1035 loss: tensor(6.4992, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1036 loss: tensor(6.4940, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1037 loss: tensor(6.4887, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1038 loss: tensor(6.4835, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1039 loss: tensor(6.4782, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1040 loss: tensor(6.4729, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1041 loss: tensor(6.4676, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1042 loss: tensor(6.4623, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1043 loss: tensor(6.4569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1044 loss: tensor(6.4515, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1045 loss: tensor(6.4461, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1046 loss: tensor(6.4406, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1047 loss: tensor(6.4351, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1048 loss: tensor(6.4296, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1049 loss: tensor(6.4240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1050 loss: tensor(6.4185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1051 loss: tensor(6.4129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1052 loss: tensor(6.4073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1053 loss: tensor(6.4017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1054 loss: tensor(6.3959, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1055 loss: tensor(6.3901, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1056 loss: tensor(6.3842, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1057 loss: tensor(6.3784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1058 loss: tensor(6.3727, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1059 loss: tensor(6.3671, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1060 loss: tensor(6.3615, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1061 loss: tensor(6.3559, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1062 loss: tensor(6.3504, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1063 loss: tensor(6.3448, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1064 loss: tensor(6.3392, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1065 loss: tensor(6.3336, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1066 loss: tensor(6.3281, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1067 loss: tensor(6.3225, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1068 loss: tensor(6.3168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1069 loss: tensor(6.3111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1070 loss: tensor(6.3054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1071 loss: tensor(6.2996, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1072 loss: tensor(6.2939, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1073 loss: tensor(6.2881, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1074 loss: tensor(6.2822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1075 loss: tensor(6.2764, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1076 loss: tensor(6.2705, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1077 loss: tensor(6.2645, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1078 loss: tensor(6.2585, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1079 loss: tensor(6.2525, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1080 loss: tensor(6.2464, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1081 loss: tensor(6.2403, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1082 loss: tensor(6.2341, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1083 loss: tensor(6.2279, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1084 loss: tensor(6.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1085 loss: tensor(6.2152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1086 loss: tensor(6.2087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1087 loss: tensor(6.2022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1088 loss: tensor(6.1956, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1089 loss: tensor(6.1890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1090 loss: tensor(6.1825, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1091 loss: tensor(6.1760, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1092 loss: tensor(6.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1093 loss: tensor(6.1630, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1094 loss: tensor(6.1566, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1095 loss: tensor(6.1502, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1096 loss: tensor(6.1439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1097 loss: tensor(6.1376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1098 loss: tensor(6.1313, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1099 loss: tensor(6.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1100 loss: tensor(6.1186, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1101 loss: tensor(6.1124, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1102 loss: tensor(6.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1103 loss: tensor(6.0997, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1104 loss: tensor(6.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1105 loss: tensor(6.0869, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1106 loss: tensor(6.0804, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1107 loss: tensor(6.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1108 loss: tensor(6.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1109 loss: tensor(6.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1110 loss: tensor(6.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1111 loss: tensor(6.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1112 loss: tensor(6.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1113 loss: tensor(6.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1114 loss: tensor(6.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1115 loss: tensor(6.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1116 loss: tensor(6.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1117 loss: tensor(6.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1118 loss: tensor(6.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1119 loss: tensor(5.9987, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1120 loss: tensor(5.9926, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1121 loss: tensor(5.9866, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1122 loss: tensor(5.9805, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1123 loss: tensor(5.9744, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1124 loss: tensor(5.9683, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1125 loss: tensor(5.9622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1126 loss: tensor(5.9560, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1127 loss: tensor(5.9498, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1128 loss: tensor(5.9436, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1129 loss: tensor(5.9374, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1130 loss: tensor(5.9311, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1131 loss: tensor(5.9248, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1132 loss: tensor(5.9185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1133 loss: tensor(5.9122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1134 loss: tensor(5.9058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1135 loss: tensor(5.8995, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1136 loss: tensor(5.8931, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1137 loss: tensor(5.8868, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1138 loss: tensor(5.8804, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1139 loss: tensor(5.8740, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1140 loss: tensor(5.8675, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1141 loss: tensor(5.8609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1142 loss: tensor(5.8543, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1143 loss: tensor(5.8477, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1144 loss: tensor(5.8411, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1145 loss: tensor(5.8346, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1146 loss: tensor(5.8280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1147 loss: tensor(5.8215, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1148 loss: tensor(5.8149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1149 loss: tensor(5.8082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1150 loss: tensor(5.8015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1151 loss: tensor(5.7948, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1152 loss: tensor(5.7879, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1153 loss: tensor(5.7809, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1154 loss: tensor(5.7741, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1155 loss: tensor(5.7672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1156 loss: tensor(5.7604, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1157 loss: tensor(5.7536, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1158 loss: tensor(5.7467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1159 loss: tensor(5.7399, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1160 loss: tensor(5.7330, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1161 loss: tensor(5.7262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1162 loss: tensor(5.7193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1163 loss: tensor(5.7125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1164 loss: tensor(5.7057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1165 loss: tensor(5.6990, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1166 loss: tensor(5.6922, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1167 loss: tensor(5.6855, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1168 loss: tensor(5.6787, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1169 loss: tensor(5.6719, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1170 loss: tensor(5.6652, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1171 loss: tensor(5.6583, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1172 loss: tensor(5.6514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1173 loss: tensor(5.6445, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1174 loss: tensor(5.6376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1175 loss: tensor(5.6308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1176 loss: tensor(5.6239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1177 loss: tensor(5.6170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1178 loss: tensor(5.6101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1179 loss: tensor(5.6032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1180 loss: tensor(5.5964, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1181 loss: tensor(5.5895, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1182 loss: tensor(5.5826, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1183 loss: tensor(5.5756, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1184 loss: tensor(5.5685, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1185 loss: tensor(5.5614, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1186 loss: tensor(5.5543, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1187 loss: tensor(5.5473, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1188 loss: tensor(5.5403, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1189 loss: tensor(5.5333, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1190 loss: tensor(5.5262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1191 loss: tensor(5.5191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1192 loss: tensor(5.5119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1193 loss: tensor(5.5045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1194 loss: tensor(5.4970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1195 loss: tensor(5.4894, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1196 loss: tensor(5.4819, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1197 loss: tensor(5.4745, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1198 loss: tensor(5.4672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1199 loss: tensor(5.4601, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1200 loss: tensor(5.4531, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1201 loss: tensor(5.4462, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1202 loss: tensor(5.4394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1203 loss: tensor(5.4326, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1204 loss: tensor(5.4258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1205 loss: tensor(5.4190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1206 loss: tensor(5.4121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1207 loss: tensor(5.4052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1208 loss: tensor(5.3982, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1209 loss: tensor(5.3912, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1210 loss: tensor(5.3841, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1211 loss: tensor(5.3768, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1212 loss: tensor(5.3694, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1213 loss: tensor(5.3619, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1214 loss: tensor(5.3543, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1215 loss: tensor(5.3466, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1216 loss: tensor(5.3390, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1217 loss: tensor(5.3314, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1218 loss: tensor(5.3239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1219 loss: tensor(5.3165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1220 loss: tensor(5.3092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1221 loss: tensor(5.3019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1222 loss: tensor(5.2946, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1223 loss: tensor(5.2874, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1224 loss: tensor(5.2802, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1225 loss: tensor(5.2730, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1226 loss: tensor(5.2658, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1227 loss: tensor(5.2585, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1228 loss: tensor(5.2512, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1229 loss: tensor(5.2439, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1230 loss: tensor(5.2365, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1231 loss: tensor(5.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1232 loss: tensor(5.2217, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1233 loss: tensor(5.2143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1234 loss: tensor(5.2068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1235 loss: tensor(5.1992, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1236 loss: tensor(5.1917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1237 loss: tensor(5.1841, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1238 loss: tensor(5.1766, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1239 loss: tensor(5.1690, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1240 loss: tensor(5.1613, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1241 loss: tensor(5.1536, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1242 loss: tensor(5.1458, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1243 loss: tensor(5.1380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1244 loss: tensor(5.1302, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1245 loss: tensor(5.1223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1246 loss: tensor(5.1144, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1247 loss: tensor(5.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1248 loss: tensor(5.0983, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1249 loss: tensor(5.0904, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1250 loss: tensor(5.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1251 loss: tensor(5.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1252 loss: tensor(5.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1253 loss: tensor(5.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1254 loss: tensor(5.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1255 loss: tensor(5.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1256 loss: tensor(5.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1257 loss: tensor(5.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1258 loss: tensor(5.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1259 loss: tensor(5.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1260 loss: tensor(5.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1261 loss: tensor(4.9951, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1262 loss: tensor(4.9867, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1263 loss: tensor(4.9784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1264 loss: tensor(4.9701, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1265 loss: tensor(4.9618, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1266 loss: tensor(4.9536, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1267 loss: tensor(4.9454, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1268 loss: tensor(4.9373, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1269 loss: tensor(4.9292, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1270 loss: tensor(4.9211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1271 loss: tensor(4.9131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1272 loss: tensor(4.9050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1273 loss: tensor(4.8970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1274 loss: tensor(4.8889, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1275 loss: tensor(4.8808, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1276 loss: tensor(4.8728, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1277 loss: tensor(4.8646, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1278 loss: tensor(4.8562, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1279 loss: tensor(4.8477, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1280 loss: tensor(4.8392, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1281 loss: tensor(4.8307, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1282 loss: tensor(4.8222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1283 loss: tensor(4.8137, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1284 loss: tensor(4.8054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1285 loss: tensor(4.7970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1286 loss: tensor(4.7886, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1287 loss: tensor(4.7802, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1288 loss: tensor(4.7718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1289 loss: tensor(4.7634, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1290 loss: tensor(4.7549, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1291 loss: tensor(4.7464, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1292 loss: tensor(4.7377, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1293 loss: tensor(4.7291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1294 loss: tensor(4.7207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1295 loss: tensor(4.7123, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1296 loss: tensor(4.7039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1297 loss: tensor(4.6955, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1298 loss: tensor(4.6871, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1299 loss: tensor(4.6787, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1300 loss: tensor(4.6704, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1301 loss: tensor(4.6620, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1302 loss: tensor(4.6538, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1303 loss: tensor(4.6455, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1304 loss: tensor(4.6373, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1305 loss: tensor(4.6290, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1306 loss: tensor(4.6207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1307 loss: tensor(4.6121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1308 loss: tensor(4.6035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1309 loss: tensor(4.5947, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1310 loss: tensor(4.5860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1311 loss: tensor(4.5772, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1312 loss: tensor(4.5685, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1313 loss: tensor(4.5599, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1314 loss: tensor(4.5512, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1315 loss: tensor(4.5423, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1316 loss: tensor(4.5334, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1317 loss: tensor(4.5244, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1318 loss: tensor(4.5156, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1319 loss: tensor(4.5070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1320 loss: tensor(4.4984, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1321 loss: tensor(4.4899, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1322 loss: tensor(4.4813, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1323 loss: tensor(4.4726, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1324 loss: tensor(4.4639, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1325 loss: tensor(4.4552, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1326 loss: tensor(4.4466, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1327 loss: tensor(4.4381, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1328 loss: tensor(4.4296, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1329 loss: tensor(4.4211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1330 loss: tensor(4.4125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1331 loss: tensor(4.4039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1332 loss: tensor(4.3953, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1333 loss: tensor(4.3866, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1334 loss: tensor(4.3780, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1335 loss: tensor(4.3693, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1336 loss: tensor(4.3607, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1337 loss: tensor(4.3522, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1338 loss: tensor(4.3437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1339 loss: tensor(4.3354, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1340 loss: tensor(4.3271, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1341 loss: tensor(4.3188, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1342 loss: tensor(4.3105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1343 loss: tensor(4.3020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1344 loss: tensor(4.2936, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1345 loss: tensor(4.2852, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1346 loss: tensor(4.2769, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1347 loss: tensor(4.2686, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1348 loss: tensor(4.2602, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1349 loss: tensor(4.2519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1350 loss: tensor(4.2434, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1351 loss: tensor(4.2349, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1352 loss: tensor(4.2263, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1353 loss: tensor(4.2177, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1354 loss: tensor(4.2091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1355 loss: tensor(4.2004, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1356 loss: tensor(4.1917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1357 loss: tensor(4.1830, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1358 loss: tensor(4.1743, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1359 loss: tensor(4.1657, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1360 loss: tensor(4.1572, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1361 loss: tensor(4.1488, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1362 loss: tensor(4.1403, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1363 loss: tensor(4.1319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1364 loss: tensor(4.1234, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1365 loss: tensor(4.1149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1366 loss: tensor(4.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1367 loss: tensor(4.0975, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1368 loss: tensor(4.0887, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1369 loss: tensor(4.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1370 loss: tensor(4.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1371 loss: tensor(4.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1372 loss: tensor(4.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1373 loss: tensor(4.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1374 loss: tensor(4.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1375 loss: tensor(4.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1376 loss: tensor(4.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1377 loss: tensor(4.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1378 loss: tensor(3.9995, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1379 loss: tensor(3.9904, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1380 loss: tensor(3.9811, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1381 loss: tensor(3.9719, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1382 loss: tensor(3.9627, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1383 loss: tensor(3.9535, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1384 loss: tensor(3.9444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1385 loss: tensor(3.9351, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1386 loss: tensor(3.9258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1387 loss: tensor(3.9164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1388 loss: tensor(3.9070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1389 loss: tensor(3.8975, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1390 loss: tensor(3.8880, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1391 loss: tensor(3.8785, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1392 loss: tensor(3.8689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1393 loss: tensor(3.8594, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1394 loss: tensor(3.8499, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1395 loss: tensor(3.8404, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1396 loss: tensor(3.8308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1397 loss: tensor(3.8212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1398 loss: tensor(3.8116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1399 loss: tensor(3.8019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1400 loss: tensor(3.7921, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1401 loss: tensor(3.7822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1402 loss: tensor(3.7723, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1403 loss: tensor(3.7622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1404 loss: tensor(3.7519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1405 loss: tensor(3.7415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1406 loss: tensor(3.7310, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1407 loss: tensor(3.7204, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1408 loss: tensor(3.7098, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1409 loss: tensor(3.6991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1410 loss: tensor(3.6884, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1411 loss: tensor(3.6779, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1412 loss: tensor(3.6677, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1413 loss: tensor(3.6577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1414 loss: tensor(3.6478, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1415 loss: tensor(3.6380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1416 loss: tensor(3.6282, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1417 loss: tensor(3.6185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1418 loss: tensor(3.6087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1419 loss: tensor(3.5988, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1420 loss: tensor(3.5888, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1421 loss: tensor(3.5785, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1422 loss: tensor(3.5682, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1423 loss: tensor(3.5577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1424 loss: tensor(3.5472, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1425 loss: tensor(3.5367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1426 loss: tensor(3.5261, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1427 loss: tensor(3.5155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1428 loss: tensor(3.5050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1429 loss: tensor(3.4946, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1430 loss: tensor(3.4843, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1431 loss: tensor(3.4742, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1432 loss: tensor(3.4642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1433 loss: tensor(3.4543, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1434 loss: tensor(3.4443, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1435 loss: tensor(3.4343, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1436 loss: tensor(3.4242, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1437 loss: tensor(3.4139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1438 loss: tensor(3.4035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1439 loss: tensor(3.3931, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1440 loss: tensor(3.3827, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1441 loss: tensor(3.3724, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1442 loss: tensor(3.3621, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1443 loss: tensor(3.3518, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1444 loss: tensor(3.3415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1445 loss: tensor(3.3311, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1446 loss: tensor(3.3207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1447 loss: tensor(3.3105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1448 loss: tensor(3.3005, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1449 loss: tensor(3.2906, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1450 loss: tensor(3.2809, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1451 loss: tensor(3.2712, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1452 loss: tensor(3.2616, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1453 loss: tensor(3.2519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1454 loss: tensor(3.2423, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1455 loss: tensor(3.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1456 loss: tensor(3.2231, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1457 loss: tensor(3.2135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1458 loss: tensor(3.2039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1459 loss: tensor(3.1943, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1460 loss: tensor(3.1846, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1461 loss: tensor(3.1749, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1462 loss: tensor(3.1653, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1463 loss: tensor(3.1557, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1464 loss: tensor(3.1461, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1465 loss: tensor(3.1364, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1466 loss: tensor(3.1266, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1467 loss: tensor(3.1168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1468 loss: tensor(3.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1469 loss: tensor(3.0967, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1470 loss: tensor(3.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1471 loss: tensor(3.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1472 loss: tensor(3.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1473 loss: tensor(3.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1474 loss: tensor(3.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1475 loss: tensor(3.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1476 loss: tensor(3.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1477 loss: tensor(3.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1478 loss: tensor(3.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1479 loss: tensor(2.9986, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1480 loss: tensor(2.9892, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1481 loss: tensor(2.9799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1482 loss: tensor(2.9706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1483 loss: tensor(2.9611, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1484 loss: tensor(2.9514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1485 loss: tensor(2.9415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1486 loss: tensor(2.9313, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1487 loss: tensor(2.9212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1488 loss: tensor(2.9113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1489 loss: tensor(2.9021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1490 loss: tensor(2.8931, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1491 loss: tensor(2.8842, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1492 loss: tensor(2.8752, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1493 loss: tensor(2.8662, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1494 loss: tensor(2.8572, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1495 loss: tensor(2.8483, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1496 loss: tensor(2.8394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1497 loss: tensor(2.8306, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1498 loss: tensor(2.8218, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1499 loss: tensor(2.8129, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1500 loss: tensor(2.8041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1501 loss: tensor(2.7952, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1502 loss: tensor(2.7864, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1503 loss: tensor(2.7777, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1504 loss: tensor(2.7690, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1505 loss: tensor(2.7602, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1506 loss: tensor(2.7514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1507 loss: tensor(2.7428, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1508 loss: tensor(2.7343, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1509 loss: tensor(2.7258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1510 loss: tensor(2.7173, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1511 loss: tensor(2.7088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1512 loss: tensor(2.7002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1513 loss: tensor(2.6917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1514 loss: tensor(2.6832, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1515 loss: tensor(2.6746, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1516 loss: tensor(2.6661, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1517 loss: tensor(2.6576, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1518 loss: tensor(2.6491, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1519 loss: tensor(2.6405, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1520 loss: tensor(2.6319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1521 loss: tensor(2.6233, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1522 loss: tensor(2.6147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1523 loss: tensor(2.6061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1524 loss: tensor(2.5976, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1525 loss: tensor(2.5890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1526 loss: tensor(2.5805, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1527 loss: tensor(2.5718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1528 loss: tensor(2.5633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1529 loss: tensor(2.5548, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1530 loss: tensor(2.5463, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1531 loss: tensor(2.5378, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1532 loss: tensor(2.5294, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1533 loss: tensor(2.5210, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1534 loss: tensor(2.5125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1535 loss: tensor(2.5041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1536 loss: tensor(2.4957, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1537 loss: tensor(2.4874, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1538 loss: tensor(2.4790, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1539 loss: tensor(2.4708, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1540 loss: tensor(2.4625, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1541 loss: tensor(2.4542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1542 loss: tensor(2.4459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1543 loss: tensor(2.4376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1544 loss: tensor(2.4291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1545 loss: tensor(2.4205, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1546 loss: tensor(2.4119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1547 loss: tensor(2.4031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1548 loss: tensor(2.3943, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1549 loss: tensor(2.3854, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1550 loss: tensor(2.3764, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1551 loss: tensor(2.3675, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1552 loss: tensor(2.3585, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1553 loss: tensor(2.3496, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1554 loss: tensor(2.3407, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1555 loss: tensor(2.3318, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1556 loss: tensor(2.3229, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1557 loss: tensor(2.3141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1558 loss: tensor(2.3052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1559 loss: tensor(2.2963, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1560 loss: tensor(2.2874, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1561 loss: tensor(2.2785, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1562 loss: tensor(2.2698, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1563 loss: tensor(2.2611, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1564 loss: tensor(2.2525, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1565 loss: tensor(2.2440, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1566 loss: tensor(2.2355, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1567 loss: tensor(2.2271, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1568 loss: tensor(2.2187, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1569 loss: tensor(2.2104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1570 loss: tensor(2.2020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1571 loss: tensor(2.1937, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1572 loss: tensor(2.1854, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1573 loss: tensor(2.1772, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1574 loss: tensor(2.1689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1575 loss: tensor(2.1607, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1576 loss: tensor(2.1526, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1577 loss: tensor(2.1445, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1578 loss: tensor(2.1364, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1579 loss: tensor(2.1283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1580 loss: tensor(2.1202, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1581 loss: tensor(2.1121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1582 loss: tensor(2.1040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1583 loss: tensor(2.0958, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1584 loss: tensor(2.0877, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1585 loss: tensor(2.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1586 loss: tensor(2.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1587 loss: tensor(2.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1588 loss: tensor(2.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1589 loss: tensor(2.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1590 loss: tensor(2.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1591 loss: tensor(2.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1592 loss: tensor(2.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1593 loss: tensor(2.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1594 loss: tensor(2.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1595 loss: tensor(1.9993, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1596 loss: tensor(1.9910, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1597 loss: tensor(1.9825, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1598 loss: tensor(1.9739, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1599 loss: tensor(1.9653, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1600 loss: tensor(1.9566, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1601 loss: tensor(1.9478, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1602 loss: tensor(1.9387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1603 loss: tensor(1.9297, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1604 loss: tensor(1.9209, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1605 loss: tensor(1.9122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1606 loss: tensor(1.9036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1607 loss: tensor(1.8951, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1608 loss: tensor(1.8865, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1609 loss: tensor(1.8780, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1610 loss: tensor(1.8695, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1611 loss: tensor(1.8610, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1612 loss: tensor(1.8524, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1613 loss: tensor(1.8439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1614 loss: tensor(1.8353, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1615 loss: tensor(1.8267, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1616 loss: tensor(1.8181, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1617 loss: tensor(1.8095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1618 loss: tensor(1.8011, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1619 loss: tensor(1.7927, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1620 loss: tensor(1.7842, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1621 loss: tensor(1.7758, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1622 loss: tensor(1.7673, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1623 loss: tensor(1.7588, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1624 loss: tensor(1.7503, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1625 loss: tensor(1.7417, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1626 loss: tensor(1.7332, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1627 loss: tensor(1.7247, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1628 loss: tensor(1.7163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1629 loss: tensor(1.7081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1630 loss: tensor(1.6999, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1631 loss: tensor(1.6916, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1632 loss: tensor(1.6832, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1633 loss: tensor(1.6747, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1634 loss: tensor(1.6661, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1635 loss: tensor(1.6575, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1636 loss: tensor(1.6490, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1637 loss: tensor(1.6407, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1638 loss: tensor(1.6324, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1639 loss: tensor(1.6243, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1640 loss: tensor(1.6162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1641 loss: tensor(1.6082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1642 loss: tensor(1.6001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1643 loss: tensor(1.5920, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1644 loss: tensor(1.5839, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1645 loss: tensor(1.5757, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1646 loss: tensor(1.5676, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1647 loss: tensor(1.5595, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1648 loss: tensor(1.5515, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1649 loss: tensor(1.5435, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1650 loss: tensor(1.5355, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1651 loss: tensor(1.5274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1652 loss: tensor(1.5192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1653 loss: tensor(1.5111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1654 loss: tensor(1.5030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1655 loss: tensor(1.4949, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1656 loss: tensor(1.4869, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1657 loss: tensor(1.4788, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1658 loss: tensor(1.4708, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1659 loss: tensor(1.4627, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1660 loss: tensor(1.4548, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1661 loss: tensor(1.4468, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1662 loss: tensor(1.4389, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1663 loss: tensor(1.4310, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1664 loss: tensor(1.4231, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1665 loss: tensor(1.4152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1666 loss: tensor(1.4072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1667 loss: tensor(1.3991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1668 loss: tensor(1.3911, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1669 loss: tensor(1.3832, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1670 loss: tensor(1.3752, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1671 loss: tensor(1.3673, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1672 loss: tensor(1.3594, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1673 loss: tensor(1.3515, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1674 loss: tensor(1.3437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1675 loss: tensor(1.3360, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1676 loss: tensor(1.3282, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1677 loss: tensor(1.3203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1678 loss: tensor(1.3121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1679 loss: tensor(1.3039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1680 loss: tensor(1.2957, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1681 loss: tensor(1.2879, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1682 loss: tensor(1.2801, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1683 loss: tensor(1.2725, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1684 loss: tensor(1.2649, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1685 loss: tensor(1.2574, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1686 loss: tensor(1.2499, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1687 loss: tensor(1.2424, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1688 loss: tensor(1.2349, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1689 loss: tensor(1.2274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1690 loss: tensor(1.2199, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1691 loss: tensor(1.2124, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1692 loss: tensor(1.2050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1693 loss: tensor(1.1978, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1694 loss: tensor(1.1908, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1695 loss: tensor(1.1840, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1696 loss: tensor(1.1774, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1697 loss: tensor(1.1708, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1698 loss: tensor(1.1643, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1699 loss: tensor(1.1578, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1700 loss: tensor(1.1514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1701 loss: tensor(1.1450, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1702 loss: tensor(1.1387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1703 loss: tensor(1.1323, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1704 loss: tensor(1.1261, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1705 loss: tensor(1.1199, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1706 loss: tensor(1.1138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1707 loss: tensor(1.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1708 loss: tensor(1.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1709 loss: tensor(1.0958, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1710 loss: tensor(1.0899, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1711 loss: tensor(1.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1712 loss: tensor(1.0783, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1713 loss: tensor(1.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1714 loss: tensor(1.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1715 loss: tensor(1.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1716 loss: tensor(1.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1717 loss: tensor(1.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1718 loss: tensor(1.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1719 loss: tensor(1.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1720 loss: tensor(1.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1721 loss: tensor(1.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1722 loss: tensor(1.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1723 loss: tensor(1.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1724 loss: tensor(1.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1725 loss: tensor(1.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1726 loss: tensor(0.9967, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1727 loss: tensor(0.9910, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1728 loss: tensor(0.9854, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1729 loss: tensor(0.9799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1730 loss: tensor(0.9743, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1731 loss: tensor(0.9688, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1732 loss: tensor(0.9632, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1733 loss: tensor(0.9577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1734 loss: tensor(0.9522, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1735 loss: tensor(0.9467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1736 loss: tensor(0.9414, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1737 loss: tensor(0.9361, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1738 loss: tensor(0.9308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1739 loss: tensor(0.9256, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1740 loss: tensor(0.9204, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1741 loss: tensor(0.9153, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1742 loss: tensor(0.9102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1743 loss: tensor(0.9051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1744 loss: tensor(0.9000, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1745 loss: tensor(0.8950, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1746 loss: tensor(0.8901, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1747 loss: tensor(0.8852, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1748 loss: tensor(0.8803, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1749 loss: tensor(0.8754, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1750 loss: tensor(0.8706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1751 loss: tensor(0.8658, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1752 loss: tensor(0.8610, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1753 loss: tensor(0.8563, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1754 loss: tensor(0.8517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1755 loss: tensor(0.8472, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1756 loss: tensor(0.8430, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1757 loss: tensor(0.8390, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1758 loss: tensor(0.8351, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1759 loss: tensor(0.8307, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1760 loss: tensor(0.8254, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1761 loss: tensor(0.8195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1762 loss: tensor(0.8140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1763 loss: tensor(0.8097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1764 loss: tensor(0.8060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1765 loss: tensor(0.8019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1766 loss: tensor(0.7970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1767 loss: tensor(0.7917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1768 loss: tensor(0.7871, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1769 loss: tensor(0.7831, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1770 loss: tensor(0.7791, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1771 loss: tensor(0.7746, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1772 loss: tensor(0.7697, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1773 loss: tensor(0.7651, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1774 loss: tensor(0.7610, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1775 loss: tensor(0.7569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1776 loss: tensor(0.7526, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1777 loss: tensor(0.7479, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1778 loss: tensor(0.7432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1779 loss: tensor(0.7387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1780 loss: tensor(0.7344, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1781 loss: tensor(0.7299, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1782 loss: tensor(0.7253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1783 loss: tensor(0.7207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1784 loss: tensor(0.7162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1785 loss: tensor(0.7119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1786 loss: tensor(0.7077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1787 loss: tensor(0.7034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1788 loss: tensor(0.6991, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1789 loss: tensor(0.6949, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1790 loss: tensor(0.6907, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1791 loss: tensor(0.6866, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1792 loss: tensor(0.6826, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1793 loss: tensor(0.6785, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1794 loss: tensor(0.6744, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1795 loss: tensor(0.6703, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1796 loss: tensor(0.6662, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1797 loss: tensor(0.6622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1798 loss: tensor(0.6582, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1799 loss: tensor(0.6541, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1800 loss: tensor(0.6501, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1801 loss: tensor(0.6461, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1802 loss: tensor(0.6421, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1803 loss: tensor(0.6381, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1804 loss: tensor(0.6342, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1805 loss: tensor(0.6303, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1806 loss: tensor(0.6265, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1807 loss: tensor(0.6227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1808 loss: tensor(0.6189, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1809 loss: tensor(0.6152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1810 loss: tensor(0.6114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1811 loss: tensor(0.6076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1812 loss: tensor(0.6039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1813 loss: tensor(0.6002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1814 loss: tensor(0.5965, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1815 loss: tensor(0.5929, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1816 loss: tensor(0.5893, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1817 loss: tensor(0.5857, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1818 loss: tensor(0.5821, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1819 loss: tensor(0.5786, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1820 loss: tensor(0.5751, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1821 loss: tensor(0.5716, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1822 loss: tensor(0.5682, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1823 loss: tensor(0.5647, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1824 loss: tensor(0.5613, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1825 loss: tensor(0.5578, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1826 loss: tensor(0.5544, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1827 loss: tensor(0.5510, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1828 loss: tensor(0.5477, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1829 loss: tensor(0.5444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1830 loss: tensor(0.5412, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1831 loss: tensor(0.5382, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1832 loss: tensor(0.5353, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1833 loss: tensor(0.5327, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1834 loss: tensor(0.5304, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1835 loss: tensor(0.5284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1836 loss: tensor(0.5262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1837 loss: tensor(0.5232, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1838 loss: tensor(0.5187, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1839 loss: tensor(0.5136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1840 loss: tensor(0.5097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1841 loss: tensor(0.5074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1842 loss: tensor(0.5055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1843 loss: tensor(0.5027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1844 loss: tensor(0.4988, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1845 loss: tensor(0.4947, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1846 loss: tensor(0.4917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1847 loss: tensor(0.4894, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1848 loss: tensor(0.4868, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1849 loss: tensor(0.4834, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1850 loss: tensor(0.4799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1851 loss: tensor(0.4768, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1852 loss: tensor(0.4743, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1853 loss: tensor(0.4718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1854 loss: tensor(0.4688, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1855 loss: tensor(0.4656, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1856 loss: tensor(0.4626, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1857 loss: tensor(0.4600, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1858 loss: tensor(0.4575, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1859 loss: tensor(0.4547, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1860 loss: tensor(0.4518, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1861 loss: tensor(0.4489, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1862 loss: tensor(0.4463, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1863 loss: tensor(0.4437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1864 loss: tensor(0.4411, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1865 loss: tensor(0.4384, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1866 loss: tensor(0.4357, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1867 loss: tensor(0.4330, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1868 loss: tensor(0.4305, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1869 loss: tensor(0.4281, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1870 loss: tensor(0.4255, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1871 loss: tensor(0.4229, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1872 loss: tensor(0.4203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1873 loss: tensor(0.4177, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1874 loss: tensor(0.4152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1875 loss: tensor(0.4128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1876 loss: tensor(0.4103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1877 loss: tensor(0.4079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1878 loss: tensor(0.4054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1879 loss: tensor(0.4029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1880 loss: tensor(0.4005, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1881 loss: tensor(0.3981, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1882 loss: tensor(0.3958, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1883 loss: tensor(0.3934, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1884 loss: tensor(0.3911, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1885 loss: tensor(0.3888, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1886 loss: tensor(0.3865, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1887 loss: tensor(0.3842, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1888 loss: tensor(0.3820, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1889 loss: tensor(0.3797, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1890 loss: tensor(0.3775, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1891 loss: tensor(0.3753, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1892 loss: tensor(0.3731, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1893 loss: tensor(0.3709, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1894 loss: tensor(0.3688, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1895 loss: tensor(0.3666, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1896 loss: tensor(0.3645, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1897 loss: tensor(0.3624, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1898 loss: tensor(0.3603, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1899 loss: tensor(0.3582, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1900 loss: tensor(0.3561, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1901 loss: tensor(0.3540, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1902 loss: tensor(0.3520, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1903 loss: tensor(0.3499, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1904 loss: tensor(0.3479, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1905 loss: tensor(0.3459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1906 loss: tensor(0.3439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1907 loss: tensor(0.3419, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1908 loss: tensor(0.3399, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1909 loss: tensor(0.3379, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1910 loss: tensor(0.3359, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1911 loss: tensor(0.3339, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1912 loss: tensor(0.3320, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1913 loss: tensor(0.3300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1914 loss: tensor(0.3281, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1915 loss: tensor(0.3261, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1916 loss: tensor(0.3242, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1917 loss: tensor(0.3222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1918 loss: tensor(0.3203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1919 loss: tensor(0.3183, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1920 loss: tensor(0.3164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1921 loss: tensor(0.3145, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1922 loss: tensor(0.3126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1923 loss: tensor(0.3106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1924 loss: tensor(0.3087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1925 loss: tensor(0.3068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1926 loss: tensor(0.3049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1927 loss: tensor(0.3030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1928 loss: tensor(0.3011, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1929 loss: tensor(0.2992, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1930 loss: tensor(0.2974, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1931 loss: tensor(0.2956, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1932 loss: tensor(0.2938, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1933 loss: tensor(0.2921, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1934 loss: tensor(0.2905, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1935 loss: tensor(0.2891, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1936 loss: tensor(0.2880, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1937 loss: tensor(0.2876, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1938 loss: tensor(0.2883, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1939 loss: tensor(0.2902, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1940 loss: tensor(0.2917, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1941 loss: tensor(0.2890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1942 loss: tensor(0.2815, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1943 loss: tensor(0.2758, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1944 loss: tensor(0.2763, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1945 loss: tensor(0.2785, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1946 loss: tensor(0.2761, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1947 loss: tensor(0.2707, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1948 loss: tensor(0.2688, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1949 loss: tensor(0.2701, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1950 loss: tensor(0.2689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1951 loss: tensor(0.2649, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1952 loss: tensor(0.2629, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1953 loss: tensor(0.2633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1954 loss: tensor(0.2622, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1955 loss: tensor(0.2591, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1956 loss: tensor(0.2574, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1957 loss: tensor(0.2572, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1958 loss: tensor(0.2559, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1959 loss: tensor(0.2533, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1960 loss: tensor(0.2519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1961 loss: tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1962 loss: tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1963 loss: tensor(0.2479, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1964 loss: tensor(0.2467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1965 loss: tensor(0.2459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1966 loss: tensor(0.2445, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1967 loss: tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1968 loss: tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1969 loss: tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1970 loss: tensor(0.2392, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1971 loss: tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1972 loss: tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1973 loss: tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1974 loss: tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1975 loss: tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1976 loss: tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1977 loss: tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1978 loss: tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1979 loss: tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1980 loss: tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1981 loss: tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1982 loss: tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1983 loss: tensor(0.2231, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1984 loss: tensor(0.2220, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1985 loss: tensor(0.2209, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1986 loss: tensor(0.2197, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1987 loss: tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1988 loss: tensor(0.2173, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1989 loss: tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1990 loss: tensor(0.2151, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1991 loss: tensor(0.2140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1992 loss: tensor(0.2129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1993 loss: tensor(0.2118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1994 loss: tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1995 loss: tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1996 loss: tensor(0.2085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1997 loss: tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1998 loss: tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1999 loss: tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2000 loss: tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2001 loss: tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2002 loss: tensor(0.2020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2003 loss: tensor(0.2009, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2004 loss: tensor(0.1999, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2005 loss: tensor(0.1988, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2006 loss: tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2007 loss: tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2008 loss: tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2009 loss: tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2010 loss: tensor(0.1938, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2011 loss: tensor(0.1929, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2012 loss: tensor(0.1919, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2013 loss: tensor(0.1909, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2014 loss: tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2015 loss: tensor(0.1890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2016 loss: tensor(0.1881, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2017 loss: tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2018 loss: tensor(0.1863, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2019 loss: tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2020 loss: tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2021 loss: tensor(0.1835, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2022 loss: tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2023 loss: tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2024 loss: tensor(0.1808, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2025 loss: tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2026 loss: tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2027 loss: tensor(0.1782, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2028 loss: tensor(0.1773, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2029 loss: tensor(0.1764, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2030 loss: tensor(0.1756, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2031 loss: tensor(0.1747, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2032 loss: tensor(0.1739, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2033 loss: tensor(0.1730, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2034 loss: tensor(0.1722, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2035 loss: tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2036 loss: tensor(0.1705, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2037 loss: tensor(0.1697, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2038 loss: tensor(0.1689, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2039 loss: tensor(0.1681, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2040 loss: tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2041 loss: tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2042 loss: tensor(0.1656, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2043 loss: tensor(0.1649, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2044 loss: tensor(0.1641, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2045 loss: tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2046 loss: tensor(0.1625, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2047 loss: tensor(0.1617, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2048 loss: tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2049 loss: tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2050 loss: tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2051 loss: tensor(0.1585, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2052 loss: tensor(0.1577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2053 loss: tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2054 loss: tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2055 loss: tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2056 loss: tensor(0.1545, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2057 loss: tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2058 loss: tensor(0.1529, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2059 loss: tensor(0.1521, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2060 loss: tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2061 loss: tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2062 loss: tensor(0.1497, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2063 loss: tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2064 loss: tensor(0.1482, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2065 loss: tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2066 loss: tensor(0.1467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2067 loss: tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2068 loss: tensor(0.1452, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2069 loss: tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2070 loss: tensor(0.1437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2071 loss: tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2072 loss: tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2073 loss: tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2074 loss: tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2075 loss: tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2076 loss: tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2077 loss: tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2078 loss: tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2079 loss: tensor(0.1373, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2080 loss: tensor(0.1367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2081 loss: tensor(0.1360, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2082 loss: tensor(0.1354, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2083 loss: tensor(0.1348, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2084 loss: tensor(0.1342, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2085 loss: tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2086 loss: tensor(0.1329, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2087 loss: tensor(0.1323, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2088 loss: tensor(0.1317, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2089 loss: tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2090 loss: tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2091 loss: tensor(0.1300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2092 loss: tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2093 loss: tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2094 loss: tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2095 loss: tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2096 loss: tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2097 loss: tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2098 loss: tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2099 loss: tensor(0.1255, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2100 loss: tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2101 loss: tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2102 loss: tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2103 loss: tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2104 loss: tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2105 loss: tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2106 loss: tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2107 loss: tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2108 loss: tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2109 loss: tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2110 loss: tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2111 loss: tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2112 loss: tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2113 loss: tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2114 loss: tensor(0.1178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2115 loss: tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2116 loss: tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2117 loss: tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2118 loss: tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2119 loss: tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2120 loss: tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2121 loss: tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2122 loss: tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2123 loss: tensor(0.1142, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2124 loss: tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2125 loss: tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2126 loss: tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2127 loss: tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2128 loss: tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2129 loss: tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2130 loss: tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2131 loss: tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2132 loss: tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2133 loss: tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2134 loss: tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2135 loss: tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2136 loss: tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2137 loss: tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2138 loss: tensor(0.1080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2139 loss: tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2140 loss: tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2141 loss: tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2142 loss: tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2143 loss: tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2144 loss: tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2145 loss: tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2146 loss: tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2147 loss: tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2148 loss: tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2149 loss: tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2150 loss: tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2151 loss: tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2152 loss: tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2153 loss: tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2154 loss: tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2155 loss: tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2156 loss: tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2157 loss: tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2158 loss: tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2159 loss: tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2160 loss: tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2161 loss: tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2162 loss: tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2163 loss: tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2164 loss: tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2165 loss: tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2166 loss: tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2167 loss: tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2168 loss: tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2169 loss: tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2170 loss: tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2171 loss: tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2172 loss: tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2173 loss: tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2174 loss: tensor(0.0943, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2175 loss: tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2176 loss: tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2177 loss: tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2178 loss: tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2179 loss: tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2180 loss: tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2181 loss: tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2182 loss: tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2183 loss: tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2184 loss: tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2185 loss: tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2186 loss: tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2187 loss: tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2188 loss: tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2189 loss: tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2190 loss: tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2191 loss: tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2192 loss: tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2193 loss: tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2194 loss: tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2195 loss: tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2196 loss: tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2197 loss: tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2198 loss: tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2199 loss: tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2200 loss: tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2201 loss: tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2202 loss: tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2203 loss: tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2204 loss: tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2205 loss: tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2206 loss: tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2207 loss: tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2208 loss: tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2209 loss: tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2210 loss: tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2211 loss: tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2212 loss: tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2213 loss: tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2214 loss: tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2215 loss: tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2216 loss: tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2217 loss: tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2218 loss: tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2219 loss: tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2220 loss: tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2221 loss: tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2222 loss: tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2223 loss: tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2224 loss: tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2225 loss: tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2226 loss: tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2227 loss: tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2228 loss: tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2229 loss: tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2230 loss: tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2231 loss: tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2232 loss: tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2233 loss: tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2234 loss: tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2235 loss: tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2236 loss: tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2237 loss: tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2238 loss: tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2239 loss: tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2240 loss: tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2241 loss: tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2242 loss: tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2243 loss: tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2244 loss: tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2245 loss: tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2246 loss: tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2247 loss: tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2248 loss: tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2249 loss: tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2250 loss: tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2251 loss: tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2252 loss: tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2253 loss: tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2254 loss: tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2255 loss: tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2256 loss: tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2257 loss: tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2258 loss: tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2259 loss: tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2260 loss: tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2261 loss: tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2262 loss: tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2263 loss: tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2264 loss: tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2265 loss: tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2266 loss: tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2267 loss: tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2268 loss: tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2269 loss: tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2270 loss: tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2271 loss: tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2272 loss: tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2273 loss: tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2274 loss: tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2275 loss: tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2276 loss: tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2277 loss: tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2278 loss: tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2279 loss: tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2280 loss: tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2281 loss: tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2282 loss: tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2283 loss: tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2284 loss: tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2285 loss: tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2286 loss: tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2287 loss: tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2288 loss: tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2289 loss: tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2290 loss: tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2291 loss: tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2292 loss: tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2293 loss: tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2294 loss: tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2295 loss: tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2296 loss: tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2297 loss: tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2298 loss: tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2299 loss: tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2300 loss: tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2301 loss: tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2302 loss: tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2303 loss: tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2304 loss: tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2305 loss: tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2306 loss: tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2307 loss: tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2308 loss: tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2309 loss: tensor(0.0622, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2310 loss: tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2311 loss: tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2312 loss: tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2313 loss: tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2314 loss: tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2315 loss: tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2316 loss: tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2317 loss: tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2318 loss: tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2319 loss: tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2320 loss: tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2321 loss: tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2322 loss: tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2323 loss: tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2324 loss: tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2325 loss: tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2326 loss: tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2327 loss: tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2328 loss: tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2329 loss: tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2330 loss: tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2331 loss: tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2332 loss: tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2333 loss: tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2334 loss: tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2335 loss: tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2336 loss: tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2337 loss: tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2338 loss: tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2339 loss: tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2340 loss: tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2341 loss: tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2342 loss: tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2343 loss: tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2344 loss: tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2345 loss: tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2346 loss: tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2347 loss: tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2348 loss: tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2349 loss: tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2350 loss: tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2351 loss: tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2352 loss: tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2353 loss: tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2354 loss: tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2355 loss: tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2356 loss: tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2357 loss: tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2358 loss: tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2359 loss: tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2360 loss: tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2361 loss: tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2362 loss: tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2363 loss: tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2364 loss: tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2365 loss: tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2366 loss: tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2367 loss: tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2368 loss: tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2369 loss: tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2370 loss: tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2371 loss: tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2372 loss: tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2373 loss: tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2374 loss: tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2375 loss: tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2376 loss: tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2377 loss: tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2378 loss: tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2379 loss: tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2380 loss: tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2381 loss: tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2382 loss: tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2383 loss: tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2384 loss: tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2385 loss: tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2386 loss: tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2387 loss: tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2388 loss: tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2389 loss: tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2390 loss: tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2391 loss: tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2392 loss: tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2393 loss: tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2394 loss: tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2395 loss: tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2396 loss: tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2397 loss: tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2398 loss: tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2399 loss: tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2400 loss: tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2401 loss: tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2402 loss: tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2403 loss: tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2404 loss: tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2405 loss: tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2406 loss: tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2407 loss: tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2408 loss: tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2409 loss: tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2410 loss: tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2411 loss: tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2412 loss: tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2413 loss: tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2414 loss: tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2415 loss: tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2416 loss: tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2417 loss: tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2418 loss: tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2419 loss: tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2420 loss: tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2421 loss: tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2422 loss: tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2423 loss: tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2424 loss: tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2425 loss: tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2426 loss: tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2427 loss: tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2428 loss: tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2429 loss: tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2430 loss: tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2431 loss: tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2432 loss: tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2433 loss: tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2434 loss: tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2435 loss: tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2436 loss: tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2437 loss: tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2438 loss: tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2439 loss: tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2440 loss: tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2441 loss: tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2442 loss: tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2443 loss: tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2444 loss: tensor(0.0433, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2445 loss: tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2446 loss: tensor(0.0431, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2447 loss: tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2448 loss: tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2449 loss: tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2450 loss: tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2451 loss: tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2452 loss: tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2453 loss: tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2454 loss: tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2455 loss: tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2456 loss: tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2457 loss: tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2458 loss: tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2459 loss: tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2460 loss: tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2461 loss: tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2462 loss: tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2463 loss: tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2464 loss: tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2465 loss: tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2466 loss: tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2467 loss: tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2468 loss: tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2469 loss: tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2470 loss: tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2471 loss: tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2472 loss: tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2473 loss: tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2474 loss: tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2475 loss: tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2476 loss: tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2477 loss: tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2478 loss: tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2479 loss: tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2480 loss: tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2481 loss: tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2482 loss: tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2483 loss: tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2484 loss: tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2485 loss: tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2486 loss: tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2487 loss: tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2488 loss: tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2489 loss: tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2490 loss: tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2491 loss: tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2492 loss: tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2493 loss: tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2494 loss: tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2495 loss: tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2496 loss: tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2497 loss: tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2498 loss: tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2499 loss: tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2500 loss: tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2501 loss: tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2502 loss: tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2503 loss: tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2504 loss: tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2505 loss: tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2506 loss: tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2507 loss: tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2508 loss: tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2509 loss: tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2510 loss: tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2511 loss: tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2512 loss: tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2513 loss: tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2514 loss: tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2515 loss: tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2516 loss: tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2517 loss: tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2518 loss: tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2519 loss: tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2520 loss: tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2521 loss: tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2522 loss: tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2523 loss: tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2524 loss: tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2525 loss: tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2526 loss: tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2527 loss: tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2528 loss: tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2529 loss: tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2530 loss: tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2531 loss: tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2532 loss: tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2533 loss: tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2534 loss: tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2535 loss: tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2536 loss: tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2537 loss: tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2538 loss: tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2539 loss: tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2540 loss: tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2541 loss: tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2542 loss: tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2543 loss: tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2544 loss: tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2545 loss: tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2546 loss: tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2547 loss: tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2548 loss: tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2549 loss: tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2550 loss: tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2551 loss: tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2552 loss: tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2553 loss: tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2554 loss: tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2555 loss: tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2556 loss: tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2557 loss: tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2558 loss: tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2559 loss: tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2560 loss: tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2561 loss: tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2562 loss: tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2563 loss: tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2564 loss: tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2565 loss: tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2566 loss: tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2567 loss: tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2568 loss: tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2569 loss: tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2570 loss: tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2571 loss: tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2572 loss: tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2573 loss: tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2574 loss: tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2575 loss: tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2576 loss: tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2577 loss: tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2578 loss: tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2579 loss: tensor(0.0313, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2580 loss: tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2581 loss: tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2582 loss: tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2583 loss: tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2584 loss: tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2585 loss: tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2586 loss: tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2587 loss: tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2588 loss: tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2589 loss: tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2590 loss: tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2591 loss: tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2592 loss: tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2593 loss: tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2594 loss: tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2595 loss: tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2596 loss: tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2597 loss: tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2598 loss: tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2599 loss: tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2600 loss: tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2601 loss: tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2602 loss: tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2603 loss: tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2604 loss: tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2605 loss: tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2606 loss: tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2607 loss: tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2608 loss: tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2609 loss: tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2610 loss: tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2611 loss: tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2612 loss: tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2613 loss: tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2614 loss: tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2615 loss: tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2616 loss: tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2617 loss: tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2618 loss: tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2619 loss: tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2620 loss: tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2621 loss: tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2622 loss: tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2623 loss: tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2624 loss: tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2625 loss: tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2626 loss: tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2627 loss: tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2628 loss: tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2629 loss: tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2630 loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2631 loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2632 loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2633 loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2634 loss: tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2635 loss: tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2636 loss: tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2637 loss: tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2638 loss: tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2639 loss: tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2640 loss: tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2641 loss: tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2642 loss: tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2643 loss: tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2644 loss: tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2645 loss: tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2646 loss: tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2647 loss: tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2648 loss: tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2649 loss: tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2650 loss: tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2651 loss: tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2652 loss: tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2653 loss: tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2654 loss: tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2655 loss: tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2656 loss: tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2657 loss: tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2658 loss: tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2659 loss: tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2660 loss: tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2661 loss: tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2662 loss: tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2663 loss: tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2664 loss: tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2665 loss: tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2666 loss: tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2667 loss: tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2668 loss: tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2669 loss: tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2670 loss: tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2671 loss: tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2672 loss: tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2673 loss: tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2674 loss: tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2675 loss: tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2676 loss: tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2677 loss: tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2678 loss: tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2679 loss: tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2680 loss: tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2681 loss: tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2682 loss: tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2683 loss: tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2684 loss: tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2685 loss: tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2686 loss: tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2687 loss: tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2688 loss: tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2689 loss: tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2690 loss: tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2691 loss: tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2692 loss: tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2693 loss: tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2694 loss: tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2695 loss: tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2696 loss: tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2697 loss: tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2698 loss: tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2699 loss: tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2700 loss: tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2701 loss: tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2702 loss: tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2703 loss: tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2704 loss: tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2705 loss: tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2706 loss: tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2707 loss: tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2708 loss: tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2709 loss: tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2710 loss: tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2711 loss: tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2712 loss: tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2713 loss: tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2714 loss: tensor(0.0232, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2715 loss: tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2716 loss: tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2717 loss: tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2718 loss: tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2719 loss: tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2720 loss: tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2721 loss: tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2722 loss: tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2723 loss: tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2724 loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2725 loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2726 loss: tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2727 loss: tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2728 loss: tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2729 loss: tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2730 loss: tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2731 loss: tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2732 loss: tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2733 loss: tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2734 loss: tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2735 loss: tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2736 loss: tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2737 loss: tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2738 loss: tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2739 loss: tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2740 loss: tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2741 loss: tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2742 loss: tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2743 loss: tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2744 loss: tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2745 loss: tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2746 loss: tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2747 loss: tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2748 loss: tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2749 loss: tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2750 loss: tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2751 loss: tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2752 loss: tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2753 loss: tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2754 loss: tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2755 loss: tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2756 loss: tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2757 loss: tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2758 loss: tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2759 loss: tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2760 loss: tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2761 loss: tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2762 loss: tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2763 loss: tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2764 loss: tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2765 loss: tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2766 loss: tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2767 loss: tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2768 loss: tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2769 loss: tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2770 loss: tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2771 loss: tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2772 loss: tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2773 loss: tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2774 loss: tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2775 loss: tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2776 loss: tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2777 loss: tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2778 loss: tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2779 loss: tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2780 loss: tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2781 loss: tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2782 loss: tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2783 loss: tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2784 loss: tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2785 loss: tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2786 loss: tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2787 loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2788 loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2789 loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2790 loss: tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2791 loss: tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2792 loss: tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2793 loss: tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2794 loss: tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2795 loss: tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2796 loss: tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2797 loss: tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2798 loss: tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2799 loss: tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2800 loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2801 loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2802 loss: tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2803 loss: tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2804 loss: tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2805 loss: tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2806 loss: tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2807 loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2808 loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2809 loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2810 loss: tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2811 loss: tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2812 loss: tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2813 loss: tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2814 loss: tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2815 loss: tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2816 loss: tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2817 loss: tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2818 loss: tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2819 loss: tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2820 loss: tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2821 loss: tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2822 loss: tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2823 loss: tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2824 loss: tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2825 loss: tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2826 loss: tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2827 loss: tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2828 loss: tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2829 loss: tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2830 loss: tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2831 loss: tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2832 loss: tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2833 loss: tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2834 loss: tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2835 loss: tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2836 loss: tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2837 loss: tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2838 loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2839 loss: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2840 loss: tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2841 loss: tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2842 loss: tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2843 loss: tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2844 loss: tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2845 loss: tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2846 loss: tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2847 loss: tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2848 loss: tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2849 loss: tensor(0.0180, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2850 loss: tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2851 loss: tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2852 loss: tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2853 loss: tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2854 loss: tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2855 loss: tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2856 loss: tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2857 loss: tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2858 loss: tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2859 loss: tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2860 loss: tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2861 loss: tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2862 loss: tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2863 loss: tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2864 loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2865 loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2866 loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2867 loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2868 loss: tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2869 loss: tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2870 loss: tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2871 loss: tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2872 loss: tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2873 loss: tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2874 loss: tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2875 loss: tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2876 loss: tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2877 loss: tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2878 loss: tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2879 loss: tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2880 loss: tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2881 loss: tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2882 loss: tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2883 loss: tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2884 loss: tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2885 loss: tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2886 loss: tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2887 loss: tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2888 loss: tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2889 loss: tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2890 loss: tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2891 loss: tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2892 loss: tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2893 loss: tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2894 loss: tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2895 loss: tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2896 loss: tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2897 loss: tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2898 loss: tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2899 loss: tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2900 loss: tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2901 loss: tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2902 loss: tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2903 loss: tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2904 loss: tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2905 loss: tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2906 loss: tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2907 loss: tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2908 loss: tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2909 loss: tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2910 loss: tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2911 loss: tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2912 loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2913 loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2914 loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2915 loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2916 loss: tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2917 loss: tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2918 loss: tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2919 loss: tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2920 loss: tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2921 loss: tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2922 loss: tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2923 loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2924 loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2925 loss: tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2926 loss: tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2927 loss: tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2928 loss: tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2929 loss: tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2930 loss: tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2931 loss: tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2932 loss: tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2933 loss: tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2934 loss: tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2935 loss: tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2936 loss: tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2937 loss: tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2938 loss: tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2939 loss: tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2940 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2941 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2942 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2943 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2944 loss: tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2945 loss: tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2946 loss: tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2947 loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2948 loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2949 loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2950 loss: tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2951 loss: tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2952 loss: tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2953 loss: tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2954 loss: tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2955 loss: tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2956 loss: tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2957 loss: tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2958 loss: tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2959 loss: tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2960 loss: tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2961 loss: tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2962 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2963 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2964 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2965 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2966 loss: tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2967 loss: tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2968 loss: tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2969 loss: tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2970 loss: tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2971 loss: tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2972 loss: tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2973 loss: tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2974 loss: tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2975 loss: tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2976 loss: tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2977 loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2978 loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2979 loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2980 loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2981 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2982 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2983 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2984 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2985 loss: tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2986 loss: tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2987 loss: tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2988 loss: tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2989 loss: tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2990 loss: tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2991 loss: tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2992 loss: tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2993 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2994 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2995 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2996 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2997 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2998 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2999 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3000 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3001 loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3002 loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3003 loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3004 loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3005 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3006 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3007 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3008 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3009 loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3010 loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3011 loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3012 loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3013 loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3014 loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3015 loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3016 loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3017 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3018 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3019 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3020 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3021 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3022 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3023 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3024 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3025 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3026 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3027 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3028 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3029 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3030 loss: tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3031 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3032 loss: tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3033 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3034 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3035 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3036 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3037 loss: tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3038 loss: tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3039 loss: tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3040 loss: tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3041 loss: tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3042 loss: tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3043 loss: tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3044 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3045 loss: tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3046 loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3047 loss: tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3048 loss: tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3049 loss: tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3050 loss: tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3051 loss: tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3052 loss: tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3053 loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3054 loss: tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3055 loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3056 loss: tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3057 loss: tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3058 loss: tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3059 loss: tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3060 loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3061 loss: tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3062 loss: tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3063 loss: tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3064 loss: tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3065 loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3066 loss: tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3067 loss: tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3068 loss: tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3069 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3070 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3071 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3072 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3073 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3074 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3075 loss: tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3076 loss: tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3077 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3078 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3079 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3080 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3081 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3082 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3083 loss: tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3084 loss: tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3085 loss: tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3086 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3087 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3088 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3089 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3090 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3091 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3092 loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3093 loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3094 loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3095 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3096 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3097 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3098 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3099 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3100 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3101 loss: tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3102 loss: tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3103 loss: tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3104 loss: tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3105 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3106 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3107 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3108 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3109 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3110 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3111 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3112 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3113 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3114 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3115 loss: tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3116 loss: tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3117 loss: tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3118 loss: tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3119 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3120 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3121 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3122 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3123 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3124 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3125 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3126 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3127 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3128 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3129 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3130 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3131 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3132 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3133 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3134 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3135 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3136 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3137 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3138 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3139 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3140 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3141 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3142 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3143 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3144 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3145 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3146 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3147 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3148 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3149 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3150 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3151 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3152 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3153 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3154 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3155 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3156 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3157 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3158 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3159 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3160 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3161 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3162 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3163 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3164 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3165 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3166 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3167 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3168 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3169 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3170 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3171 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3172 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3173 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3174 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3175 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3176 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3177 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3178 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3179 loss: tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3180 loss: tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3181 loss: tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3182 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3183 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3184 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3185 loss: tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3186 loss: tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3187 loss: tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3188 loss: tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3189 loss: tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3190 loss: tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3191 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3192 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3193 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3194 loss: tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3195 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3196 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3197 loss: tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3198 loss: tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3199 loss: tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3200 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3201 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3202 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3203 loss: tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3204 loss: tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3205 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3206 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3207 loss: tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3208 loss: tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3209 loss: tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3210 loss: tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3211 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3212 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3213 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3214 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3215 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3216 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3217 loss: tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3218 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3219 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3220 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3221 loss: tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3222 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3223 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3224 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3225 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3226 loss: tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3227 loss: tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3228 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3229 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3230 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3231 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3232 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3233 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3234 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3235 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3236 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3237 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3238 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3239 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3240 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3241 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3242 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3243 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3244 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3245 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3246 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3247 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3248 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3249 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3250 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3251 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3252 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3253 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3254 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3255 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3256 loss: tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3257 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3258 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3259 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3260 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3261 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3262 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3263 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3264 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3265 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3266 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3267 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3268 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3269 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3270 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3271 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3272 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3273 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3274 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3275 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3276 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3277 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3278 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3279 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3280 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3281 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3282 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3283 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3284 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3285 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3286 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3287 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3288 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3289 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3290 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3291 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3292 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3293 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3294 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3295 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3296 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3297 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3298 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3299 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3300 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3301 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3302 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3303 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3304 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3305 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3306 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3307 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3308 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3309 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3310 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3311 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3312 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3313 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3314 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3315 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3316 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3317 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3318 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3319 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3320 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3321 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3322 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3323 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3324 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3325 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3326 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3327 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3328 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3329 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3330 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3331 loss: tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3332 loss: tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3333 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3334 loss: tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3335 loss: tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3336 loss: tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3337 loss: tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3338 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3339 loss: tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3340 loss: tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3341 loss: tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3342 loss: tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3343 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3344 loss: tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3345 loss: tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3346 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3347 loss: tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3348 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3349 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3350 loss: tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3351 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3352 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3353 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3354 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3355 loss: tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3356 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3357 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3358 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3359 loss: tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3360 loss: tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3361 loss: tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3362 loss: tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3363 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3364 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3365 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3366 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3367 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3368 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3369 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3370 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3371 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3372 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3373 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3374 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3375 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3376 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3377 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3378 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3379 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3380 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3381 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3382 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3383 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3384 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3385 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3386 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3387 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3388 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3389 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3390 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3391 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3392 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3393 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3394 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3395 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3396 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3397 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3398 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3399 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3400 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3401 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3402 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3403 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3404 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3405 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3406 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3407 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3408 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3409 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3410 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3411 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3412 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3413 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3414 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3415 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3416 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3417 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3418 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3419 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3420 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3421 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3422 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3423 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3424 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3425 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3426 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3427 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3428 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3429 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3430 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3431 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3432 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3433 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3434 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3435 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3436 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3437 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3438 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3439 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3440 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3441 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3442 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3443 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3444 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3445 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3446 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3447 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3448 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3449 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3450 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3451 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3452 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3453 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3454 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3455 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3456 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3457 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3458 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3459 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3460 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3461 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3462 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3463 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3464 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3465 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3466 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3467 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3468 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3469 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3470 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3471 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3472 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3473 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3474 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3475 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3476 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3477 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3478 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3479 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3480 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3481 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3482 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3483 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3484 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3485 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3486 loss: tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3487 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3488 loss: tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3489 loss: tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3490 loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3491 loss: tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3492 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3493 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3494 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3495 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3496 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3497 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3498 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3499 loss: tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3500 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3501 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3502 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3503 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3504 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3505 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3506 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3507 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3508 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3509 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3510 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3511 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3512 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3513 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3514 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3515 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3516 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3517 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3518 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3519 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3520 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3521 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3522 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3523 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3524 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3525 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3526 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3527 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3528 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3529 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3530 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3531 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3532 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3533 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3534 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3535 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3536 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3537 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3538 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3539 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3540 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3541 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3542 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3543 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3544 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3545 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3546 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3547 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3548 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3549 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3550 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3551 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3552 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3553 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3554 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3555 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3556 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3557 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3558 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3559 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3560 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3561 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3562 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3563 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3564 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3565 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3566 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3567 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3568 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3569 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3570 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3571 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3572 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3573 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3574 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3575 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3576 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3577 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3578 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3579 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3580 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3581 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3582 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3583 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3584 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3585 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3586 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3587 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3588 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3589 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3590 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3591 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3592 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3593 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3594 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3595 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3596 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3597 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3598 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3599 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3600 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3601 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3602 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3603 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3604 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3605 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3606 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3607 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3608 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3609 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3610 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3611 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3612 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3613 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3614 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3615 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3616 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3617 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3618 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3619 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3620 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3621 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3622 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3623 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3624 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3625 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3626 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3627 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3628 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3629 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3630 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3631 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3632 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3633 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3634 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3635 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3636 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3637 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3638 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3639 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3640 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3641 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3642 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3643 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3644 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3645 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3646 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3647 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3648 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3649 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3650 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3651 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3652 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3653 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3654 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3655 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3656 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3657 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3658 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3659 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3660 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3661 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3662 loss: tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3663 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3664 loss: tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3665 loss: tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3666 loss: tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3667 loss: tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3668 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3669 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3670 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3671 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3672 loss: tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3673 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3674 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3675 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3676 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3677 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3678 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3679 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3680 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3681 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3682 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3683 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3684 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3685 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3686 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3687 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3688 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3689 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3690 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3691 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3692 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3693 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3694 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3695 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3696 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3697 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3698 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3699 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3700 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3701 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3702 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3703 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3704 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3705 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3706 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3707 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3708 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3709 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3710 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3711 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3712 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3713 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3714 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3715 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3716 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3717 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3718 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3719 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3720 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3721 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3722 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3723 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3724 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3725 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3726 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3727 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3728 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3729 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3730 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3731 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3732 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3733 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3734 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3735 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3736 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3737 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3738 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3739 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3740 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3741 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3742 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3743 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3744 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3745 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3746 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3747 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3748 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3749 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3750 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3751 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3752 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3753 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3754 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3755 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3756 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3757 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3758 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3759 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3760 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3761 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3762 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3763 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3764 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3765 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3766 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3767 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3768 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3769 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3770 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3771 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3772 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3773 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3774 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3775 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3776 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3777 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3778 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3779 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3780 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3781 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3782 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3783 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3784 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3785 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3786 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3787 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3788 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3789 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3790 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3791 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3792 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3793 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3794 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3795 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3796 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3797 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3798 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3799 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3800 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3801 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3802 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3803 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3804 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3805 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3806 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3807 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3808 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3809 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3810 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3811 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3812 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3813 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3814 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3815 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3816 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3817 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3818 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3819 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3820 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3821 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3822 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3823 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3824 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3825 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3826 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3827 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3828 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3829 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3830 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3831 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3832 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3833 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3834 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3835 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3836 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3837 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3838 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3839 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3840 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3841 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3842 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3843 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3844 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3845 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3846 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3847 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3848 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3849 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3850 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3851 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3852 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3853 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3854 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3855 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3856 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3857 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3858 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3859 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3860 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3861 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3862 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3863 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3864 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3865 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3866 loss: tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3867 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3868 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3869 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3870 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3871 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3872 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3873 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3874 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3875 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3876 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3877 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3878 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3879 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3880 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3881 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3882 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3883 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3884 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3885 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3886 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3887 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3888 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3889 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3890 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3891 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3892 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3893 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3894 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3895 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3896 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3897 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3898 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3899 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3900 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3901 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3902 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3903 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3904 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3905 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3906 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3907 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3908 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3909 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3910 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3911 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3912 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3913 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3914 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3915 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3916 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3917 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3918 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3919 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3920 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3921 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3922 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3923 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3924 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3925 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3926 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3927 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3928 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3929 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3930 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3931 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3932 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3933 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3934 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3935 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3936 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3937 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3938 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3939 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3940 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3941 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3942 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3943 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3944 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3945 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3946 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3947 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3948 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3949 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3950 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3951 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3952 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3953 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3954 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3955 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3956 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3957 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3958 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3959 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3960 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3961 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3962 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3963 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3964 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3965 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3966 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3967 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3968 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3969 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3970 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3971 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3972 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3973 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3974 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3975 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3976 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3977 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3978 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3979 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3980 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3981 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3982 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3983 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3984 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3985 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3986 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3987 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3988 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3989 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3990 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3991 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3992 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3993 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3994 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3995 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3996 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3997 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3998 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3999 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4000 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4001 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4002 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4003 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4004 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4005 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4006 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4007 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4008 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4009 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4010 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4011 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4012 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4013 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4014 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4015 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4016 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4017 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4018 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4019 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4020 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4021 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4022 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4023 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4024 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4025 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4026 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4027 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4028 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4029 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4030 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4031 loss: tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4032 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4033 loss: tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4034 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4035 loss: tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4036 loss: tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4037 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4038 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4039 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4040 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4041 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4042 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4043 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4044 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4045 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4046 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4047 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4048 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4049 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4050 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4051 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4052 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4053 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4054 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4055 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4056 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4057 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4058 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4059 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4060 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4061 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4062 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4063 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4064 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4065 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4066 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4067 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4068 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4069 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4070 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4071 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4072 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4073 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4074 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4075 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4076 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4077 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4078 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4079 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4080 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4081 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4082 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4083 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4084 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4085 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4086 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4087 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4088 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4089 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4090 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4091 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4092 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4093 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4094 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4095 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4096 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4097 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4098 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4099 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4100 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4101 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4102 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4103 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4104 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4105 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4106 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4107 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4108 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4109 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4110 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4111 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4112 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4113 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4114 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4115 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4116 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4117 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4118 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4119 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4120 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4121 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4122 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4123 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4124 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4125 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4126 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4127 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4128 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4129 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4130 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4131 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4132 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4133 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4134 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4135 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4136 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4137 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4138 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4139 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4140 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4141 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4142 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4143 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4144 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4145 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4146 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4147 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4148 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4149 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4150 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4151 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4152 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4153 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4154 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4155 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4156 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4157 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4158 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4159 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4160 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4161 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4162 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4163 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4164 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4165 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4166 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4167 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4168 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4169 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4170 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4171 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4172 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4173 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4174 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4175 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4176 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4177 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4178 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4179 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4180 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4181 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4182 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4183 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4184 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4185 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4186 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4187 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4188 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4189 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4190 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4191 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4192 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4193 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4194 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4195 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4196 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4197 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4198 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4199 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4200 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4201 loss: tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4202 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4203 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4204 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4205 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4206 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4207 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4208 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4209 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4210 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4211 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4212 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4213 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4214 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4215 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4216 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4217 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4218 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4219 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4220 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4221 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4222 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4223 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4224 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4225 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4226 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4227 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4228 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4229 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4230 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4231 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4232 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4233 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4234 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4235 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4236 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4237 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4238 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4239 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4240 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4241 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4242 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4243 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4244 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4245 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4246 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4247 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4248 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4249 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4250 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4251 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4252 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4253 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4254 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4255 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4256 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4257 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4258 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4259 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4260 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4261 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4262 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4263 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4264 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4265 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4266 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4267 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4268 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4269 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4270 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4271 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4272 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4273 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4274 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4275 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4276 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4277 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4278 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4279 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4280 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4281 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4282 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4283 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4284 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4285 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4286 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4287 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4288 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4289 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4290 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4291 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4292 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4293 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4294 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4295 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4296 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4297 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4298 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4299 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4300 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4301 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4302 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4303 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4304 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4305 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4306 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4307 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4308 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4309 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4310 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4311 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4312 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4313 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4314 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4315 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4316 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4317 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4318 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4319 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4320 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4321 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4322 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4323 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4324 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4325 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4326 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4327 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4328 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4329 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4330 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4331 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4332 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4333 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4334 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4335 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4336 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4337 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4338 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4339 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4340 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4341 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4342 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4343 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4344 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4345 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4346 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4347 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4348 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4349 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4350 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4351 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4352 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4353 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4354 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4355 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4356 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4357 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4358 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4359 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4360 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4361 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4362 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4363 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4364 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4365 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4366 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4367 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4368 loss: tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4369 loss: tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4370 loss: tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4371 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4372 loss: tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4373 loss: tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4374 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4375 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4376 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4377 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4378 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4379 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4380 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4381 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4382 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4383 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4384 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4385 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4386 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4387 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4388 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4389 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4390 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4391 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4392 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4393 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4394 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4395 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4396 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4397 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4398 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4399 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4400 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4401 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4402 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4403 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4404 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4405 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4406 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4407 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4408 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4409 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4410 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4411 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4412 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4413 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4414 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4415 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4416 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4417 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4418 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4419 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4420 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4421 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4422 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4423 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4424 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4425 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4426 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4427 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4428 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4429 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4430 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4431 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4432 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4433 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4434 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4435 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4436 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4437 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4438 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4439 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4440 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4441 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4442 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4443 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4444 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4445 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4446 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4447 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4448 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4449 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4450 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4451 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4452 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4453 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4454 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4455 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4456 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4457 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4458 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4459 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4460 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4461 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4462 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4463 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4464 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4465 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4466 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4467 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4468 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4469 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4470 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4471 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4472 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4473 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4474 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4475 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4476 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4477 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4478 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4479 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4480 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4481 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4482 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4483 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4484 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4485 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4486 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4487 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4488 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4489 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4490 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4491 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4492 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4493 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4494 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4495 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4496 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4497 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4498 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4499 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4500 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4501 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4502 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4503 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4504 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4505 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4506 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4507 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4508 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4509 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4510 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4511 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4512 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4513 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4514 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4515 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4516 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4517 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4518 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4519 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4520 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4521 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4522 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4523 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4524 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4525 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4526 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4527 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4528 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4529 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4530 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4531 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4532 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4533 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4534 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4535 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4536 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4537 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4538 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4539 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4540 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4541 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4542 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4543 loss: tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4544 loss: tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4545 loss: tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4546 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4547 loss: tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4548 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4549 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4550 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4551 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4552 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4553 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4554 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4555 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4556 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4557 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4558 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4559 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4560 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4561 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4562 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4563 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4564 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4565 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4566 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4567 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4568 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4569 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4570 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4571 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4572 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4573 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4574 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4575 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4576 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4577 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4578 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4579 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4580 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4581 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4582 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4583 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4584 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4585 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4586 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4587 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4588 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4589 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4590 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4591 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4592 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4593 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4594 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4595 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4596 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4597 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4598 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4599 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4600 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4601 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4602 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4603 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4604 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4605 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4606 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4607 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4608 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4609 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4610 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4611 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4612 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4613 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4614 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4615 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4616 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4617 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4618 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4619 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4620 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4621 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4622 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4623 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4624 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4625 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4626 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4627 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4628 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4629 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4630 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4631 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4632 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4633 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4634 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4635 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4636 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4637 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4638 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4639 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4640 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4641 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4642 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4643 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4644 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4645 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4646 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4647 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4648 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4649 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4650 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4651 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4652 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4653 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4654 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4655 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4656 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4657 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4658 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4659 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4660 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4661 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4662 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4663 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4664 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4665 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4666 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4667 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4668 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4669 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4670 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4671 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4672 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4673 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4674 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4675 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4676 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4677 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4678 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4679 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4680 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4681 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4682 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4683 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4684 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4685 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4686 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4687 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4688 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4689 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4690 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4691 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4692 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4693 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4694 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4695 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4696 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4697 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4698 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4699 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4700 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4701 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4702 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4703 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4704 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4705 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4706 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4707 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4708 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4709 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4710 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4711 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4712 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4713 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4714 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4715 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4716 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4717 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4718 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4719 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4720 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4721 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4722 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4723 loss: tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4724 loss: tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4725 loss: tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4726 loss: tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4727 loss: tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4728 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4729 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4730 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4731 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4732 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4733 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4734 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4735 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4736 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4737 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4738 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4739 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4740 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4741 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4742 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4743 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4744 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4745 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4746 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4747 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4748 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4749 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4750 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4751 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4752 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4753 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4754 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4755 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4756 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4757 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4758 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4759 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4760 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4761 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4762 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4763 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4764 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4765 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4766 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4767 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4768 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4769 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4770 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4771 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4772 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4773 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4774 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4775 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4776 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4777 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4778 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4779 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4780 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4781 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4782 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4783 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4784 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4785 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4786 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4787 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4788 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4789 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4790 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4791 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4792 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4793 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4794 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4795 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4796 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4797 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4798 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4799 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4800 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4801 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4802 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4803 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4804 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4805 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4806 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4807 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4808 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4809 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4810 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4811 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4812 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4813 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4814 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4815 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4816 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4817 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4818 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4819 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4820 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4821 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4822 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4823 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4824 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4825 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4826 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4827 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4828 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4829 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4830 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4831 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4832 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4833 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4834 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4835 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4836 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4837 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4838 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4839 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4840 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4841 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4842 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4843 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4844 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4845 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4846 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4847 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4848 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4849 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4850 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4851 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4852 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4853 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4854 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4855 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4856 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4857 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4858 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4859 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4860 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4861 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4862 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4863 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4864 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4865 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4866 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4867 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4868 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4869 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4870 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4871 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4872 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4873 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4874 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4875 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4876 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4877 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4878 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4879 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4880 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4881 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4882 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4883 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4884 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4885 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4886 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4887 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4888 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4889 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4890 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4891 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4892 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4893 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4894 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4895 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4896 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4897 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4898 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4899 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4900 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4901 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4902 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4903 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4904 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4905 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4906 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4907 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4908 loss: tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4909 loss: tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4910 loss: tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4911 loss: tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4912 loss: tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4913 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4914 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4915 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4916 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4917 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4918 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4919 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4920 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4921 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4922 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4923 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4924 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4925 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4926 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4927 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4928 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4929 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4930 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4931 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4932 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4933 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4934 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4935 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4936 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4937 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4938 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4939 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4940 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4941 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4942 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4943 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4944 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4945 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4946 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4947 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4948 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4949 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4950 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4951 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4952 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4953 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4954 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4955 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4956 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4957 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4958 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4959 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4960 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4961 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4962 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4963 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4964 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4965 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4966 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4967 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4968 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4969 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4970 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4971 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4972 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4973 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4974 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4975 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4976 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4977 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4978 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4979 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4980 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4981 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4982 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4983 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4984 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4985 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4986 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4987 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4988 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4989 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4990 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4991 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4992 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4993 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4994 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4995 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4996 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4997 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4998 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4999 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = train(5000, net, features_temp, labels_temp, criterion, optimizer, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44cd992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.  0.  2.]\n",
      " [ 2.  4.  1.  2.]\n",
      " [ 4.  4.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [ 9.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 4.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 4.  4.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  4.  8.  2.]\n",
      " [ 9.  4.  9.  2.]\n",
      " [10.  4. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 4.  4.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [ 9.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [14.  3. 14.  2.]\n",
      " [15.  3. 15.  2.]\n",
      " [16.  3. 16.  2.]\n",
      " [17.  3. 17.  2.]\n",
      " [ 4.  3.  3.  2.]\n",
      " [ 4.  3.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [10.  2. 11.  2.]\n",
      " [11.  2. 12.  2.]\n",
      " [12.  2. 13.  2.]\n",
      " [13.  2. 14.  2.]\n",
      " [14.  2. 15.  2.]\n",
      " [15.  2. 16.  2.]\n",
      " [16.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [10.  3. 11.  2.]\n",
      " [11.  3. 12.  2.]\n",
      " [12.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [ 9.  3.  9.  2.]\n",
      " [10.  3. 10.  2.]\n",
      " [11.  3. 11.  2.]\n",
      " [12.  3. 12.  2.]\n",
      " [13.  3. 13.  2.]\n",
      " [13.  3. 14.  2.]\n",
      " [14.  3. 15.  2.]\n",
      " [15.  3. 16.  2.]\n",
      " [16.  3. 17.  2.]\n",
      " [ 3.  3.  3.  2.]\n",
      " [ 5.  3.  5.  2.]\n",
      " [ 8.  3.  8.  2.]\n",
      " [-4.  6.  0.  2.]\n",
      " [-3.  6.  1.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [-2.  6.  5.  2.]\n",
      " [ 1.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-2.  6.  3.  2.]\n",
      " [ 0.  6.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 2.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [ 1.  6.  5.  2.]\n",
      " [ 3.  6.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 2.  6.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  6.  3.  2.]\n",
      " [ 1.  5.  5.  2.]\n",
      " [ 3.  5.  7.  2.]\n",
      " [-1.  5.  3.  2.]\n",
      " [-2.  5.  5.  2.]\n",
      " [ 2.  6.  7.  2.]\n",
      " [-1.  2.  0.  2.]\n",
      " [-0.  2.  1.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 1.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 7.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [ 9.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 1.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 7.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6. -0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [ 9.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 1.  1.  5.  2.]\n",
      " [ 3. -0.  8.  2.]\n",
      " [ 3.  0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 7.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6. -0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 5. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 8.  1. 11.  2.]\n",
      " [ 9.  1. 12.  2.]\n",
      " [ 9.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 3. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 7.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 5. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 8.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 3. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 7.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 4. -0. 12.  2.]\n",
      " [ 5. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 8.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 1.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 7.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [ 9.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 1.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 4.  0. 10.  2.]\n",
      " [ 5.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  2.  8.  2.]\n",
      " [ 6.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  0. 11.  2.]\n",
      " [ 6.  0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [-0. -0.  5.  2.]\n",
      " [ 6.  2.  8.  2.]\n",
      " [ 7.  2.  9.  2.]\n",
      " [ 7.  2. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [10.  2. 13.  2.]\n",
      " [ 1.  2.  3.  2.]\n",
      " [ 3.  2.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 3.  0.  8.  2.]\n",
      " [ 4.  0.  9.  2.]\n",
      " [ 5.  0. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]\n",
      " [ 8.  1. 13.  2.]\n",
      " [-1.  0.  3.  2.]\n",
      " [ 1.  0.  5.  2.]\n",
      " [ 2. -0.  8.  2.]\n",
      " [ 3. -0.  9.  2.]\n",
      " [ 4. -0. 10.  2.]\n",
      " [ 5. -0. 11.  2.]\n",
      " [ 6. -0. 12.  2.]\n",
      " [ 7.  0. 13.  2.]\n",
      " [-2. -0.  3.  2.]\n",
      " [ 0.  0.  5.  2.]\n",
      " [ 1. -0.  8.  2.]\n",
      " [ 2. -0.  9.  2.]\n",
      " [ 3. -0. 10.  2.]\n",
      " [ 4. -0. 11.  2.]\n",
      " [ 5. -0. 12.  2.]\n",
      " [ 6. -0. 13.  2.]\n",
      " [-3. -0.  3.  2.]\n",
      " [-1. -0.  5.  2.]\n",
      " [ 5.  1.  8.  2.]\n",
      " [ 6.  1.  9.  2.]\n",
      " [ 7.  1. 10.  2.]\n",
      " [ 8.  2. 11.  2.]\n",
      " [ 9.  2. 12.  2.]\n",
      " [ 9.  2. 13.  2.]\n",
      " [ 1.  1.  3.  2.]\n",
      " [ 3.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 5.  1.  9.  2.]\n",
      " [ 6.  1. 10.  2.]\n",
      " [ 7.  1. 11.  2.]\n",
      " [ 8.  1. 12.  2.]\n",
      " [ 9.  1. 13.  2.]\n",
      " [-0.  1.  3.  2.]\n",
      " [ 2.  1.  5.  2.]\n",
      " [ 4.  1.  8.  2.]\n",
      " [ 4.  1.  9.  2.]\n",
      " [ 5.  1. 10.  2.]\n",
      " [ 6.  1. 11.  2.]\n",
      " [ 7.  1. 12.  2.]]\n",
      "Epoch = 0 test_acc = 0.167  test_rmse = 2.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109417/3030192740.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_target_torch = torch.tensor(torch.from_numpy(np.array(labels_temp)).float())\n",
      "/tmp/ipykernel_109417/3030192740.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_target_torch = torch.tensor(torch.from_numpy(np.array(test_target)).float())\n"
     ]
    }
   ],
   "source": [
    "#net = net.to(device)\n",
    "N_epochs = 10000\n",
    "\n",
    "labels_temp = np.array(labels_temp)\n",
    "#train_data_torch = torch.from_numpy(features_temp).float()\n",
    "#train_target_torch = torch.from_numpy(labels_temp).float()\n",
    "train_target_torch = torch.tensor(torch.from_numpy(np.array(labels_temp)).float())\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def validate(net, test_data, test_target, i):\n",
    "    \n",
    "    test_data_torch = torch.from_numpy(features_test).float()\n",
    "    #test_target_torch = torch.from_numpy(labels_test).float()\n",
    "    test_target_torch = torch.tensor(torch.from_numpy(np.array(test_target)).float())\n",
    "\n",
    "    test_pred = np.rint(net(test_data_torch).detach().numpy())\n",
    "    if i % 500 == 0:\n",
    "        print(np.concatenate((test_pred, test_target_torch.detach().numpy()), axis=1))\n",
    "    #test_accuracy = (test_target_torch.detach().numpy() == test_pred).float().mean().detach().numpy()\n",
    "    test_accuracy = (test_target_torch.detach().numpy() == test_pred).mean()\n",
    "\n",
    "    #test_rmse = ((test_pred-test_target_torch)**2).mean().sqrt().detach().numpy()\n",
    "    test_rmse = (np.sqrt((test_pred-test_target_torch.detach().numpy())**2).mean())\n",
    "\n",
    "    return test_accuracy, test_rmse\n",
    "\n",
    "for i in range(1):\n",
    "    #pred = net(train_data_torch)\n",
    "    #loss = criterion(pred, train_target_torch)\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        #train_accuracy, train_rmse = validate(net, features_temp, labels_temp)\n",
    "        test_accuracy, test_rmse = validate(net, features_test, labels_test, i)\n",
    "        #print(f'Epoch = {i} loss={loss} train_acc = {train_accuracy:.3f} test_acc = {test_accuracy:.3f} train_rmse = {train_rmse:.3f}  test_rmse = {test_rmse:.3f}')         \n",
    "        print(f'Epoch = {i} test_acc = {test_accuracy:.3f}  test_rmse = {test_rmse:.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af476f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 3.]\n"
     ]
    }
   ],
   "source": [
    "preds = net(torch.from_numpy(features_test[3]).float()).detach().numpy()\n",
    "print(np.rint(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5fdda9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9992, grad_fn=<UnbindBackward0>)\n",
      "tensor(2.0004, grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for p in preds:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0aed387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3626e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
