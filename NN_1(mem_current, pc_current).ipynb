{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10977213",
   "metadata": {},
   "source": [
    "## Preparing SV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79a0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#np.set_printoptions(formatter={'int':hex})\n",
    "\n",
    "import os\n",
    "files = os.listdir('sv_traces/')\n",
    "\n",
    "### reads an sv_trace file into 2 structures:\n",
    "### pcs: a list of 1001 16-bit pc values\n",
    "### mem: a list of 1001 65542-byte memory vectors\n",
    "def read_trace(sv_file):\n",
    "    with open(sv_file, 'rb') as f:\n",
    "        lines = f.read()\n",
    "        lines = np.frombuffer(lines, dtype=np.uint8)\n",
    "        lines = lines.reshape(1001,-1)\n",
    "        pcs = lines[:, 0:2]\n",
    "        mem = lines[:, :]\n",
    "        #pcs = [np.uint16(i[1]<<8 | i[0]) for i in pcs]\n",
    "        return mem, pcs\n",
    "    \n",
    "### reads trace data into a dataset of mem-to-pc mappings, where\n",
    "### mem_current: partial memory trace &\n",
    "### pcs_current: full pcs trace\n",
    "def read_dataset(file):\n",
    "    mem_trace = dict_traces[file][0]\n",
    "    mem_current = mem_trace[:]\n",
    "    pcs_trace = dict_traces[file][1]\n",
    "    pcs_current = pcs_trace[:]\n",
    "    return mem_current, pcs_current\n",
    "\n",
    "### dict_traces[file][0]: memory trace of <file>\n",
    "### dict_traces[file][1]: pc trace of <file>\n",
    "dict_traces = {}\n",
    "for file in files[0:20]:\n",
    "    dict_traces[file] = read_trace(os.path.join('sv_traces/', file))\n",
    "    \n",
    "### dict_dataset[file][0]: memory trace of <file>\n",
    "### dict_dataset[file][1]: pc trace of <file>\n",
    "dict_dataset = {}\n",
    "for trace in dict_traces:\n",
    "    dict_dataset[trace] = read_dataset(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b038ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'167:149:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 126, ...,   2,   0,   0],\n",
       "         [  5,   2,  20, ...,   2,   0,   0],\n",
       "         [  7,   2,  20, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '121:187:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  2, 50, ...,  2,  0,  0],\n",
       "         [10,  2, 50, ...,  2,  0,  0],\n",
       "         [11,  2, 50, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '144:101:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  9,   2, 243, ...,   2,   0,   0],\n",
       "         [ 10,   2, 243, ...,   2,   0,   0],\n",
       "         [ 11,   2, 243, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '91:117:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  41, ...,   2,   0,   0],\n",
       "         [  5,   2, 159, ...,   2,   0,   0],\n",
       "         [  7,   2, 159, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '308:221:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 12,   2, 220, ...,   2,   0,   0],\n",
       "         [ 13,   2, 220, ...,   2,   0,   0],\n",
       "         [ 14,   2, 220, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '387:118:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [10,  2, 38, ...,  2,  0,  0],\n",
       "         [11,  2, 38, ...,  2,  0,  0],\n",
       "         [12,  2, 38, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '391:23:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 174, ...,   2,   0,   0],\n",
       "         [ 11,   2, 174, ...,   2,   0,   0],\n",
       "         [ 12,   2, 174, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '103:2:11.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 144, ...,   2,   0,   0],\n",
       "         [  8,   2, 144, ...,   2,   0,   0],\n",
       "         [  9,   2, 144, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '387:177:6.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [12,  2, 11, ...,  2,  0,  0],\n",
       "         [13,  2, 11, ...,  2,  0,  0],\n",
       "         [14,  2, 11, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '221:53:2.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  5,   2, 145, ...,   2,   0,   0],\n",
       "         [  7,   2, 145, ...,   2,   0,   0],\n",
       "         [  8,   2, 145, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [5, 2],\n",
       "         [7, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '347:229:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 136, ...,   2,   0,   0],\n",
       "         [  5,   2, 110, ...,   2,   0,   0],\n",
       "         [  8,   2, 110, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '245:222:0.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,   8, ...,   2,   0,   0],\n",
       "         [  5,   2, 231, ...,   2,   0,   0],\n",
       "         [  7,   2, 231, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '317:48:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 135, ...,   2,   0,   0],\n",
       "         [ 11,   2, 135, ...,   2,   0,   0],\n",
       "         [ 12,   2, 135, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '151:96:12.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [11,  2, 56, ...,  2,  0,  0],\n",
       "         [12,  2, 56, ...,  2,  0,  0],\n",
       "         [13,  2, 56, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '232:123:4.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 249, ...,   2,   0,   0],\n",
       "         [  8,   2, 249, ...,   2,   0,   0],\n",
       "         [  9,   2, 249, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '276:162:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 104, ...,   2,   0,   0],\n",
       "         [ 11,   2, 104, ...,   2,   0,   0],\n",
       "         [ 12,   2, 104, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '21:209:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 148, ...,   2,   0,   0],\n",
       "         [ 12,   2, 148, ...,   2,   0,   0],\n",
       "         [ 13,   2, 148, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '322:139:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 123, ...,   2,   0,   0],\n",
       "         [  5,   2,   7, ...,   2,   0,   0],\n",
       "         [  8,   2,   7, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '150:162:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 207, ...,   2,   0,   0],\n",
       "         [ 12,   2, 207, ...,   2,   0,   0],\n",
       "         [ 13,   2, 207, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '117:148:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  87, ...,   2,   0,   0],\n",
       "         [  5,   2, 236, ...,   2,   0,   0],\n",
       "         [  7,   2, 236, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8))}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86a39d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'167:149:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 126, ...,   2,   0,   0],\n",
       "         [  5,   2,  20, ...,   2,   0,   0],\n",
       "         [  7,   2,  20, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '121:187:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  2, 50, ...,  2,  0,  0],\n",
       "         [10,  2, 50, ...,  2,  0,  0],\n",
       "         [11,  2, 50, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '144:101:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  9,   2, 243, ...,   2,   0,   0],\n",
       "         [ 10,   2, 243, ...,   2,   0,   0],\n",
       "         [ 11,   2, 243, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [ 9,  2],\n",
       "         [10,  2],\n",
       "         [11,  2]], dtype=uint8)),\n",
       " '91:117:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  41, ...,   2,   0,   0],\n",
       "         [  5,   2, 159, ...,   2,   0,   0],\n",
       "         [  7,   2, 159, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '308:221:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 12,   2, 220, ...,   2,   0,   0],\n",
       "         [ 13,   2, 220, ...,   2,   0,   0],\n",
       "         [ 14,   2, 220, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '387:118:13.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [10,  2, 38, ...,  2,  0,  0],\n",
       "         [11,  2, 38, ...,  2,  0,  0],\n",
       "         [12,  2, 38, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '391:23:13.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 174, ...,   2,   0,   0],\n",
       "         [ 11,   2, 174, ...,   2,   0,   0],\n",
       "         [ 12,   2, 174, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '103:2:11.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 144, ...,   2,   0,   0],\n",
       "         [  8,   2, 144, ...,   2,   0,   0],\n",
       "         [  9,   2, 144, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '387:177:6.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [12,  2, 11, ...,  2,  0,  0],\n",
       "         [13,  2, 11, ...,  2,  0,  0],\n",
       "         [14,  2, 11, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [12,  2],\n",
       "         [13,  2],\n",
       "         [14,  2]], dtype=uint8)),\n",
       " '221:53:2.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  5,   2, 145, ...,   2,   0,   0],\n",
       "         [  7,   2, 145, ...,   2,   0,   0],\n",
       "         [  8,   2, 145, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [5, 2],\n",
       "         [7, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '347:229:9.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 136, ...,   2,   0,   0],\n",
       "         [  5,   2, 110, ...,   2,   0,   0],\n",
       "         [  8,   2, 110, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '245:222:0.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,   8, ...,   2,   0,   0],\n",
       "         [  5,   2, 231, ...,   2,   0,   0],\n",
       "         [  7,   2, 231, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8)),\n",
       " '317:48:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 135, ...,   2,   0,   0],\n",
       "         [ 11,   2, 135, ...,   2,   0,   0],\n",
       "         [ 12,   2, 135, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '151:96:12.svbinttrc': (array([[ 0,  2,  0, ...,  2,  0,  0],\n",
       "         [ 1,  2,  0, ...,  2,  0,  0],\n",
       "         [ 3,  2,  0, ...,  2,  0,  0],\n",
       "         ...,\n",
       "         [11,  2, 56, ...,  2,  0,  0],\n",
       "         [12,  2, 56, ...,  2,  0,  0],\n",
       "         [13,  2, 56, ...,  2,  0,  0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '232:123:4.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  7,   2, 249, ...,   2,   0,   0],\n",
       "         [  8,   2, 249, ...,   2,   0,   0],\n",
       "         [  9,   2, 249, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [7, 2],\n",
       "         [8, 2],\n",
       "         [9, 2]], dtype=uint8)),\n",
       " '276:162:5.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 10,   2, 104, ...,   2,   0,   0],\n",
       "         [ 11,   2, 104, ...,   2,   0,   0],\n",
       "         [ 12,   2, 104, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [10,  2],\n",
       "         [11,  2],\n",
       "         [12,  2]], dtype=uint8)),\n",
       " '21:209:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 148, ...,   2,   0,   0],\n",
       "         [ 12,   2, 148, ...,   2,   0,   0],\n",
       "         [ 13,   2, 148, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '322:139:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2, 123, ...,   2,   0,   0],\n",
       "         [  5,   2,   7, ...,   2,   0,   0],\n",
       "         [  8,   2,   7, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [8, 2]], dtype=uint8)),\n",
       " '150:162:8.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [ 11,   2, 207, ...,   2,   0,   0],\n",
       "         [ 12,   2, 207, ...,   2,   0,   0],\n",
       "         [ 13,   2, 207, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 3,  2],\n",
       "         ...,\n",
       "         [11,  2],\n",
       "         [12,  2],\n",
       "         [13,  2]], dtype=uint8)),\n",
       " '117:148:3.svbinttrc': (array([[  0,   2,   0, ...,   2,   0,   0],\n",
       "         [  1,   2,   0, ...,   2,   0,   0],\n",
       "         [  3,   2,   0, ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  3,   2,  87, ...,   2,   0,   0],\n",
       "         [  5,   2, 236, ...,   2,   0,   0],\n",
       "         [  7,   2, 236, ...,   2,   0,   0]], dtype=uint8),\n",
       "  array([[0, 2],\n",
       "         [1, 2],\n",
       "         [3, 2],\n",
       "         ...,\n",
       "         [3, 2],\n",
       "         [5, 2],\n",
       "         [7, 2]], dtype=uint8))}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997a46d",
   "metadata": {},
   "source": [
    "## Defining Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4145c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdccbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_label(l, width=16):\n",
    "    val = bin(l)[2:]\n",
    "    N = len(val)\n",
    "    return [0.] * (width-N) + [float(i) for i in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a45607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_label(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "256108b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = dict_dataset[list(dict_dataset.keys())[0]]\n",
    "for file in list(dict_dataset.keys())[1:10]:\n",
    "    features = np.append(features, dict_dataset[file][0], axis=0)\n",
    "    labels = np.append(labels, dict_dataset[file][1], axis=0)\n",
    "features_test, labels_test = dict_dataset[list(dict_dataset.keys())[10]]\n",
    "for file in list(dict_dataset.keys())[11:13]:\n",
    "    features_test = np.append(features_test, dict_dataset[file][0], axis=0)\n",
    "    labels_test = np.append(labels_test, dict_dataset[file][1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8063235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, labels = dict_dataset[list(dict_dataset.keys())[0]]\n",
    "#features_test, labels_test = dict_dataset[list(dict_dataset.keys())[1]]\n",
    "#features = features - features.mean(axis=0)\n",
    "# temp\n",
    "features_temp = features#[9:15, ]\n",
    "labels_temp = labels#[9:15]\n",
    "# end temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6178cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 1  2]\n",
      " [ 3  2]\n",
      " [ 5  2]\n",
      " [ 7  2]\n",
      " [ 8  2]\n",
      " [ 9  2]\n",
      " [10  2]\n",
      " [11  2]\n",
      " [12  2]\n",
      " [13  2]\n",
      " [14  2]\n",
      " [15  2]\n",
      " [16  2]\n",
      " [17  2]\n",
      " [18  2]]\n",
      "[[ 0  2]\n",
      " [ 1  2]\n",
      " [ 3  2]\n",
      " [ 5  2]\n",
      " [ 7  2]\n",
      " [ 8  2]\n",
      " [ 9  2]\n",
      " [10  2]\n",
      " [11  2]\n",
      " [12  2]\n",
      " [13  2]\n",
      " [14  2]\n",
      " [15  2]\n",
      " [16  2]\n",
      " [ 3  2]\n",
      " [ 5  2]]\n"
     ]
    }
   ],
   "source": [
    "print(labels_test[0:16])\n",
    "print(labels_temp[0:16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "206ca5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2], dtype=uint8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d29da65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10010\n",
      "10010\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "partial_mem_trace = features_temp[: , 0:8]\n",
    "#partial_mem_trace = features_temp[: , 0:1024]\n",
    "features_temp = partial_mem_trace # all rows are identical here\n",
    "\n",
    "partial_mem_trace_test = features_test[: , 0:8]\n",
    "features_test = partial_mem_trace_test # all rows are identical here\n",
    "\n",
    "    \n",
    "print(partial_mem_trace.shape[0])\n",
    "print(features_temp.shape[0])\n",
    "print(partial_mem_trace.shape[1])\n",
    "print(features_temp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08cf5f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  0,  0,  0,  0, 20,  0], dtype=uint8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5bea2",
   "metadata": {},
   "source": [
    "### Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e94e92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   2   0 ...   0  20   0]\n",
      " [  1   2   0 ...   0  20   0]\n",
      " [  3   2   0 ...   0  22   0]\n",
      " ...\n",
      " [  5   2 145 ...   0 212   0]\n",
      " [  7   2 145 ...   0 212   0]\n",
      " [  8   2 145 ...   0 212   0]]\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(features_temp.shape[1], 2**8),\n",
    "    nn.ReLU(), #rectified linear unit\n",
    "    #nn.Linear(2**12, 2**10),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Linear(2**8, 2**8),\n",
    "    #nn.ReLU(),\n",
    "    nn.Linear(2**8, 2),\n",
    "    #nn.Sigmoid()\n",
    ")\n",
    "\n",
    "#criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(n_epochs, net, features, labels, criterion, optimizer, freq=1, debug=False):\n",
    "    for i in range(n_epochs): #number of passes over full dataset\n",
    "        #step 1: get features and use net to make predictions\n",
    "        preds = net(torch.from_numpy(features).float())\n",
    "        \n",
    "        #step 2: compute loss/error\n",
    "        labels_torch = torch.tensor(torch.from_numpy(np.array(labels)).float())\n",
    "        if debug: print('\\n------')\n",
    "        if debug: print(preds)\n",
    "        #loss = np.sqrt(((np.rint(preds.detach().numpy()) - labels_torch.detach().numpy())**2).mean())\n",
    "        loss = criterion(preds, labels_torch)\n",
    "        if i % freq == 0:\n",
    "            print('epoch:', i, 'loss:', loss)\n",
    "\n",
    "        #step 3: backprop to update weights\n",
    "        # compute gradients/derivatives - backprop\n",
    "        # use gradients to update weights - gradient descent - w = w - 0.1 * deriv. loss w.r.t. w\n",
    "\n",
    "        optimizer.zero_grad() #set previous buffers to zero\n",
    "        loss.backward() #backprop\n",
    "        optimizer.step() #update weights        \n",
    "        \n",
    "    return net\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "print(features_temp)\n",
    "#net = train(1000, net, features_temp, labels_temp, criterion, optimizer, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e5af8506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39771/1586916469.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_torch = torch.tensor(torch.from_numpy(np.array(labels)).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 10 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 11 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 12 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 13 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 14 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 15 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 16 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 17 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 18 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 19 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 20 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 21 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 22 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 23 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 24 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 25 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 26 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 27 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 28 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 29 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 30 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 31 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 32 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 33 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 34 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 35 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 36 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 37 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 38 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 39 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 40 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 41 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 42 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 43 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 44 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 45 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 46 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 47 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 48 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 49 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 50 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 51 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 52 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 53 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 54 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 55 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 56 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 57 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 58 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 59 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 60 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 61 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 62 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 63 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 64 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 65 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 66 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 67 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 68 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 69 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 70 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 71 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 72 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 73 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 74 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 75 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 76 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 77 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 78 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 79 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 80 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 81 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 82 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 83 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 84 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 85 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 86 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 87 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 88 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 89 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 90 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 91 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 92 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 93 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 94 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 95 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 96 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 97 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 98 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 99 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 100 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 101 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 102 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 103 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 104 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 105 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 106 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 107 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 108 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 109 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 110 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 111 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 112 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 113 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 114 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 115 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 116 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 117 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 118 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 119 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 120 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 121 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 122 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 123 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 124 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 125 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 126 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 127 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 128 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 129 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 130 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 131 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 132 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 133 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 134 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 135 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 136 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 137 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 138 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 139 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 140 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 141 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 142 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 143 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 144 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 145 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 146 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 148 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 149 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 150 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 151 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 152 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 153 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 154 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 155 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 156 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 157 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 158 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 159 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 160 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 161 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 162 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 163 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 164 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 165 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 166 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 167 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 168 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 169 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 170 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 171 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 172 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 173 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 174 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 175 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 176 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 177 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 178 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 179 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 180 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 181 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 182 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 183 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 184 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 185 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 186 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 187 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 188 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 189 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 190 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 191 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 192 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 193 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 194 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 195 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 196 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 197 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 198 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 199 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 200 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 201 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 202 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 203 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 204 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 205 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 206 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 207 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 208 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 209 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 210 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 211 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 212 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 213 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 214 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 215 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 216 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 217 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 218 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 219 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 220 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 221 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 222 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 223 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 224 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 225 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 226 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 227 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 228 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 229 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 230 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 231 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 232 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 233 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 234 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 235 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 236 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 237 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 238 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 239 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 240 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 241 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 242 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 243 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 244 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 245 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 246 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 247 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 248 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 249 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 250 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 251 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 252 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 253 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 254 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 255 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 256 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 257 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 258 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 259 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 260 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 261 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 262 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 263 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 264 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 265 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 266 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 267 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 268 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 269 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 270 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 271 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 272 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 273 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 274 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 275 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 279 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 280 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 281 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 282 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 283 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 284 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 285 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 290 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 291 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 292 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 293 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 299 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 300 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 301 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 302 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 303 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 304 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 305 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 306 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 307 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 308 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 309 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 310 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 311 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 312 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 313 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 314 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 315 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 316 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 317 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 318 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 319 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 320 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 321 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 322 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 323 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 324 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 325 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 326 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 327 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 328 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 329 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 330 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 331 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 332 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 333 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 334 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 335 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 336 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 337 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 338 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 339 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 340 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 341 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 342 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 343 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 344 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 345 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 346 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 347 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 348 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 349 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 350 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 351 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 352 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 353 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 354 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 355 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 356 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 357 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 358 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 359 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 360 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 361 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 362 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 363 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 364 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 365 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 366 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 367 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 368 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 369 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 370 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 371 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 372 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 373 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 374 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 375 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 376 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 377 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 378 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 379 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 380 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 381 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 382 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 383 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 384 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 385 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 386 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 387 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 388 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 389 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 390 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 391 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 392 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 393 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 394 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 395 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 396 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 397 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 398 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 399 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 400 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 401 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 402 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 403 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 404 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 405 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 406 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 407 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 408 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 409 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 410 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 411 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 412 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 413 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 414 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 415 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 416 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 417 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 418 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 419 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 420 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 421 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 422 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 423 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 424 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 425 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 426 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 427 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 428 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 429 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 430 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 431 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 432 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 433 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 434 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 435 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 436 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 437 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 438 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 439 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 440 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 441 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 442 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 443 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 444 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 445 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 446 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 447 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 448 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 449 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 450 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 451 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 452 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 453 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 454 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 455 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 456 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 457 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 458 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 459 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 460 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 461 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 462 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 463 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 464 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 465 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 466 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 467 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 468 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 469 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 470 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 471 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 472 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 473 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 474 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 475 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 476 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 477 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 478 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 479 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 480 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 481 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 482 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 483 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 484 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 485 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 486 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 487 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 488 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 489 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 490 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 491 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 492 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 493 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 494 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 495 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 496 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 497 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 498 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 499 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 500 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 501 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 502 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 503 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 504 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 505 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 506 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 507 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 508 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 509 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 510 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 511 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 512 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 513 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 514 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 515 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 516 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 517 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 518 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 519 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 520 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 521 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 522 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 523 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 524 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 525 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 526 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 527 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 528 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 529 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 530 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 531 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 532 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 533 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 534 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 535 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 536 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 537 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 538 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 539 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 540 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 541 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 542 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 543 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 544 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 545 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 546 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 547 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 548 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 549 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 550 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 551 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 552 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 553 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 554 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 555 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 556 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 557 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 558 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 559 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 560 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 561 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 562 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 563 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 564 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 565 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 566 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 567 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 568 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 569 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 570 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 571 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 572 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 573 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 574 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 575 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 576 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 577 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 578 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 579 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 580 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 581 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 582 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 583 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 584 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 585 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 586 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 587 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 588 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 589 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 590 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 591 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 592 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 593 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 594 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 595 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 596 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 597 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 598 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 599 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 600 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 601 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 602 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 603 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 604 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 605 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 606 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 607 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 608 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 609 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 610 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 611 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 612 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 613 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 614 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 615 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 616 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 617 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 618 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 619 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 620 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 621 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 622 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 623 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 624 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 625 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 626 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 627 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 628 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 629 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 630 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 631 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 632 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 633 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 634 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 635 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 636 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 637 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 638 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 639 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 640 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 641 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 642 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 643 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 644 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 645 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 646 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 647 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 648 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 649 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 650 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 651 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 652 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 653 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 654 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 655 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 656 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 657 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 658 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 659 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 660 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 661 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 662 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 663 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 664 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 665 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 666 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 667 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 668 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 669 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 670 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 671 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 672 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 673 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 674 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 675 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 676 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 677 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 678 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 679 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 680 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 681 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 682 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 683 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 684 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 685 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 686 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 687 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 688 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 689 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 690 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 691 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 692 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 693 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 694 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 695 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 696 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 697 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 698 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 699 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 700 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 701 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 702 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 703 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 704 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 705 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 706 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 707 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 708 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 709 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 710 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 711 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 712 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 713 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 714 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 715 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 716 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 726 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 727 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 728 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 729 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 730 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 731 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 736 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 737 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 738 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 739 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 740 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 741 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 742 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 743 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 744 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 745 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 746 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 747 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 748 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 749 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 750 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 751 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 752 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 753 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 754 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 755 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 756 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 757 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 758 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 759 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 760 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 761 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 762 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 763 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 764 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 765 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 766 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 767 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 768 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 769 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 770 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 771 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 772 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 773 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 774 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 775 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 776 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 777 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 778 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 779 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 780 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 781 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 782 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 783 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 784 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 785 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 786 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 787 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 788 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 789 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 790 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 791 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 792 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 793 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 794 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 795 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 796 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 797 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 798 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 799 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 800 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 801 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 802 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 803 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 804 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 805 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 806 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 807 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 808 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 809 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 810 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 811 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 812 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 813 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 814 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 815 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 816 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 817 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 818 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 819 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 820 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 821 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 822 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 823 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 824 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 825 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 826 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 827 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 828 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 829 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 830 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 831 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 832 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 833 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 834 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 835 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 836 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 837 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 838 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 839 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 840 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 841 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 842 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 843 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 844 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 845 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 846 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 847 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 848 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 849 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 850 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 851 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 852 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 853 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 854 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 855 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 856 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 857 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 858 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 859 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 860 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 861 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 862 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 863 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 864 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 865 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 866 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 867 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 868 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 869 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 870 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 871 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 872 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 873 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 874 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 875 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 876 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 877 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 878 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 879 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 880 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 881 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 882 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 883 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 884 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 885 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 886 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 887 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 888 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 889 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 890 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 891 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 892 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 893 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 894 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 895 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 896 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 897 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 898 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 899 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 900 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 901 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 902 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 903 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 904 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 905 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 906 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 907 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 908 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 909 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 910 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 911 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 912 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 913 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 914 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 915 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 916 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 917 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 918 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 919 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 920 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 921 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 922 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 923 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 924 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 925 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 926 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 927 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 928 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 929 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 930 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 931 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 932 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 933 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 934 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 935 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 936 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 937 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 938 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 939 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 940 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 941 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 942 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 943 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 944 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 945 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 946 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 947 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 948 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 949 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 950 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 951 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 952 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 953 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 954 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 955 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 956 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 957 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 958 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 959 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 960 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 961 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 962 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 963 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 964 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 965 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 966 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 967 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 968 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 969 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 970 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 971 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 972 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 973 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 974 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 975 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 976 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 977 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 978 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 979 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 980 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 981 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 982 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 983 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 984 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 985 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 986 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 987 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 988 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 989 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 990 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 991 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 992 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 993 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 994 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 995 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 996 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 997 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 998 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 999 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1000 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1001 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1002 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1003 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1004 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1005 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1006 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1007 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1008 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1009 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1010 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1011 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1012 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1013 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1014 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1015 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1016 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1017 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1018 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1019 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1020 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1021 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1022 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1023 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1024 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1025 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1026 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1027 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1028 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1029 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1030 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1031 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1032 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1033 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1034 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1035 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1036 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1037 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1038 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1039 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1040 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1041 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1042 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1043 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1044 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1045 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1046 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1047 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1048 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1049 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1050 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1051 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1052 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1053 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1054 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1055 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1056 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1057 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1058 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1059 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1060 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1061 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1062 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1063 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1064 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1065 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1066 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1067 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1068 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1069 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1070 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1071 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1072 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1073 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1074 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1075 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1076 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1077 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1078 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1079 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1080 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1081 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1082 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1083 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1084 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1085 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1086 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1087 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1088 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1089 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1090 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1091 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1092 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1093 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1094 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1095 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1096 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1097 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1098 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1099 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1100 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1101 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1102 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1103 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1104 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1105 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1106 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1107 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1108 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1109 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1110 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1111 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1112 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1113 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1114 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1115 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1116 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1117 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1118 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1119 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1120 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1121 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1122 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1123 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1124 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1125 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1126 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1127 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1128 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1129 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1130 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1131 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1132 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1133 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1134 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1135 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1136 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1137 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1138 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1139 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1140 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1141 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1142 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1143 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1144 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1145 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1146 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1147 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1148 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1149 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1150 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1151 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1152 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1153 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1154 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1155 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1156 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1157 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1158 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1159 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1160 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1161 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1162 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1163 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1164 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1165 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1166 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1167 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1168 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1169 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1170 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1171 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1172 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1173 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1174 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1175 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1176 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1177 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1178 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1179 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1180 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1181 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1182 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1183 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1184 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1185 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1186 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1187 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1188 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1189 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1190 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1191 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1192 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1193 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1194 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1195 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1196 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1197 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1198 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1199 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1200 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1201 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1202 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1203 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1204 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1205 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1206 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1207 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1208 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1209 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1210 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1211 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1212 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1213 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1214 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1215 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1216 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1217 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1218 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1219 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1220 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1221 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1222 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1223 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1224 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1225 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1226 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1227 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1228 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1229 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1230 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1231 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1232 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1233 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1234 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1235 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1236 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1237 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1238 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1239 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1240 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1241 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1242 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1243 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1244 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1245 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1246 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1247 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1248 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1249 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1250 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1251 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1252 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1253 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1254 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1255 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1256 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1257 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1258 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1259 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1260 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1261 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1262 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1263 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1264 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1265 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1266 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1267 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1268 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1269 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1270 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1271 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1272 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1273 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1274 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1275 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1279 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1280 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1281 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1282 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1283 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1284 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1285 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1290 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1291 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1292 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1293 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1299 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1300 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1301 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1302 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1303 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1304 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1305 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1306 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1307 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1308 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1309 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1310 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1311 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1312 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1313 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1314 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1315 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1316 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1317 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1318 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1319 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1320 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1321 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1322 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1323 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1324 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1325 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1326 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1327 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1328 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1329 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1330 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1331 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1332 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1333 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1334 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1335 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1336 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1337 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1338 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1339 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1340 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1341 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1342 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1343 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1344 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1345 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1346 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1347 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1348 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1349 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1350 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1351 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1352 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1353 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1354 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1355 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1356 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1357 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1358 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1359 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1360 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1361 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1362 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1363 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1364 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1365 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1366 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1367 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1368 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1369 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1370 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1371 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1372 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1373 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1374 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1375 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1376 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1377 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1378 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1379 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1380 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1381 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1382 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1383 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1384 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1385 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1386 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1387 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1388 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1389 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1390 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1391 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1392 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1393 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1394 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1395 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1396 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1397 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1398 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1399 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1400 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1401 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1402 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1403 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1404 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1405 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1406 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1407 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1408 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1409 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1410 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1411 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1412 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1413 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1414 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1415 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1416 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1417 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1418 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1419 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1420 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1421 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1422 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1423 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1424 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1425 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1426 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1427 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1428 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1429 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1430 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1431 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1432 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1433 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1434 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1435 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1436 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1437 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1438 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1439 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1440 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1441 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1442 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1443 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1444 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1445 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1446 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1447 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1448 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1449 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1450 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1451 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1452 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1453 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1454 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1455 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1456 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1457 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1458 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1459 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1460 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1461 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1462 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1463 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1464 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1465 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1466 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1467 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1468 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1469 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1470 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1471 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1472 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1473 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1474 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1475 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1476 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1477 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1478 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1479 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1480 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1481 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1482 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1483 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1484 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1485 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1486 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1487 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1488 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1489 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1490 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1491 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1492 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1493 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1494 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1495 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1496 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1497 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1498 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1499 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1500 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1501 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1502 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1503 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1504 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1505 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1506 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1507 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1508 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1509 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1510 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1511 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1512 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1513 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1514 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1515 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1516 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1517 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1518 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1519 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1520 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1521 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1522 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1523 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1524 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1525 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1526 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1527 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1528 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1529 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1530 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1531 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1532 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1533 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1534 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1535 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1536 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1537 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1538 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1539 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1540 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1541 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1542 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1543 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1544 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1545 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1546 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1547 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1548 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1549 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1550 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1551 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1552 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1553 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1554 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1555 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1556 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1557 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1558 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1559 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1560 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1561 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1562 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1563 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1564 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1565 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1566 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1567 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1568 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1569 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1570 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1571 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1572 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1573 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1574 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1575 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1576 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1577 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1578 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1579 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1580 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1581 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1582 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1583 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1584 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1585 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1586 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1587 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1588 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1589 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1590 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1591 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1592 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1593 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1594 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1595 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1596 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1597 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1598 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1599 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1600 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1601 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1602 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1603 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1604 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1605 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1606 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1607 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1608 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1609 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1610 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1611 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1612 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1613 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1614 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1615 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1616 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1617 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1618 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1619 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1620 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1621 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1622 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1623 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1624 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1625 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1626 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1627 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1628 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1629 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1630 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1631 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1632 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1633 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1634 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1635 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1636 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1637 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1638 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1639 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1640 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1641 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1642 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1643 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1644 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1645 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1646 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1647 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1648 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1649 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1650 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1651 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1652 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1653 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1654 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1655 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1656 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1657 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1658 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1659 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1660 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1661 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1662 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1663 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1664 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1665 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1666 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1667 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1668 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1669 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1670 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1671 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1672 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1673 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1674 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1675 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1676 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1677 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1678 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1679 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1680 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1681 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1682 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1683 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1684 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1685 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1686 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1687 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1688 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1689 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1690 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1691 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1692 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1693 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1694 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1695 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1696 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1697 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1698 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1699 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1700 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1701 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1702 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1703 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1704 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1705 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1706 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1707 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1708 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1709 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1710 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1711 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1712 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1713 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1714 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1715 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1716 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1726 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1727 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1728 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1729 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1730 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1731 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1736 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1737 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1738 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1739 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1740 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1741 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1742 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1743 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1744 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1745 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1746 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1747 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1748 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1749 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1750 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1751 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1752 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1753 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1754 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1755 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1756 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1757 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1758 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1759 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1760 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1761 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1762 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1763 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1764 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1765 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1766 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1767 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1768 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1769 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1770 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1771 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1772 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1773 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1774 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1775 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1776 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1777 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1778 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1779 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1780 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1781 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1782 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1783 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1784 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1785 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1786 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1787 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1788 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1789 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1790 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1791 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1792 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1793 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1794 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1795 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1796 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1797 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1798 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1799 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1800 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1801 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1802 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1803 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1804 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1805 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1806 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1807 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1808 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1809 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1810 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1811 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1812 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1813 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1814 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1815 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1816 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1817 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1818 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1819 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1820 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1821 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1822 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1823 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1824 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1825 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1826 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1827 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1828 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1829 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1830 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1831 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1832 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1833 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1834 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1835 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1836 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1837 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1838 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1839 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1840 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1841 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1842 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1843 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1844 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1845 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1846 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1847 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1848 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1849 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1850 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1851 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1852 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1853 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1854 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1855 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1856 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1857 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1858 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1859 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1860 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1861 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1862 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1863 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1864 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1865 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1866 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1867 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1868 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1869 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1870 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1871 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1872 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1873 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1874 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1875 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1876 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1877 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1878 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1879 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1880 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1881 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1882 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1883 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1884 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1885 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1886 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1887 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1888 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1889 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1890 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1891 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1892 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1893 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1894 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1895 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1896 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1897 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1898 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1899 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1900 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1901 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1902 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1903 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1904 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1905 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1906 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1907 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1908 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1909 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1910 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1911 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1912 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1913 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1914 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1915 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1916 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1917 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1918 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1919 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1920 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1921 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1922 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1923 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1924 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1925 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1926 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1927 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1928 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1929 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1930 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1931 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1932 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1933 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1934 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1935 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1936 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1937 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1938 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1939 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1940 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1941 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1942 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1943 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1944 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1945 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1946 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1947 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1948 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1949 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1950 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1951 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1952 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1953 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1954 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1955 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1956 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1957 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1958 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1959 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1960 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1961 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1962 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1963 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1964 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1965 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1966 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1967 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1968 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1969 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1970 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1971 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1972 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1973 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1974 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1975 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1976 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1977 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1978 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1979 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1980 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1981 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1982 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1983 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1984 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1985 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1986 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1987 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1988 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1989 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1990 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1991 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1992 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1993 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1994 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1995 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1996 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1997 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1998 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 1999 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2000 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2001 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2002 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2003 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2004 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2005 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2006 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2007 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2008 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2009 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2010 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2011 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2012 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2013 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2014 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2015 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2016 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2017 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2018 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2019 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2020 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2021 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2022 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2023 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2024 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2025 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2026 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2027 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2028 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2029 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2030 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2031 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2032 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2033 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2034 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2035 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2036 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2037 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2038 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2039 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2040 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2041 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2042 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2043 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2044 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2045 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2046 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2047 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2048 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2049 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2050 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2051 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2052 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2053 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2054 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2055 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2056 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2057 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2058 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2059 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2060 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2061 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2062 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2063 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2064 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2065 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2066 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2067 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2068 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2069 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2070 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2071 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2072 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2073 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2074 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2075 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2076 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2077 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2078 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2079 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2080 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2081 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2082 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2083 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2084 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2085 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2086 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2087 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2088 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2089 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2090 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2091 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2092 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2093 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2094 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2095 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2096 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2097 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2098 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2099 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2100 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2101 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2102 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2103 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2104 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2105 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2106 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2107 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2108 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2109 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2110 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2111 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2112 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2113 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2114 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2115 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2116 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2117 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2118 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2119 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2120 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2121 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2122 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2123 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2124 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2125 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2126 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2127 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2128 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2129 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2130 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2131 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2132 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2133 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2134 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2135 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2136 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2137 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2138 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2139 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2140 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2141 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2142 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2143 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2144 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2145 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2146 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2147 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2148 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2149 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2150 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2151 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2152 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2153 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2154 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2155 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2156 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2157 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2158 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2159 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2160 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2161 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2162 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2163 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2164 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2165 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2166 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2167 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2168 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2169 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2170 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2171 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2172 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2173 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2174 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2175 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2176 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2177 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2178 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2179 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2180 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2181 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2182 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2183 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2184 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2185 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2186 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2187 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2188 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2189 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2190 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2191 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2192 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2193 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2194 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2195 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2196 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2197 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2198 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2199 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2200 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2201 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2202 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2203 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2204 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2205 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2206 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2207 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2208 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2209 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2210 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2211 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2212 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2213 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2214 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2215 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2216 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2217 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2218 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2219 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2220 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2221 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2222 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2223 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2224 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2225 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2226 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2227 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2228 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2229 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2230 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2231 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2232 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2233 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2234 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2235 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2236 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2237 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2238 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2239 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2240 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2241 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2242 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2243 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2244 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2245 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2246 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2247 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2248 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2249 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2250 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2251 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2252 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2253 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2254 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2255 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2256 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2257 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2258 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2259 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2260 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2261 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2262 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2263 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2264 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2265 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2266 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2267 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2268 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2269 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2270 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2271 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2272 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2273 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2274 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2275 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2279 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2280 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2281 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2282 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2283 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2284 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2285 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2290 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2291 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2292 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2293 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2299 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2300 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2301 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2302 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2303 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2304 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2305 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2306 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2307 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2308 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2309 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2310 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2311 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2312 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2313 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2314 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2315 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2316 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2317 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2318 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2319 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2320 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2321 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2322 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2323 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2324 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2325 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2326 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2327 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2328 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2329 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2330 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2331 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2332 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2333 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2334 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2335 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2336 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2337 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2338 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2339 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2340 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2341 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2342 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2343 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2344 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2345 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2346 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2347 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2348 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2349 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2350 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2351 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2352 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2353 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2354 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2355 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2356 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2357 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2358 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2359 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2360 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2361 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2362 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2363 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2364 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2365 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2366 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2367 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2368 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2369 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2370 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2371 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2372 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2373 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2374 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2375 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2376 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2377 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2378 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2379 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2380 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2381 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2382 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2383 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2384 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2385 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2386 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2387 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2388 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2389 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2390 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2391 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2392 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2393 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2394 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2395 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2396 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2397 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2398 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2399 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2400 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2401 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2402 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2403 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2404 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2405 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2406 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2407 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2408 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2409 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2410 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2411 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2412 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2413 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2414 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2415 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2416 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2417 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2418 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2419 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2420 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2421 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2422 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2423 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2424 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2425 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2426 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2427 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2428 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2429 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2430 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2431 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2432 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2433 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2434 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2435 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2436 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2437 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2438 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2439 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2440 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2441 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2442 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2443 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2444 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2445 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2446 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2447 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2448 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2449 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2450 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2451 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2452 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2453 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2454 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2455 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2456 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2457 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2458 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2459 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2460 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2461 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2462 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2463 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2464 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2465 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2466 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2467 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2468 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2469 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2470 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2471 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2472 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2473 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2474 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2475 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2476 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2477 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2478 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2479 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2480 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2481 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2482 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2483 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2484 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2485 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2486 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2487 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2488 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2489 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2490 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2491 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2492 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2493 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2494 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2495 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2496 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2497 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2498 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2499 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2500 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2501 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2502 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2503 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2504 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2505 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2506 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2507 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2508 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2509 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2510 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2511 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2512 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2513 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2514 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2515 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2516 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2517 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2518 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2519 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2520 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2521 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2522 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2523 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2524 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2525 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2526 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2527 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2528 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2529 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2530 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2531 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2532 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2533 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2534 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2535 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2536 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2537 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2538 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2539 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2540 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2541 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2542 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2543 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2544 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2545 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2546 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2547 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2548 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2549 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2550 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2551 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2552 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2553 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2554 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2555 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2556 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2557 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2558 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2559 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2560 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2561 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2562 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2563 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2564 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2565 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2566 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2567 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2568 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2569 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2570 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2571 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2572 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2573 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2574 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2575 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2576 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2577 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2578 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2579 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2580 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2581 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2582 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2583 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2584 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2585 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2586 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2587 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2588 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2589 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2590 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2591 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2592 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2593 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2594 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2595 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2596 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2597 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2598 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2599 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2600 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2601 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2602 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2603 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2604 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2605 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2606 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2607 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2608 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2609 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2610 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2611 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2612 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2613 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2614 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2615 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2616 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2617 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2618 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2619 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2620 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2621 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2622 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2623 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2624 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2625 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2626 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2627 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2628 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2629 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2630 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2631 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2632 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2633 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2634 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2635 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2636 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2637 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2638 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2639 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2640 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2641 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2642 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2643 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2644 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2645 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2646 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2647 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2648 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2649 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2650 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2651 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2652 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2653 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2654 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2655 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2656 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2657 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2658 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2659 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2660 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2661 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2662 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2663 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2664 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2665 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2666 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2667 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2668 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2669 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2670 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2671 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2672 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2673 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2674 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2675 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2676 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2677 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2678 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2679 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2680 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2681 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2682 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2683 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2684 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2685 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2686 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2687 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2688 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2689 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2690 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2691 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2692 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2693 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2694 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2695 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2696 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2697 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2698 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2699 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2700 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2701 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2702 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2703 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2704 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2705 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2706 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2707 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2708 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2709 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2710 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2711 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2712 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2713 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2714 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2715 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2716 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2726 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2727 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2728 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2729 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2730 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2731 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2736 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2737 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2738 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2739 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2740 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2741 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2742 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2743 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2744 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2745 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2746 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2747 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2748 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2749 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2750 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2751 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2752 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2753 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2754 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2755 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2756 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2757 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2758 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2759 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2760 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2761 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2762 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2763 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2764 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2765 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2766 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2767 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2768 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2769 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2770 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2771 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2772 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2773 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2774 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2775 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2776 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2777 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2778 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2779 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2780 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2781 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2782 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2783 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2784 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2785 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2786 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2787 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2788 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2789 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2790 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2791 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2792 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2793 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2794 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2795 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2796 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2797 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2798 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2799 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2800 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2801 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2802 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2803 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2804 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2805 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2806 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2807 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2808 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2809 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2810 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2811 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2812 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2813 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2814 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2815 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2816 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2817 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2818 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2819 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2820 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2821 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2822 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2823 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2824 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2825 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2826 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2827 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2828 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2829 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2830 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2831 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2832 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2833 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2834 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2835 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2836 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2837 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2838 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2839 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2840 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2841 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2842 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2843 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2844 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2845 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2846 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2847 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2848 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2849 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2850 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2851 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2852 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2853 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2854 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2855 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2856 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2857 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2858 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2859 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2860 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2861 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2862 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2863 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2864 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2865 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2866 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2867 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2868 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2869 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2870 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2871 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2872 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2873 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2874 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2875 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2876 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2877 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2878 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2879 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2880 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2881 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2882 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2883 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2884 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2885 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2886 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2887 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2888 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2889 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2890 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2891 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2892 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2893 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2894 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2895 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2896 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2897 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2898 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2899 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2900 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2901 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2902 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2903 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2904 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2905 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2906 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2907 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2908 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2909 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2910 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2911 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2912 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2913 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2914 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2915 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2916 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2917 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2918 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2919 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2920 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2921 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2922 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2923 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2924 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2925 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2926 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2927 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2928 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2929 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2930 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2931 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2932 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2933 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2934 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2935 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2936 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2937 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2938 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2939 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2940 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2941 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2942 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2943 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2944 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2945 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2946 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2947 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2948 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2949 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2950 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2951 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2952 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2953 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2954 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2955 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2956 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2957 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2958 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2959 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2960 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2961 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2962 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2963 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2964 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2965 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2966 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2967 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2968 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2969 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2970 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2971 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2972 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2973 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2974 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2975 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2976 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2977 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2978 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2979 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2980 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2981 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2982 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2983 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2984 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2985 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2986 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2987 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2988 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2989 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2990 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2991 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2992 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2993 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2994 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2995 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2996 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2997 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2998 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 2999 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3000 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3001 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3002 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3003 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3004 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3005 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3006 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3007 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3008 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3009 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3010 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3011 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3012 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3013 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3014 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3015 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3016 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3017 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3018 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3019 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3020 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3021 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3022 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3023 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3024 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3025 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3026 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3027 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3028 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3029 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3030 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3031 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3032 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3033 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3034 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3035 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3036 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3037 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3038 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3039 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3040 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3041 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3042 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3043 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3044 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3045 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3046 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3047 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3048 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3049 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3050 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3051 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3052 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3053 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3054 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3055 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3056 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3057 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3058 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3059 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3060 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3061 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3062 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3063 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3064 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3065 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3066 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3067 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3068 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3069 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3070 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3071 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3072 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3073 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3074 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3075 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3076 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3077 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3078 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3079 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3080 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3081 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3082 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3083 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3084 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3085 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3086 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3087 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3088 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3089 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3090 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3091 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3092 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3093 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3094 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3095 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3096 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3097 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3098 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3099 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3100 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3101 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3102 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3103 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3104 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3105 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3106 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3107 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3108 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3109 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3110 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3111 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3112 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3113 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3114 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3115 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3116 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3117 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3118 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3119 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3120 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3121 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3122 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3123 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3124 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3125 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3126 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3127 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3128 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3129 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3130 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3131 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3132 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3133 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3134 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3135 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3136 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3137 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3138 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3139 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3140 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3141 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3142 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3143 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3144 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3145 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3146 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3147 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3148 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3149 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3150 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3151 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3152 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3153 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3154 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3155 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3156 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3157 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3158 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3159 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3160 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3161 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3162 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3163 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3164 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3165 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3166 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3167 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3168 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3169 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3170 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3171 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3172 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3173 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3174 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3175 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3176 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3177 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3178 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3179 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3180 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3181 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3182 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3183 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3184 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3185 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3186 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3187 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3188 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3189 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3190 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3191 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3192 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3193 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3194 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3195 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3196 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3197 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3198 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3199 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3200 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3201 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3202 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3203 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3204 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3205 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3206 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3207 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3208 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3209 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3210 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3211 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3212 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3213 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3214 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3215 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3216 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3217 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3218 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3219 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3220 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3221 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3222 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3223 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3224 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3225 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3226 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3227 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3228 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3229 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3230 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3231 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3232 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3233 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3234 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3235 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3236 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3237 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3238 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3239 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3240 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3241 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3242 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3243 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3244 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3245 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3246 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3247 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3248 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3249 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3250 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3251 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3252 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3253 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3254 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3255 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3256 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3257 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3258 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3259 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3260 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3261 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3262 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3263 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3264 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3265 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3266 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3267 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3268 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3269 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3270 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3271 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3272 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3273 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3274 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3275 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3279 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3280 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3281 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3282 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3283 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3284 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3285 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3290 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3291 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3292 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3293 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3299 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3300 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3301 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3302 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3303 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3304 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3305 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3306 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3307 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3308 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3309 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3310 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3311 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3312 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3313 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3314 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3315 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3316 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3317 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3318 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3319 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3320 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3321 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3322 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3323 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3324 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3325 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3326 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3327 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3328 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3329 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3330 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3331 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3332 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3333 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3334 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3335 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3336 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3337 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3338 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3339 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3340 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3341 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3342 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3343 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3344 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3345 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3346 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3347 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3348 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3349 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3350 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3351 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3352 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3353 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3354 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3355 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3356 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3357 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3358 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3359 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3360 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3361 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3362 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3363 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3364 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3365 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3366 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3367 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3368 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3369 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3370 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3371 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3372 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3373 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3374 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3375 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3376 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3377 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3378 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3379 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3380 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3381 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3382 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3383 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3384 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3385 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3386 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3387 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3388 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3389 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3390 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3391 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3392 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3393 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3394 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3395 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3396 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3397 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3398 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3399 loss: tensor(9.9984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3400 loss: tensor(9.9973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3401 loss: tensor(9.9968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3402 loss: tensor(9.9964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3403 loss: tensor(9.9964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3404 loss: tensor(9.9966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3405 loss: tensor(9.9969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3406 loss: tensor(9.9973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3407 loss: tensor(9.9979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3408 loss: tensor(9.9984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3409 loss: tensor(9.9991e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3410 loss: tensor(9.9998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3411 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3412 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3413 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3414 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3415 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3416 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3417 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3418 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3419 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3420 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3421 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3422 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3423 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3424 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3425 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3426 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3427 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3428 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3429 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3430 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3431 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3432 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3433 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3434 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3435 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3436 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3437 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3438 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3439 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3440 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3441 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3442 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3443 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3444 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3445 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3446 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3447 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3448 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3449 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3450 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3451 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3452 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3453 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3454 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3455 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3456 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3457 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3458 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3459 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3460 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3461 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3462 loss: tensor(9.9902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3463 loss: tensor(9.9832e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3464 loss: tensor(9.9883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3465 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3466 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3467 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3468 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3469 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3470 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3471 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3472 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3473 loss: tensor(9.9928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3474 loss: tensor(9.9829e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3475 loss: tensor(9.9767e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3476 loss: tensor(9.9741e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3477 loss: tensor(9.9744e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3478 loss: tensor(9.9763e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3479 loss: tensor(9.9791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3480 loss: tensor(9.9814e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3481 loss: tensor(9.9830e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3482 loss: tensor(9.9837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3483 loss: tensor(9.9834e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3484 loss: tensor(9.9825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3485 loss: tensor(9.9811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3486 loss: tensor(9.9797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3487 loss: tensor(9.9786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3488 loss: tensor(9.9778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3489 loss: tensor(9.9774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3490 loss: tensor(9.9772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3491 loss: tensor(9.9774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3492 loss: tensor(9.9779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3493 loss: tensor(9.9782e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3494 loss: tensor(9.9783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3495 loss: tensor(9.9785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3496 loss: tensor(9.9786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3497 loss: tensor(9.9787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3498 loss: tensor(9.9790e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3499 loss: tensor(9.9794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3500 loss: tensor(9.9800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3501 loss: tensor(9.9811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3502 loss: tensor(9.9824e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3503 loss: tensor(9.9842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3504 loss: tensor(9.9868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3505 loss: tensor(9.9903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3506 loss: tensor(9.9950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3507 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3508 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3509 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3510 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3511 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3512 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3513 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3514 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3515 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3516 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3517 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3518 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3519 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3520 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3521 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3522 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3523 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3524 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3525 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3526 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3527 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3528 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3529 loss: tensor(9.9813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3530 loss: tensor(9.9898e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3531 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3532 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3533 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3534 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3535 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3536 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3537 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3538 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3539 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3540 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3541 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3542 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3543 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3544 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3545 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3546 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3547 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3548 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3549 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3550 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3551 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3552 loss: tensor(9.9510e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3553 loss: tensor(9.9676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3554 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3555 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3556 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3557 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3558 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3559 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3560 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3561 loss: tensor(9.9922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3562 loss: tensor(9.9533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3563 loss: tensor(9.9460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3564 loss: tensor(9.9636e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3565 loss: tensor(9.9934e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3566 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3567 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3568 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3569 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3570 loss: tensor(9.9963e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3571 loss: tensor(9.9715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3572 loss: tensor(9.9528e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3573 loss: tensor(9.9434e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3574 loss: tensor(9.9435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3575 loss: tensor(9.9503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3576 loss: tensor(9.9599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3577 loss: tensor(9.9681e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3578 loss: tensor(9.9725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3579 loss: tensor(9.9723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3580 loss: tensor(9.9678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3581 loss: tensor(9.9605e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3582 loss: tensor(9.9522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3583 loss: tensor(9.9449e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3584 loss: tensor(9.9400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3585 loss: tensor(9.9376e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3586 loss: tensor(9.9377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3587 loss: tensor(9.9395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3588 loss: tensor(9.9419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3589 loss: tensor(9.9442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3590 loss: tensor(9.9457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3591 loss: tensor(9.9462e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3592 loss: tensor(9.9456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3593 loss: tensor(9.9440e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3594 loss: tensor(9.9420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3595 loss: tensor(9.9398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3596 loss: tensor(9.9374e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3597 loss: tensor(9.9356e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3598 loss: tensor(9.9343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3599 loss: tensor(9.9333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3600 loss: tensor(9.9328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3601 loss: tensor(9.9329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3602 loss: tensor(9.9330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3603 loss: tensor(9.9331e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3604 loss: tensor(9.9334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3605 loss: tensor(9.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3606 loss: tensor(9.9338e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3607 loss: tensor(9.9337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3608 loss: tensor(9.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3609 loss: tensor(9.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3610 loss: tensor(9.9334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3611 loss: tensor(9.9333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3612 loss: tensor(9.9333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3613 loss: tensor(9.9332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3614 loss: tensor(9.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3615 loss: tensor(9.9342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3616 loss: tensor(9.9354e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3617 loss: tensor(9.9372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3618 loss: tensor(9.9400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3619 loss: tensor(9.9446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3620 loss: tensor(9.9514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3621 loss: tensor(9.9617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3622 loss: tensor(9.9772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3623 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3624 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3625 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3626 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3627 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3628 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3629 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3630 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3631 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3632 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3633 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3634 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3635 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3636 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3637 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3638 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3639 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3640 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3641 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3642 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3643 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3644 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3645 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3646 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3647 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3648 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3649 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3650 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3651 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3652 loss: tensor(9.9272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3653 loss: tensor(9.9343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3654 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3655 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3656 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3657 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3658 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3659 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3660 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3661 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3662 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3663 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3664 loss: tensor(9.9828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3665 loss: tensor(9.9392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3666 loss: tensor(9.9135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3667 loss: tensor(9.9145e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3668 loss: tensor(9.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3669 loss: tensor(9.9542e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3670 loss: tensor(9.9632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3671 loss: tensor(9.9582e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3672 loss: tensor(9.9466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3673 loss: tensor(9.9375e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3674 loss: tensor(9.9366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3675 loss: tensor(9.9423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3676 loss: tensor(9.9482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3677 loss: tensor(9.9484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3678 loss: tensor(9.9418e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3679 loss: tensor(9.9309e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3680 loss: tensor(9.9209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3681 loss: tensor(9.9152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3682 loss: tensor(9.9142e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3683 loss: tensor(9.9157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3684 loss: tensor(9.9167e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3685 loss: tensor(9.9152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3686 loss: tensor(9.9116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3687 loss: tensor(9.9075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3688 loss: tensor(9.9045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3689 loss: tensor(9.9036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3690 loss: tensor(9.9047e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3691 loss: tensor(9.9063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3692 loss: tensor(9.9073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3693 loss: tensor(9.9072e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3694 loss: tensor(9.9060e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3695 loss: tensor(9.9046e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3696 loss: tensor(9.9036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3697 loss: tensor(9.9035e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3698 loss: tensor(9.9044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3699 loss: tensor(9.9055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3700 loss: tensor(9.9065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3701 loss: tensor(9.9071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3702 loss: tensor(9.9074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3703 loss: tensor(9.9079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3704 loss: tensor(9.9086e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3705 loss: tensor(9.9101e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3706 loss: tensor(9.9126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3707 loss: tensor(9.9161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3708 loss: tensor(9.9212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3709 loss: tensor(9.9277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3710 loss: tensor(9.9362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3711 loss: tensor(9.9476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3712 loss: tensor(9.9633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3713 loss: tensor(9.9847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3714 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3715 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3716 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3726 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3727 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3728 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3729 loss: tensor(9.9515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3730 loss: tensor(9.8951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3731 loss: tensor(9.9385e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3736 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3737 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3738 loss: tensor(9.9543e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3739 loss: tensor(9.9068e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3740 loss: tensor(9.9017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3741 loss: tensor(9.9278e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3742 loss: tensor(9.9646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3743 loss: tensor(9.9922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3744 loss: tensor(9.9985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3745 loss: tensor(9.9827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3746 loss: tensor(9.9529e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3747 loss: tensor(9.9218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3748 loss: tensor(9.9001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3749 loss: tensor(9.8929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3750 loss: tensor(9.8984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3751 loss: tensor(9.9106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3752 loss: tensor(9.9227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3753 loss: tensor(9.9289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3754 loss: tensor(9.9270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3755 loss: tensor(9.9179e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3756 loss: tensor(9.9052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3757 loss: tensor(9.8931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3758 loss: tensor(9.8850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3759 loss: tensor(9.8822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3760 loss: tensor(9.8843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3761 loss: tensor(9.8893e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3762 loss: tensor(9.8947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3763 loss: tensor(9.8984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3764 loss: tensor(9.8994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3765 loss: tensor(9.8973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3766 loss: tensor(9.8934e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3767 loss: tensor(9.8884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3768 loss: tensor(9.8837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3769 loss: tensor(9.8802e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3770 loss: tensor(9.8785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3771 loss: tensor(9.8781e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3772 loss: tensor(9.8789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3773 loss: tensor(9.8798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3774 loss: tensor(9.8805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3775 loss: tensor(9.8808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3776 loss: tensor(9.8805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3777 loss: tensor(9.8797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3778 loss: tensor(9.8783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3779 loss: tensor(9.8770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3780 loss: tensor(9.8756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3781 loss: tensor(9.8746e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3782 loss: tensor(9.8739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3783 loss: tensor(9.8734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3784 loss: tensor(9.8733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3785 loss: tensor(9.8733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3786 loss: tensor(9.8735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3787 loss: tensor(9.8735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3788 loss: tensor(9.8736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3789 loss: tensor(9.8734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3790 loss: tensor(9.8732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3791 loss: tensor(9.8728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3792 loss: tensor(9.8724e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3793 loss: tensor(9.8718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3794 loss: tensor(9.8714e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3795 loss: tensor(9.8709e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3796 loss: tensor(9.8706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3797 loss: tensor(9.8703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3798 loss: tensor(9.8702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3799 loss: tensor(9.8703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3800 loss: tensor(9.8706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3801 loss: tensor(9.8714e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3802 loss: tensor(9.8725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3803 loss: tensor(9.8744e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3804 loss: tensor(9.8770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3805 loss: tensor(9.8809e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3806 loss: tensor(9.8866e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3807 loss: tensor(9.8948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3808 loss: tensor(9.9069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3809 loss: tensor(9.9248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3810 loss: tensor(9.9509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3811 loss: tensor(9.9892e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3812 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3813 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3814 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3815 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3816 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3817 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3818 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3819 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3820 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3821 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3822 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3823 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3824 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3825 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3826 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3827 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3828 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3829 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3830 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3831 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3832 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3833 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3834 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3835 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3836 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3837 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3838 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3839 loss: tensor(9.9456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3840 loss: tensor(9.9227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3841 loss: tensor(9.9615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3842 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3843 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3844 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3845 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3846 loss: tensor(9.9521e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3847 loss: tensor(9.8977e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3848 loss: tensor(9.8768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3849 loss: tensor(9.8850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3850 loss: tensor(9.9030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3851 loss: tensor(9.9120e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3852 loss: tensor(9.9046e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3853 loss: tensor(9.8870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3854 loss: tensor(9.8716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3855 loss: tensor(9.8680e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3856 loss: tensor(9.8770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3857 loss: tensor(9.8916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3858 loss: tensor(9.9021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3859 loss: tensor(9.9029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3860 loss: tensor(9.8941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3861 loss: tensor(9.8806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3862 loss: tensor(9.8689e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3863 loss: tensor(9.8625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3864 loss: tensor(9.8618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3865 loss: tensor(9.8637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3866 loss: tensor(9.8646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3867 loss: tensor(9.8623e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3868 loss: tensor(9.8573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3869 loss: tensor(9.8514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3870 loss: tensor(9.8468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3871 loss: tensor(9.8449e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3872 loss: tensor(9.8457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3873 loss: tensor(9.8480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3874 loss: tensor(9.8501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3875 loss: tensor(9.8509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3876 loss: tensor(9.8505e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3877 loss: tensor(9.8491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3878 loss: tensor(9.8477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3879 loss: tensor(9.8469e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3880 loss: tensor(9.8472e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3881 loss: tensor(9.8485e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3882 loss: tensor(9.8505e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3883 loss: tensor(9.8522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3884 loss: tensor(9.8539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3885 loss: tensor(9.8552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3886 loss: tensor(9.8566e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3887 loss: tensor(9.8583e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3888 loss: tensor(9.8608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3889 loss: tensor(9.8647e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3890 loss: tensor(9.8702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3891 loss: tensor(9.8774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3892 loss: tensor(9.8867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3893 loss: tensor(9.8985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3894 loss: tensor(9.9138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3895 loss: tensor(9.9338e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3896 loss: tensor(9.9599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3897 loss: tensor(9.9941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3898 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3899 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3900 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3901 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3902 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3903 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3904 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3905 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3906 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3907 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3908 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3909 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3910 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3911 loss: tensor(9.9599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3912 loss: tensor(9.8693e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3913 loss: tensor(9.8407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3914 loss: tensor(9.8648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3915 loss: tensor(9.9191e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3916 loss: tensor(9.9779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3917 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3918 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3919 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3920 loss: tensor(9.9746e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3921 loss: tensor(9.9263e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3922 loss: tensor(9.8831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3923 loss: tensor(9.8545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3924 loss: tensor(9.8438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3925 loss: tensor(9.8481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3926 loss: tensor(9.8610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3927 loss: tensor(9.8752e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3928 loss: tensor(9.8849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3929 loss: tensor(9.8870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3930 loss: tensor(9.8817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3931 loss: tensor(9.8706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3932 loss: tensor(9.8574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3933 loss: tensor(9.8456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3934 loss: tensor(9.8373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3935 loss: tensor(9.8334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3936 loss: tensor(9.8339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3937 loss: tensor(9.8372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3938 loss: tensor(9.8414e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3939 loss: tensor(9.8452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3940 loss: tensor(9.8471e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3941 loss: tensor(9.8468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3942 loss: tensor(9.8442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3943 loss: tensor(9.8399e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3944 loss: tensor(9.8349e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3945 loss: tensor(9.8300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3946 loss: tensor(9.8257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3947 loss: tensor(9.8227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3948 loss: tensor(9.8208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3949 loss: tensor(9.8200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3950 loss: tensor(9.8203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3951 loss: tensor(9.8210e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3952 loss: tensor(9.8222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3953 loss: tensor(9.8234e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3954 loss: tensor(9.8245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3955 loss: tensor(9.8250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3956 loss: tensor(9.8254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3957 loss: tensor(9.8251e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3958 loss: tensor(9.8246e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3959 loss: tensor(9.8240e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3960 loss: tensor(9.8233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3961 loss: tensor(9.8225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3962 loss: tensor(9.8219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3963 loss: tensor(9.8217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3964 loss: tensor(9.8216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3965 loss: tensor(9.8220e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3966 loss: tensor(9.8227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3967 loss: tensor(9.8241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3968 loss: tensor(9.8260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3969 loss: tensor(9.8288e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3970 loss: tensor(9.8328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3971 loss: tensor(9.8381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3972 loss: tensor(9.8452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3973 loss: tensor(9.8549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3974 loss: tensor(9.8678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3975 loss: tensor(9.8856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3976 loss: tensor(9.9096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3977 loss: tensor(9.9424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3978 loss: tensor(9.9871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3979 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3980 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3981 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3982 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3983 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3984 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3985 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3986 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3987 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3988 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3989 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3990 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3991 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3992 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3993 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3994 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3995 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3996 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3997 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3998 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 3999 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4000 loss: tensor(9.8805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4001 loss: tensor(9.8141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4002 loss: tensor(9.8267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4003 loss: tensor(9.8953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4004 loss: tensor(9.9802e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4005 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4006 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4007 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4008 loss: tensor(9.9762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4009 loss: tensor(9.9104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4010 loss: tensor(9.8589e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4011 loss: tensor(9.8327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4012 loss: tensor(9.8303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4013 loss: tensor(9.8423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4014 loss: tensor(9.8565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4015 loss: tensor(9.8639e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4016 loss: tensor(9.8614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4017 loss: tensor(9.8515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4018 loss: tensor(9.8400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4019 loss: tensor(9.8320e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4020 loss: tensor(9.8298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4021 loss: tensor(9.8327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4022 loss: tensor(9.8376e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4023 loss: tensor(9.8409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4024 loss: tensor(9.8398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4025 loss: tensor(9.8339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4026 loss: tensor(9.8239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4027 loss: tensor(9.8127e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4028 loss: tensor(9.8030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4029 loss: tensor(9.7967e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4030 loss: tensor(9.7947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4031 loss: tensor(9.7957e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4032 loss: tensor(9.7993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4033 loss: tensor(9.8031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4034 loss: tensor(9.8062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4035 loss: tensor(9.8077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4036 loss: tensor(9.8075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4037 loss: tensor(9.8061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4038 loss: tensor(9.8040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4039 loss: tensor(9.8019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4040 loss: tensor(9.8002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4041 loss: tensor(9.7994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4042 loss: tensor(9.7993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4043 loss: tensor(9.7994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4044 loss: tensor(9.7998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4045 loss: tensor(9.8002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4046 loss: tensor(9.8004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4047 loss: tensor(9.8001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4048 loss: tensor(9.7998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4049 loss: tensor(9.7992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4050 loss: tensor(9.7985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4051 loss: tensor(9.7979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4052 loss: tensor(9.7976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4053 loss: tensor(9.7976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4054 loss: tensor(9.7980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4055 loss: tensor(9.7989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4056 loss: tensor(9.8003e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4057 loss: tensor(9.8022e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4058 loss: tensor(9.8048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4059 loss: tensor(9.8082e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4060 loss: tensor(9.8125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4061 loss: tensor(9.8185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4062 loss: tensor(9.8264e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4063 loss: tensor(9.8368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4064 loss: tensor(9.8504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4065 loss: tensor(9.8684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4066 loss: tensor(9.8922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4067 loss: tensor(9.9239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4068 loss: tensor(9.9647e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4069 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4070 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4071 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4072 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4073 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4074 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4075 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4076 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4077 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4078 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4079 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4080 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4081 loss: tensor(9.9944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4082 loss: tensor(9.8757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4083 loss: tensor(9.8332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4084 loss: tensor(9.8593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4085 loss: tensor(9.9270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4086 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4087 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4088 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4089 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4090 loss: tensor(9.9788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4091 loss: tensor(9.9101e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4092 loss: tensor(9.8527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4093 loss: tensor(9.8204e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4094 loss: tensor(9.8161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4095 loss: tensor(9.8333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4096 loss: tensor(9.8603e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4097 loss: tensor(9.8848e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4098 loss: tensor(9.8978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4099 loss: tensor(9.8957e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4100 loss: tensor(9.8806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4101 loss: tensor(9.8585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4102 loss: tensor(9.8369e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4103 loss: tensor(9.8214e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4104 loss: tensor(9.8156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4105 loss: tensor(9.8197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4106 loss: tensor(9.8312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4107 loss: tensor(9.8464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4108 loss: tensor(9.8618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4109 loss: tensor(9.8755e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4110 loss: tensor(9.8859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4111 loss: tensor(9.8944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4112 loss: tensor(9.9021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4113 loss: tensor(9.9114e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4114 loss: tensor(9.9247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4115 loss: tensor(9.9432e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4116 loss: tensor(9.9675e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4117 loss: tensor(9.9969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4118 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4119 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4120 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4121 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4122 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4123 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4124 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4125 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4126 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4127 loss: tensor(9.9815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4128 loss: tensor(9.9226e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4129 loss: tensor(9.8673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4130 loss: tensor(9.8211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4131 loss: tensor(9.7879e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4132 loss: tensor(9.7688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4133 loss: tensor(9.7627e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4134 loss: tensor(9.7668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4135 loss: tensor(9.7779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4136 loss: tensor(9.7925e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4137 loss: tensor(9.8079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4138 loss: tensor(9.8216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4139 loss: tensor(9.8319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4140 loss: tensor(9.8378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4141 loss: tensor(9.8393e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4142 loss: tensor(9.8365e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4143 loss: tensor(9.8302e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4144 loss: tensor(9.8215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4145 loss: tensor(9.8115e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4146 loss: tensor(9.8016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4147 loss: tensor(9.7921e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4148 loss: tensor(9.7836e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4149 loss: tensor(9.7766e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4150 loss: tensor(9.7713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4151 loss: tensor(9.7674e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4152 loss: tensor(9.7647e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4153 loss: tensor(9.7630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4154 loss: tensor(9.7622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4155 loss: tensor(9.7619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4156 loss: tensor(9.7621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4157 loss: tensor(9.7628e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4158 loss: tensor(9.7634e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4159 loss: tensor(9.7641e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4160 loss: tensor(9.7650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4161 loss: tensor(9.7659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4162 loss: tensor(9.7668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4163 loss: tensor(9.7676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4164 loss: tensor(9.7686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4165 loss: tensor(9.7697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4166 loss: tensor(9.7708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4167 loss: tensor(9.7724e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4168 loss: tensor(9.7743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4169 loss: tensor(9.7770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4170 loss: tensor(9.7803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4171 loss: tensor(9.7844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4172 loss: tensor(9.7897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4173 loss: tensor(9.7965e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4174 loss: tensor(9.8051e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4175 loss: tensor(9.8161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4176 loss: tensor(9.8304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4177 loss: tensor(9.8488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4178 loss: tensor(9.8726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4179 loss: tensor(9.9032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4180 loss: tensor(9.9424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4181 loss: tensor(9.9922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4182 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4183 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4184 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4185 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4186 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4187 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4188 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4189 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4190 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4191 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4192 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4193 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4194 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4195 loss: tensor(9.9383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4196 loss: tensor(9.7892e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4197 loss: tensor(9.7427e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4198 loss: tensor(9.7848e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4199 loss: tensor(9.8789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4200 loss: tensor(9.9811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4201 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4202 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4203 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4204 loss: tensor(9.9688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4205 loss: tensor(9.8844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4206 loss: tensor(9.8128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4207 loss: tensor(9.7716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4208 loss: tensor(9.7650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4209 loss: tensor(9.7851e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4210 loss: tensor(9.8173e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4211 loss: tensor(9.8463e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4212 loss: tensor(9.8614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4213 loss: tensor(9.8577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4214 loss: tensor(9.8376e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4215 loss: tensor(9.8078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4216 loss: tensor(9.7769e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4217 loss: tensor(9.7530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4218 loss: tensor(9.7402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4219 loss: tensor(9.7389e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4220 loss: tensor(9.7460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4221 loss: tensor(9.7569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4222 loss: tensor(9.7674e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4223 loss: tensor(9.7734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4224 loss: tensor(9.7742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4225 loss: tensor(9.7697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4226 loss: tensor(9.7613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4227 loss: tensor(9.7518e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4228 loss: tensor(9.7428e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4229 loss: tensor(9.7362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4230 loss: tensor(9.7328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4231 loss: tensor(9.7322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4232 loss: tensor(9.7340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4233 loss: tensor(9.7370e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4234 loss: tensor(9.7401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4235 loss: tensor(9.7424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4236 loss: tensor(9.7434e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4237 loss: tensor(9.7433e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4238 loss: tensor(9.7420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4239 loss: tensor(9.7398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4240 loss: tensor(9.7374e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4241 loss: tensor(9.7350e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4242 loss: tensor(9.7333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4243 loss: tensor(9.7322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4244 loss: tensor(9.7321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4245 loss: tensor(9.7329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4246 loss: tensor(9.7351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4247 loss: tensor(9.7386e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4248 loss: tensor(9.7441e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4249 loss: tensor(9.7522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4250 loss: tensor(9.7642e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4251 loss: tensor(9.7822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4252 loss: tensor(9.8086e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4253 loss: tensor(9.8481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4254 loss: tensor(9.9069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4255 loss: tensor(9.9944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4256 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4257 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4258 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4259 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4260 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4261 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4262 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4263 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4264 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4265 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4266 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4267 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4268 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4269 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4270 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4271 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4272 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4273 loss: tensor(9.8848e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4274 loss: tensor(9.9181e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4275 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4279 loss: tensor(9.9091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4280 loss: tensor(9.7562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4281 loss: tensor(9.7182e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4282 loss: tensor(9.7856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4283 loss: tensor(9.8871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4284 loss: tensor(9.9474e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4285 loss: tensor(9.9327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4286 loss: tensor(9.8631e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4287 loss: tensor(9.7877e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4288 loss: tensor(9.7464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4289 loss: tensor(9.7476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4290 loss: tensor(9.7713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4291 loss: tensor(9.7900e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4292 loss: tensor(9.7892e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4293 loss: tensor(9.7726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4294 loss: tensor(9.7546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4295 loss: tensor(9.7469e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4296 loss: tensor(9.7506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4297 loss: tensor(9.7573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4298 loss: tensor(9.7574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4299 loss: tensor(9.7469e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4300 loss: tensor(9.7305e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4301 loss: tensor(9.7175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4302 loss: tensor(9.7140e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4303 loss: tensor(9.7201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4304 loss: tensor(9.7303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4305 loss: tensor(9.7376e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4306 loss: tensor(9.7375e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4307 loss: tensor(9.7304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4308 loss: tensor(9.7203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4309 loss: tensor(9.7120e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4310 loss: tensor(9.7083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4311 loss: tensor(9.7092e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4312 loss: tensor(9.7123e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4313 loss: tensor(9.7148e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4314 loss: tensor(9.7152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4315 loss: tensor(9.7136e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4316 loss: tensor(9.7112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4317 loss: tensor(9.7094e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4318 loss: tensor(9.7084e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4319 loss: tensor(9.7085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4320 loss: tensor(9.7088e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4321 loss: tensor(9.7083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4322 loss: tensor(9.7072e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4323 loss: tensor(9.7054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4324 loss: tensor(9.7037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4325 loss: tensor(9.7025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4326 loss: tensor(9.7020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4327 loss: tensor(9.7022e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4328 loss: tensor(9.7028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4329 loss: tensor(9.7033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4330 loss: tensor(9.7034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4331 loss: tensor(9.7031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4332 loss: tensor(9.7025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4333 loss: tensor(9.7016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4334 loss: tensor(9.7008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4335 loss: tensor(9.7001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4336 loss: tensor(9.6998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4337 loss: tensor(9.6994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4338 loss: tensor(9.6991e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4339 loss: tensor(9.6986e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4340 loss: tensor(9.6981e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4341 loss: tensor(9.6974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4342 loss: tensor(9.6969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4343 loss: tensor(9.6964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4344 loss: tensor(9.6958e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4345 loss: tensor(9.6955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4346 loss: tensor(9.6951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4347 loss: tensor(9.6948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4348 loss: tensor(9.6946e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4349 loss: tensor(9.6943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4350 loss: tensor(9.6941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4351 loss: tensor(9.6939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4352 loss: tensor(9.6935e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4353 loss: tensor(9.6932e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4354 loss: tensor(9.6929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4355 loss: tensor(9.6926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4356 loss: tensor(9.6923e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4357 loss: tensor(9.6919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4358 loss: tensor(9.6918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4359 loss: tensor(9.6915e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4360 loss: tensor(9.6912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4361 loss: tensor(9.6912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4362 loss: tensor(9.6912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4363 loss: tensor(9.6913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4364 loss: tensor(9.6912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4365 loss: tensor(9.6915e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4366 loss: tensor(9.6919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4367 loss: tensor(9.6927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4368 loss: tensor(9.6938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4369 loss: tensor(9.6955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4370 loss: tensor(9.6979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4371 loss: tensor(9.7015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4372 loss: tensor(9.7066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4373 loss: tensor(9.7138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4374 loss: tensor(9.7243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4375 loss: tensor(9.7396e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4376 loss: tensor(9.7615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4377 loss: tensor(9.7930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4378 loss: tensor(9.8386e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4379 loss: tensor(9.9036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4380 loss: tensor(9.9950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4381 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4382 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4383 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4384 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4385 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4386 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4387 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4388 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4389 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4390 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4391 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4392 loss: tensor(9.9215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4393 loss: tensor(9.9838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4394 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4395 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4396 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4397 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4398 loss: tensor(9.8605e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4399 loss: tensor(9.7256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4400 loss: tensor(9.7056e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4401 loss: tensor(9.7855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4402 loss: tensor(9.8980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4403 loss: tensor(9.9701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4404 loss: tensor(9.9628e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4405 loss: tensor(9.8881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4406 loss: tensor(9.7928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4407 loss: tensor(9.7260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4408 loss: tensor(9.7101e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4409 loss: tensor(9.7340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4410 loss: tensor(9.7672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4411 loss: tensor(9.7810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4412 loss: tensor(9.7653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4413 loss: tensor(9.7299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4414 loss: tensor(9.6962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4415 loss: tensor(9.6810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4416 loss: tensor(9.6885e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4417 loss: tensor(9.7097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4418 loss: tensor(9.7299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4419 loss: tensor(9.7373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4420 loss: tensor(9.7293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4421 loss: tensor(9.7115e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4422 loss: tensor(9.6935e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4423 loss: tensor(9.6829e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4424 loss: tensor(9.6819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4425 loss: tensor(9.6872e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4426 loss: tensor(9.6930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4427 loss: tensor(9.6946e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4428 loss: tensor(9.6904e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4429 loss: tensor(9.6824e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4430 loss: tensor(9.6740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4431 loss: tensor(9.6686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4432 loss: tensor(9.6672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4433 loss: tensor(9.6692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4434 loss: tensor(9.6723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4435 loss: tensor(9.6746e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4436 loss: tensor(9.6749e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4437 loss: tensor(9.6732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4438 loss: tensor(9.6703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4439 loss: tensor(9.6676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4440 loss: tensor(9.6657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4441 loss: tensor(9.6653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4442 loss: tensor(9.6661e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4443 loss: tensor(9.6673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4444 loss: tensor(9.6684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4445 loss: tensor(9.6688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4446 loss: tensor(9.6685e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4447 loss: tensor(9.6678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4448 loss: tensor(9.6672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4449 loss: tensor(9.6669e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4450 loss: tensor(9.6673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4451 loss: tensor(9.6686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4452 loss: tensor(9.6706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4453 loss: tensor(9.6735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4454 loss: tensor(9.6771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4455 loss: tensor(9.6817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4456 loss: tensor(9.6878e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4457 loss: tensor(9.6963e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4458 loss: tensor(9.7082e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4459 loss: tensor(9.7249e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4460 loss: tensor(9.7484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4461 loss: tensor(9.7810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4462 loss: tensor(9.8253e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4463 loss: tensor(9.8858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4464 loss: tensor(9.9665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4465 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4466 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4467 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4468 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4469 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4470 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4471 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4472 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4473 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4474 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4475 loss: tensor(9.8119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4476 loss: tensor(9.6965e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4477 loss: tensor(9.7034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4478 loss: tensor(9.7913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4479 loss: tensor(9.8978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4480 loss: tensor(9.9664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4481 loss: tensor(9.9670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4482 loss: tensor(9.9042e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4483 loss: tensor(9.8106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4484 loss: tensor(9.7288e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4485 loss: tensor(9.6887e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4486 loss: tensor(9.6962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4487 loss: tensor(9.7338e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4488 loss: tensor(9.7743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4489 loss: tensor(9.7939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4490 loss: tensor(9.7826e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4491 loss: tensor(9.7458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4492 loss: tensor(9.7004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4493 loss: tensor(9.6639e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4494 loss: tensor(9.6476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4495 loss: tensor(9.6523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4496 loss: tensor(9.6706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4497 loss: tensor(9.6909e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4498 loss: tensor(9.7038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4499 loss: tensor(9.7048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4500 loss: tensor(9.6947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4501 loss: tensor(9.6792e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4502 loss: tensor(9.6645e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4503 loss: tensor(9.6551e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4504 loss: tensor(9.6529e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4505 loss: tensor(9.6562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4506 loss: tensor(9.6617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4507 loss: tensor(9.6661e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4508 loss: tensor(9.6668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4509 loss: tensor(9.6638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4510 loss: tensor(9.6580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4511 loss: tensor(9.6512e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4512 loss: tensor(9.6455e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4513 loss: tensor(9.6418e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4514 loss: tensor(9.6408e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4515 loss: tensor(9.6415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4516 loss: tensor(9.6435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4517 loss: tensor(9.6454e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4518 loss: tensor(9.6465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4519 loss: tensor(9.6466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4520 loss: tensor(9.6455e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4521 loss: tensor(9.6436e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4522 loss: tensor(9.6415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4523 loss: tensor(9.6396e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4524 loss: tensor(9.6384e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4525 loss: tensor(9.6377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4526 loss: tensor(9.6377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4527 loss: tensor(9.6381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4528 loss: tensor(9.6386e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4529 loss: tensor(9.6392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4530 loss: tensor(9.6394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4531 loss: tensor(9.6397e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4532 loss: tensor(9.6396e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4533 loss: tensor(9.6395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4534 loss: tensor(9.6394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4535 loss: tensor(9.6400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4536 loss: tensor(9.6409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4537 loss: tensor(9.6429e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4538 loss: tensor(9.6458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4539 loss: tensor(9.6502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4540 loss: tensor(9.6569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4541 loss: tensor(9.6665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4542 loss: tensor(9.6805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4543 loss: tensor(9.7007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4544 loss: tensor(9.7298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4545 loss: tensor(9.7714e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4546 loss: tensor(9.8309e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4547 loss: tensor(9.9159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4548 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4549 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4550 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4551 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4552 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4553 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4554 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4555 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4556 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4557 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4558 loss: tensor(9.9337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4559 loss: tensor(9.7808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4560 loss: tensor(9.8456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4561 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4562 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4563 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4564 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4565 loss: tensor(9.8786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4566 loss: tensor(9.6970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4567 loss: tensor(9.6242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4568 loss: tensor(9.6677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4569 loss: tensor(9.7710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4570 loss: tensor(9.8569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4571 loss: tensor(9.8740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4572 loss: tensor(9.8198e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4573 loss: tensor(9.7344e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4574 loss: tensor(9.6697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4575 loss: tensor(9.6560e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4576 loss: tensor(9.6869e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4577 loss: tensor(9.7319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4578 loss: tensor(9.7575e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4579 loss: tensor(9.7477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4580 loss: tensor(9.7098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4581 loss: tensor(9.6660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4582 loss: tensor(9.6378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4583 loss: tensor(9.6340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4584 loss: tensor(9.6481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4585 loss: tensor(9.6653e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4586 loss: tensor(9.6727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4587 loss: tensor(9.6653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4588 loss: tensor(9.6479e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4589 loss: tensor(9.6295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4590 loss: tensor(9.6186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4591 loss: tensor(9.6180e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4592 loss: tensor(9.6248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4593 loss: tensor(9.6334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4594 loss: tensor(9.6379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4595 loss: tensor(9.6363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4596 loss: tensor(9.6295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4597 loss: tensor(9.6214e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4598 loss: tensor(9.6155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4599 loss: tensor(9.6138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4600 loss: tensor(9.6158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4601 loss: tensor(9.6194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4602 loss: tensor(9.6223e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4603 loss: tensor(9.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4604 loss: tensor(9.6213e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4605 loss: tensor(9.6181e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4606 loss: tensor(9.6151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4607 loss: tensor(9.6130e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4608 loss: tensor(9.6127e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4609 loss: tensor(9.6138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4610 loss: tensor(9.6158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4611 loss: tensor(9.6181e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4612 loss: tensor(9.6201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4613 loss: tensor(9.6219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4614 loss: tensor(9.6241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4615 loss: tensor(9.6274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4616 loss: tensor(9.6332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4617 loss: tensor(9.6425e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4618 loss: tensor(9.6569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4619 loss: tensor(9.6780e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4620 loss: tensor(9.7087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4621 loss: tensor(9.7531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4622 loss: tensor(9.8169e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4623 loss: tensor(9.9078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4624 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4625 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4626 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4627 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4628 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4629 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4630 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4631 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4632 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4633 loss: tensor(9.9750e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4634 loss: tensor(9.6769e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4635 loss: tensor(9.6274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4636 loss: tensor(9.7791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4637 loss: tensor(9.9940e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4638 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4639 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4640 loss: tensor(9.9501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4641 loss: tensor(9.7561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4642 loss: tensor(9.6341e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4643 loss: tensor(9.6315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4644 loss: tensor(9.7160e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4645 loss: tensor(9.8102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4646 loss: tensor(9.8458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4647 loss: tensor(9.8017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4648 loss: tensor(9.7104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4649 loss: tensor(9.6287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4650 loss: tensor(9.5980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4651 loss: tensor(9.6218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4652 loss: tensor(9.6705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4653 loss: tensor(9.7063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4654 loss: tensor(9.7068e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4655 loss: tensor(9.6755e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4656 loss: tensor(9.6337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4657 loss: tensor(9.6052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4658 loss: tensor(9.6013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4659 loss: tensor(9.6166e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4660 loss: tensor(9.6361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4661 loss: tensor(9.6454e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4662 loss: tensor(9.6393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4663 loss: tensor(9.6221e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4664 loss: tensor(9.6041e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4665 loss: tensor(9.5941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4666 loss: tensor(9.5951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4667 loss: tensor(9.6033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4668 loss: tensor(9.6121e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4669 loss: tensor(9.6159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4670 loss: tensor(9.6129e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4671 loss: tensor(9.6054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4672 loss: tensor(9.5976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4673 loss: tensor(9.5930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4674 loss: tensor(9.5926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4675 loss: tensor(9.5955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4676 loss: tensor(9.5990e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4677 loss: tensor(9.6007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4678 loss: tensor(9.5998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4679 loss: tensor(9.5968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4680 loss: tensor(9.5929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4681 loss: tensor(9.5900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4682 loss: tensor(9.5887e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4683 loss: tensor(9.5890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4684 loss: tensor(9.5900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4685 loss: tensor(9.5911e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4686 loss: tensor(9.5912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4687 loss: tensor(9.5906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4688 loss: tensor(9.5891e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4689 loss: tensor(9.5877e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4690 loss: tensor(9.5864e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4691 loss: tensor(9.5857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4692 loss: tensor(9.5855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4693 loss: tensor(9.5858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4694 loss: tensor(9.5862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4695 loss: tensor(9.5863e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4696 loss: tensor(9.5862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4697 loss: tensor(9.5858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4698 loss: tensor(9.5853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4699 loss: tensor(9.5848e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4700 loss: tensor(9.5844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4701 loss: tensor(9.5845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4702 loss: tensor(9.5849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4703 loss: tensor(9.5858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4704 loss: tensor(9.5868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4705 loss: tensor(9.5885e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4706 loss: tensor(9.5908e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4707 loss: tensor(9.5942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4708 loss: tensor(9.5989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4709 loss: tensor(9.6061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4710 loss: tensor(9.6168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4711 loss: tensor(9.6328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4712 loss: tensor(9.6565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4713 loss: tensor(9.6916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4714 loss: tensor(9.7434e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4715 loss: tensor(9.8188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4716 loss: tensor(9.9271e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4726 loss: tensor(9.8890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4727 loss: tensor(9.6465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4728 loss: tensor(9.6778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4729 loss: tensor(9.8844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4730 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4731 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4733 loss: tensor(9.8487e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4734 loss: tensor(9.6555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4735 loss: tensor(9.5859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4736 loss: tensor(9.6484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4737 loss: tensor(9.7698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4738 loss: tensor(9.8553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4739 loss: tensor(9.8488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4740 loss: tensor(9.7616e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4741 loss: tensor(9.6541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4742 loss: tensor(9.5881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4743 loss: tensor(9.5887e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4744 loss: tensor(9.6351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4745 loss: tensor(9.6826e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4746 loss: tensor(9.6955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4747 loss: tensor(9.6671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4748 loss: tensor(9.6180e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4749 loss: tensor(9.5796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4750 loss: tensor(9.5706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4751 loss: tensor(9.5884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4752 loss: tensor(9.6155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4753 loss: tensor(9.6316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4754 loss: tensor(9.6277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4755 loss: tensor(9.6083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4756 loss: tensor(9.5859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4757 loss: tensor(9.5729e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4758 loss: tensor(9.5736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4759 loss: tensor(9.5831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4760 loss: tensor(9.5931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4761 loss: tensor(9.5962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4762 loss: tensor(9.5910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4763 loss: tensor(9.5804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4764 loss: tensor(9.5703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4765 loss: tensor(9.5652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4766 loss: tensor(9.5659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4767 loss: tensor(9.5702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4768 loss: tensor(9.5743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4769 loss: tensor(9.5756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4770 loss: tensor(9.5733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4771 loss: tensor(9.5688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4772 loss: tensor(9.5644e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4773 loss: tensor(9.5617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4774 loss: tensor(9.5615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4775 loss: tensor(9.5630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4776 loss: tensor(9.5648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4777 loss: tensor(9.5661e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4778 loss: tensor(9.5658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4779 loss: tensor(9.5645e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4780 loss: tensor(9.5629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4781 loss: tensor(9.5616e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4782 loss: tensor(9.5611e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4783 loss: tensor(9.5619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4784 loss: tensor(9.5635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4785 loss: tensor(9.5656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4786 loss: tensor(9.5682e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4787 loss: tensor(9.5711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4788 loss: tensor(9.5746e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4789 loss: tensor(9.5796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4790 loss: tensor(9.5871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4791 loss: tensor(9.5978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4792 loss: tensor(9.6135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4793 loss: tensor(9.6359e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4794 loss: tensor(9.6684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4795 loss: tensor(9.7143e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4796 loss: tensor(9.7788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4797 loss: tensor(9.8679e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4798 loss: tensor(9.9873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4799 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4800 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4801 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4802 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4803 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4804 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4805 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4806 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4807 loss: tensor(9.9084e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4808 loss: tensor(9.6537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4809 loss: tensor(9.5733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4810 loss: tensor(9.6495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4811 loss: tensor(9.8008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4812 loss: tensor(9.9298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4813 loss: tensor(9.9673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4814 loss: tensor(9.8989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4815 loss: tensor(9.7673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4816 loss: tensor(9.6423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4817 loss: tensor(9.5796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4818 loss: tensor(9.5925e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4819 loss: tensor(9.6515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4820 loss: tensor(9.7090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4821 loss: tensor(9.7277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4822 loss: tensor(9.6978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4823 loss: tensor(9.6375e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4824 loss: tensor(9.5794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4825 loss: tensor(9.5493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4826 loss: tensor(9.5549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4827 loss: tensor(9.5840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4828 loss: tensor(9.6154e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4829 loss: tensor(9.6310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4830 loss: tensor(9.6238e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4831 loss: tensor(9.5997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4832 loss: tensor(9.5713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4833 loss: tensor(9.5507e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4834 loss: tensor(9.5445e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4835 loss: tensor(9.5508e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4836 loss: tensor(9.5625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4837 loss: tensor(9.5715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4838 loss: tensor(9.5729e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4839 loss: tensor(9.5667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4840 loss: tensor(9.5563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4841 loss: tensor(9.5465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4842 loss: tensor(9.5413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4843 loss: tensor(9.5412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4844 loss: tensor(9.5452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4845 loss: tensor(9.5500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4846 loss: tensor(9.5531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4847 loss: tensor(9.5533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4848 loss: tensor(9.5505e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4849 loss: tensor(9.5459e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4850 loss: tensor(9.5413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4851 loss: tensor(9.5380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4852 loss: tensor(9.5365e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4853 loss: tensor(9.5368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4854 loss: tensor(9.5379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4855 loss: tensor(9.5393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4856 loss: tensor(9.5397e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4857 loss: tensor(9.5394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4858 loss: tensor(9.5379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4859 loss: tensor(9.5362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4860 loss: tensor(9.5345e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4861 loss: tensor(9.5332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4862 loss: tensor(9.5325e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4863 loss: tensor(9.5322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4864 loss: tensor(9.5323e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4865 loss: tensor(9.5325e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4866 loss: tensor(9.5326e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4867 loss: tensor(9.5324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4868 loss: tensor(9.5322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4869 loss: tensor(9.5316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4870 loss: tensor(9.5308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4871 loss: tensor(9.5303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4872 loss: tensor(9.5297e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4873 loss: tensor(9.5294e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4874 loss: tensor(9.5291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4875 loss: tensor(9.5290e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4876 loss: tensor(9.5290e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4877 loss: tensor(9.5291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4878 loss: tensor(9.5290e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4879 loss: tensor(9.5292e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4880 loss: tensor(9.5294e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4881 loss: tensor(9.5298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4882 loss: tensor(9.5304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4883 loss: tensor(9.5314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4884 loss: tensor(9.5331e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4885 loss: tensor(9.5360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4886 loss: tensor(9.5403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4887 loss: tensor(9.5468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4888 loss: tensor(9.5567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4889 loss: tensor(9.5716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4890 loss: tensor(9.5939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4891 loss: tensor(9.6274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4892 loss: tensor(9.6774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4893 loss: tensor(9.7519e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4894 loss: tensor(9.8611e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4895 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4896 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4897 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4898 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4899 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4900 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4901 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4902 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4903 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4904 loss: tensor(9.9251e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4905 loss: tensor(9.6771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4906 loss: tensor(9.7527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4907 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4908 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4909 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4910 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4911 loss: tensor(9.7796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4912 loss: tensor(9.5655e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4913 loss: tensor(9.5339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4914 loss: tensor(9.6502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4915 loss: tensor(9.7916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4916 loss: tensor(9.8453e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4917 loss: tensor(9.7793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4918 loss: tensor(9.6518e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4919 loss: tensor(9.5552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4920 loss: tensor(9.5446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4921 loss: tensor(9.6052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4922 loss: tensor(9.6757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4923 loss: tensor(9.7001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4924 loss: tensor(9.6642e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4925 loss: tensor(9.5974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4926 loss: tensor(9.5453e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4927 loss: tensor(9.5348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4928 loss: tensor(9.5590e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4929 loss: tensor(9.5898e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4930 loss: tensor(9.5996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4931 loss: tensor(9.5815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4932 loss: tensor(9.5485e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4933 loss: tensor(9.5215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4934 loss: tensor(9.5141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4935 loss: tensor(9.5247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4936 loss: tensor(9.5403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4937 loss: tensor(9.5476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4938 loss: tensor(9.5415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4939 loss: tensor(9.5269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4940 loss: tensor(9.5133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4941 loss: tensor(9.5078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4942 loss: tensor(9.5113e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4943 loss: tensor(9.5188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4944 loss: tensor(9.5242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4945 loss: tensor(9.5238e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4946 loss: tensor(9.5183e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4947 loss: tensor(9.5111e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4948 loss: tensor(9.5063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4949 loss: tensor(9.5058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4950 loss: tensor(9.5083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4951 loss: tensor(9.5116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4952 loss: tensor(9.5131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4953 loss: tensor(9.5121e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4954 loss: tensor(9.5095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4955 loss: tensor(9.5066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4956 loss: tensor(9.5051e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4957 loss: tensor(9.5053e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4958 loss: tensor(9.5071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4959 loss: tensor(9.5096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4960 loss: tensor(9.5121e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4961 loss: tensor(9.5145e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4962 loss: tensor(9.5175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4963 loss: tensor(9.5221e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4964 loss: tensor(9.5299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4965 loss: tensor(9.5425e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4966 loss: tensor(9.5618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4967 loss: tensor(9.5899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4968 loss: tensor(9.6303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4969 loss: tensor(9.6886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4970 loss: tensor(9.7718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4971 loss: tensor(9.8901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4972 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4973 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4974 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4975 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4976 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4977 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4978 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4979 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4980 loss: tensor(9.9987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4981 loss: tensor(9.6265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4982 loss: tensor(9.5071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4983 loss: tensor(9.6258e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4984 loss: tensor(9.8531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4985 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4986 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4987 loss: tensor(9.9054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4988 loss: tensor(9.6986e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4989 loss: tensor(9.5482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4990 loss: tensor(9.5211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4991 loss: tensor(9.5956e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4992 loss: tensor(9.6933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4993 loss: tensor(9.7378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4994 loss: tensor(9.7012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4995 loss: tensor(9.6133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4996 loss: tensor(9.5324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4997 loss: tensor(9.5032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4998 loss: tensor(9.5289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 4999 loss: tensor(9.5778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5000 loss: tensor(9.6098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5001 loss: tensor(9.6029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5002 loss: tensor(9.5633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5003 loss: tensor(9.5172e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5004 loss: tensor(9.4903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5005 loss: tensor(9.4926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5006 loss: tensor(9.5146e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5007 loss: tensor(9.5375e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5008 loss: tensor(9.5460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5009 loss: tensor(9.5360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5010 loss: tensor(9.5151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5011 loss: tensor(9.4958e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5012 loss: tensor(9.4871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5013 loss: tensor(9.4900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5014 loss: tensor(9.4996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5015 loss: tensor(9.5077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5016 loss: tensor(9.5089e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5017 loss: tensor(9.5031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5018 loss: tensor(9.4942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5019 loss: tensor(9.4867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5020 loss: tensor(9.4839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5021 loss: tensor(9.4855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5022 loss: tensor(9.4897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5023 loss: tensor(9.4929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5024 loss: tensor(9.4934e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5025 loss: tensor(9.4909e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5026 loss: tensor(9.4865e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5027 loss: tensor(9.4825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5028 loss: tensor(9.4803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5029 loss: tensor(9.4801e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5030 loss: tensor(9.4815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5031 loss: tensor(9.4830e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5032 loss: tensor(9.4837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5033 loss: tensor(9.4833e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5034 loss: tensor(9.4819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5035 loss: tensor(9.4800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5036 loss: tensor(9.4786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5037 loss: tensor(9.4776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5038 loss: tensor(9.4773e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5039 loss: tensor(9.4776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5040 loss: tensor(9.4779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5041 loss: tensor(9.4780e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5042 loss: tensor(9.4777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5043 loss: tensor(9.4771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5044 loss: tensor(9.4762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5045 loss: tensor(9.4754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5046 loss: tensor(9.4746e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5047 loss: tensor(9.4743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5048 loss: tensor(9.4740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5049 loss: tensor(9.4739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5050 loss: tensor(9.4737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5051 loss: tensor(9.4737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5052 loss: tensor(9.4733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5053 loss: tensor(9.4729e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5054 loss: tensor(9.4725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5055 loss: tensor(9.4718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5056 loss: tensor(9.4715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5057 loss: tensor(9.4710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5058 loss: tensor(9.4708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5059 loss: tensor(9.4705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5060 loss: tensor(9.4703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5061 loss: tensor(9.4702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5062 loss: tensor(9.4699e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5063 loss: tensor(9.4696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5064 loss: tensor(9.4695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5065 loss: tensor(9.4692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5066 loss: tensor(9.4690e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5067 loss: tensor(9.4687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5068 loss: tensor(9.4688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5069 loss: tensor(9.4689e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5070 loss: tensor(9.4692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5071 loss: tensor(9.4697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5072 loss: tensor(9.4706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5073 loss: tensor(9.4720e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5074 loss: tensor(9.4740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5075 loss: tensor(9.4772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5076 loss: tensor(9.4822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5077 loss: tensor(9.4897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5078 loss: tensor(9.5008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5079 loss: tensor(9.5175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5080 loss: tensor(9.5423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5081 loss: tensor(9.5793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5082 loss: tensor(9.6345e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5083 loss: tensor(9.7164e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5084 loss: tensor(9.8363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5085 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5086 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5087 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5088 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5089 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5090 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5091 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5092 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5093 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5094 loss: tensor(9.7640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5095 loss: tensor(9.5883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5096 loss: tensor(9.7204e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5097 loss: tensor(9.9922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5098 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5099 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5100 loss: tensor(9.9334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5101 loss: tensor(9.6477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5102 loss: tensor(9.4758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5103 loss: tensor(9.4881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5104 loss: tensor(9.6233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5105 loss: tensor(9.7537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5106 loss: tensor(9.7803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5107 loss: tensor(9.6941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5108 loss: tensor(9.5662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5109 loss: tensor(9.4856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5110 loss: tensor(9.4923e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5111 loss: tensor(9.5586e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5112 loss: tensor(9.6213e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5113 loss: tensor(9.6312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5114 loss: tensor(9.5843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5115 loss: tensor(9.5167e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5116 loss: tensor(9.4720e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5117 loss: tensor(9.4707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5118 loss: tensor(9.4998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5119 loss: tensor(9.5287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5120 loss: tensor(9.5331e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5121 loss: tensor(9.5106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5122 loss: tensor(9.4778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5123 loss: tensor(9.4552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5124 loss: tensor(9.4532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5125 loss: tensor(9.4667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5126 loss: tensor(9.4820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5127 loss: tensor(9.4868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5128 loss: tensor(9.4787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5129 loss: tensor(9.4640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5130 loss: tensor(9.4520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5131 loss: tensor(9.4486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5132 loss: tensor(9.4533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5133 loss: tensor(9.4610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5134 loss: tensor(9.4657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5135 loss: tensor(9.4646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5136 loss: tensor(9.4591e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5137 loss: tensor(9.4529e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5138 loss: tensor(9.4495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5139 loss: tensor(9.4502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5140 loss: tensor(9.4538e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5141 loss: tensor(9.4577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5142 loss: tensor(9.4605e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5143 loss: tensor(9.4612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5144 loss: tensor(9.4613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5145 loss: tensor(9.4622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5146 loss: tensor(9.4656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5147 loss: tensor(9.4728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5148 loss: tensor(9.4837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5149 loss: tensor(9.4988e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5150 loss: tensor(9.5188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5151 loss: tensor(9.5457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5152 loss: tensor(9.5825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5153 loss: tensor(9.6335e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5154 loss: tensor(9.7045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5155 loss: tensor(9.8013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5156 loss: tensor(9.9277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5157 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5158 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5159 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5160 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5161 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5162 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5163 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5164 loss: tensor(9.9193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5165 loss: tensor(9.6356e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5166 loss: tensor(9.4723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5167 loss: tensor(9.4574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5168 loss: tensor(9.5541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5169 loss: tensor(9.6889e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5170 loss: tensor(9.7886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5171 loss: tensor(9.8076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5172 loss: tensor(9.7419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5173 loss: tensor(9.6283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5174 loss: tensor(9.5201e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5175 loss: tensor(9.4596e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5176 loss: tensor(9.4585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5177 loss: tensor(9.4988e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5178 loss: tensor(9.5475e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5179 loss: tensor(9.5756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5180 loss: tensor(9.5700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5181 loss: tensor(9.5368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5182 loss: tensor(9.4939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5183 loss: tensor(9.4605e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5184 loss: tensor(9.4476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5185 loss: tensor(9.4540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5186 loss: tensor(9.4700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5187 loss: tensor(9.4837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5188 loss: tensor(9.4870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5189 loss: tensor(9.4787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5190 loss: tensor(9.4635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5191 loss: tensor(9.4482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5192 loss: tensor(9.4388e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5193 loss: tensor(9.4373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5194 loss: tensor(9.4420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5195 loss: tensor(9.4486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5196 loss: tensor(9.4532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5197 loss: tensor(9.4532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5198 loss: tensor(9.4487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5199 loss: tensor(9.4413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5200 loss: tensor(9.4341e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5201 loss: tensor(9.4292e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5202 loss: tensor(9.4277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5203 loss: tensor(9.4291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5204 loss: tensor(9.4321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5205 loss: tensor(9.4350e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5206 loss: tensor(9.4364e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5207 loss: tensor(9.4360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5208 loss: tensor(9.4340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5209 loss: tensor(9.4310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5210 loss: tensor(9.4280e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5211 loss: tensor(9.4252e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5212 loss: tensor(9.4238e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5213 loss: tensor(9.4231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5214 loss: tensor(9.4235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5215 loss: tensor(9.4244e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5216 loss: tensor(9.4250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5217 loss: tensor(9.4254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5218 loss: tensor(9.4253e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5219 loss: tensor(9.4247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5220 loss: tensor(9.4237e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5221 loss: tensor(9.4226e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5222 loss: tensor(9.4218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5223 loss: tensor(9.4209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5224 loss: tensor(9.4204e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5225 loss: tensor(9.4201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5226 loss: tensor(9.4199e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5227 loss: tensor(9.4198e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5228 loss: tensor(9.4197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5229 loss: tensor(9.4195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5230 loss: tensor(9.4193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5231 loss: tensor(9.4189e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5232 loss: tensor(9.4185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5233 loss: tensor(9.4179e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5234 loss: tensor(9.4174e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5235 loss: tensor(9.4169e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5236 loss: tensor(9.4164e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5237 loss: tensor(9.4160e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5238 loss: tensor(9.4156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5239 loss: tensor(9.4153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5240 loss: tensor(9.4149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5241 loss: tensor(9.4145e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5242 loss: tensor(9.4144e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5243 loss: tensor(9.4141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5244 loss: tensor(9.4138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5245 loss: tensor(9.4135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5246 loss: tensor(9.4133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5247 loss: tensor(9.4129e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5248 loss: tensor(9.4127e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5249 loss: tensor(9.4124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5250 loss: tensor(9.4122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5251 loss: tensor(9.4119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5252 loss: tensor(9.4116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5253 loss: tensor(9.4112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5254 loss: tensor(9.4109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5255 loss: tensor(9.4106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5256 loss: tensor(9.4104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5257 loss: tensor(9.4101e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5258 loss: tensor(9.4100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5259 loss: tensor(9.4099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5260 loss: tensor(9.4099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5261 loss: tensor(9.4100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5262 loss: tensor(9.4105e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5263 loss: tensor(9.4113e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5264 loss: tensor(9.4128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5265 loss: tensor(9.4150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5266 loss: tensor(9.4184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5267 loss: tensor(9.4240e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5268 loss: tensor(9.4328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5269 loss: tensor(9.4465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5270 loss: tensor(9.4676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5271 loss: tensor(9.5006e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5272 loss: tensor(9.5521e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5273 loss: tensor(9.6314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5274 loss: tensor(9.7528e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5275 loss: tensor(9.9352e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5276 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5277 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5278 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5279 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5280 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5281 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5282 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5283 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5284 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5285 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5290 loss: tensor(9.9321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5291 loss: tensor(9.4765e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5292 loss: tensor(9.4352e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5293 loss: tensor(9.7254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5296 loss: tensor(9.9801e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5297 loss: tensor(9.7093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5298 loss: tensor(9.5381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5299 loss: tensor(9.5355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5300 loss: tensor(9.6180e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5301 loss: tensor(9.6610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5302 loss: tensor(9.6168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5303 loss: tensor(9.5378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5304 loss: tensor(9.5031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5305 loss: tensor(9.5348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5306 loss: tensor(9.5834e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5307 loss: tensor(9.5847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5308 loss: tensor(9.5230e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5309 loss: tensor(9.4414e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5310 loss: tensor(9.3993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5311 loss: tensor(9.4186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5312 loss: tensor(9.4709e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5313 loss: tensor(9.5074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5314 loss: tensor(9.5007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5315 loss: tensor(9.4613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5316 loss: tensor(9.4208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5317 loss: tensor(9.4042e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5318 loss: tensor(9.4118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5319 loss: tensor(9.4262e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5320 loss: tensor(9.4307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5321 loss: tensor(9.4228e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5322 loss: tensor(9.4116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5323 loss: tensor(9.4074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5324 loss: tensor(9.4118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5325 loss: tensor(9.4178e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5326 loss: tensor(9.4175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5327 loss: tensor(9.4090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5328 loss: tensor(9.3969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5329 loss: tensor(9.3892e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5330 loss: tensor(9.3893e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5331 loss: tensor(9.3952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5332 loss: tensor(9.4013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5333 loss: tensor(9.4032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5334 loss: tensor(9.4002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5335 loss: tensor(9.3952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5336 loss: tensor(9.3915e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5337 loss: tensor(9.3902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5338 loss: tensor(9.3908e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5339 loss: tensor(9.3912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5340 loss: tensor(9.3900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5341 loss: tensor(9.3879e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5342 loss: tensor(9.3859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5343 loss: tensor(9.3853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5344 loss: tensor(9.3860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5345 loss: tensor(9.3873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5346 loss: tensor(9.3881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5347 loss: tensor(9.3878e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5348 loss: tensor(9.3866e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5349 loss: tensor(9.3849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5350 loss: tensor(9.3835e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5351 loss: tensor(9.3827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5352 loss: tensor(9.3827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5353 loss: tensor(9.3827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5354 loss: tensor(9.3822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5355 loss: tensor(9.3817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5356 loss: tensor(9.3809e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5357 loss: tensor(9.3803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5358 loss: tensor(9.3800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5359 loss: tensor(9.3799e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5360 loss: tensor(9.3800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5361 loss: tensor(9.3800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5362 loss: tensor(9.3797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5363 loss: tensor(9.3793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5364 loss: tensor(9.3786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5365 loss: tensor(9.3782e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5366 loss: tensor(9.3778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5367 loss: tensor(9.3776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5368 loss: tensor(9.3773e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5369 loss: tensor(9.3770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5370 loss: tensor(9.3766e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5371 loss: tensor(9.3762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5372 loss: tensor(9.3758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5373 loss: tensor(9.3754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5374 loss: tensor(9.3751e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5375 loss: tensor(9.3749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5376 loss: tensor(9.3745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5377 loss: tensor(9.3743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5378 loss: tensor(9.3740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5379 loss: tensor(9.3737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5380 loss: tensor(9.3733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5381 loss: tensor(9.3730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5382 loss: tensor(9.3727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5383 loss: tensor(9.3725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5384 loss: tensor(9.3722e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5385 loss: tensor(9.3720e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5386 loss: tensor(9.3718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5387 loss: tensor(9.3715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5388 loss: tensor(9.3713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5389 loss: tensor(9.3710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5390 loss: tensor(9.3708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5391 loss: tensor(9.3706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5392 loss: tensor(9.3705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5393 loss: tensor(9.3703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5394 loss: tensor(9.3703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5395 loss: tensor(9.3703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5396 loss: tensor(9.3706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5397 loss: tensor(9.3710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5398 loss: tensor(9.3716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5399 loss: tensor(9.3728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5400 loss: tensor(9.3745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5401 loss: tensor(9.3770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5402 loss: tensor(9.3811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5403 loss: tensor(9.3870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5404 loss: tensor(9.3959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5405 loss: tensor(9.4090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5406 loss: tensor(9.4289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5407 loss: tensor(9.4585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5408 loss: tensor(9.5020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5409 loss: tensor(9.5659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5410 loss: tensor(9.6593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5411 loss: tensor(9.7933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5412 loss: tensor(9.9785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5413 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5414 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5415 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5416 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5417 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5418 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5419 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5420 loss: tensor(9.7766e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5421 loss: tensor(9.4516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5422 loss: tensor(9.4248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5423 loss: tensor(9.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5424 loss: tensor(9.8653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5425 loss: tensor(9.9788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5426 loss: tensor(9.8919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5427 loss: tensor(9.6684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5428 loss: tensor(9.4546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5429 loss: tensor(9.3718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5430 loss: tensor(9.4364e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5431 loss: tensor(9.5667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5432 loss: tensor(9.6554e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5433 loss: tensor(9.6407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5434 loss: tensor(9.5396e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5435 loss: tensor(9.4245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5436 loss: tensor(9.3650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5437 loss: tensor(9.3808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5438 loss: tensor(9.4389e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5439 loss: tensor(9.4856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5440 loss: tensor(9.4868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5441 loss: tensor(9.4448e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5442 loss: tensor(9.3914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5443 loss: tensor(9.3606e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5444 loss: tensor(9.3655e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5445 loss: tensor(9.3933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5446 loss: tensor(9.4193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5447 loss: tensor(9.4247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5448 loss: tensor(9.4076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5449 loss: tensor(9.3809e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5450 loss: tensor(9.3609e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5451 loss: tensor(9.3568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5452 loss: tensor(9.3660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5453 loss: tensor(9.3783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5454 loss: tensor(9.3843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5455 loss: tensor(9.3798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5456 loss: tensor(9.3682e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5457 loss: tensor(9.3567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5458 loss: tensor(9.3511e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5459 loss: tensor(9.3523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5460 loss: tensor(9.3576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5461 loss: tensor(9.3625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5462 loss: tensor(9.3633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5463 loss: tensor(9.3601e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5464 loss: tensor(9.3547e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5465 loss: tensor(9.3501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5466 loss: tensor(9.3480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5467 loss: tensor(9.3489e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5468 loss: tensor(9.3513e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5469 loss: tensor(9.3531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5470 loss: tensor(9.3534e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5471 loss: tensor(9.3520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5472 loss: tensor(9.3497e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5473 loss: tensor(9.3475e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5474 loss: tensor(9.3464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5475 loss: tensor(9.3464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5476 loss: tensor(9.3472e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5477 loss: tensor(9.3482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5478 loss: tensor(9.3486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5479 loss: tensor(9.3487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5480 loss: tensor(9.3482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5481 loss: tensor(9.3478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5482 loss: tensor(9.3480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5483 loss: tensor(9.3490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5484 loss: tensor(9.3509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5485 loss: tensor(9.3539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5486 loss: tensor(9.3581e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5487 loss: tensor(9.3637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5488 loss: tensor(9.3716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5489 loss: tensor(9.3831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5490 loss: tensor(9.4000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5491 loss: tensor(9.4251e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5492 loss: tensor(9.4622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5493 loss: tensor(9.5162e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5494 loss: tensor(9.5937e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5495 loss: tensor(9.7037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5496 loss: tensor(9.8552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5497 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5498 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5499 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5500 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5501 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5502 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5503 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5504 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5505 loss: tensor(9.5906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5506 loss: tensor(9.3735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5507 loss: tensor(9.4067e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5508 loss: tensor(9.6000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5509 loss: tensor(9.8026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5510 loss: tensor(9.8868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5511 loss: tensor(9.8092e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5512 loss: tensor(9.6254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5513 loss: tensor(9.4470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5514 loss: tensor(9.3653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5515 loss: tensor(9.3988e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5516 loss: tensor(9.4938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5517 loss: tensor(9.5711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5518 loss: tensor(9.5771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5519 loss: tensor(9.5104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5520 loss: tensor(9.4158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5521 loss: tensor(9.3485e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5522 loss: tensor(9.3383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5523 loss: tensor(9.3758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5524 loss: tensor(9.4257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5525 loss: tensor(9.4527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5526 loss: tensor(9.4416e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5527 loss: tensor(9.4021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5528 loss: tensor(9.3592e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5529 loss: tensor(9.3349e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5530 loss: tensor(9.3362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5531 loss: tensor(9.3547e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5532 loss: tensor(9.3737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5533 loss: tensor(9.3808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5534 loss: tensor(9.3725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5535 loss: tensor(9.3548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5536 loss: tensor(9.3381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5537 loss: tensor(9.3306e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5538 loss: tensor(9.3333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5539 loss: tensor(9.3419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5540 loss: tensor(9.3495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5541 loss: tensor(9.3515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5542 loss: tensor(9.3470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5543 loss: tensor(9.3387e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5544 loss: tensor(9.3306e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5545 loss: tensor(9.3260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5546 loss: tensor(9.3258e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5547 loss: tensor(9.3287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5548 loss: tensor(9.3322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5549 loss: tensor(9.3343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5550 loss: tensor(9.3336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5551 loss: tensor(9.3307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5552 loss: tensor(9.3272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5553 loss: tensor(9.3242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5554 loss: tensor(9.3229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5555 loss: tensor(9.3233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5556 loss: tensor(9.3248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5557 loss: tensor(9.3262e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5558 loss: tensor(9.3265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5559 loss: tensor(9.3260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5560 loss: tensor(9.3245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5561 loss: tensor(9.3229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5562 loss: tensor(9.3215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5563 loss: tensor(9.3209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5564 loss: tensor(9.3208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5565 loss: tensor(9.3211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5566 loss: tensor(9.3216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5567 loss: tensor(9.3219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5568 loss: tensor(9.3217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5569 loss: tensor(9.3213e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5570 loss: tensor(9.3207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5571 loss: tensor(9.3200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5572 loss: tensor(9.3196e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5573 loss: tensor(9.3195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5574 loss: tensor(9.3200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5575 loss: tensor(9.3207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5576 loss: tensor(9.3217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5577 loss: tensor(9.3229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5578 loss: tensor(9.3245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5579 loss: tensor(9.3267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5580 loss: tensor(9.3295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5581 loss: tensor(9.3333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5582 loss: tensor(9.3390e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5583 loss: tensor(9.3467e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5584 loss: tensor(9.3576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5585 loss: tensor(9.3730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5586 loss: tensor(9.3946e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5587 loss: tensor(9.4250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5588 loss: tensor(9.4677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5589 loss: tensor(9.5270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5590 loss: tensor(9.6079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5591 loss: tensor(9.7163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5592 loss: tensor(9.8565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5593 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5594 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5595 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5596 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5597 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5598 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5599 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5600 loss: tensor(9.7504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5601 loss: tensor(9.4845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5602 loss: tensor(9.3641e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5603 loss: tensor(9.3930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5604 loss: tensor(9.5122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5605 loss: tensor(9.6372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5606 loss: tensor(9.6966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5607 loss: tensor(9.6613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5608 loss: tensor(9.5526e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5609 loss: tensor(9.4264e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5610 loss: tensor(9.3402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5611 loss: tensor(9.3233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5612 loss: tensor(9.3663e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5613 loss: tensor(9.4329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5614 loss: tensor(9.4824e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5615 loss: tensor(9.4896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5616 loss: tensor(9.4540e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5617 loss: tensor(9.3961e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5618 loss: tensor(9.3438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5619 loss: tensor(9.3171e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5620 loss: tensor(9.3198e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5621 loss: tensor(9.3409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5622 loss: tensor(9.3635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5623 loss: tensor(9.3737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5624 loss: tensor(9.3668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5625 loss: tensor(9.3469e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5626 loss: tensor(9.3237e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5627 loss: tensor(9.3071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5628 loss: tensor(9.3020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5629 loss: tensor(9.3076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5630 loss: tensor(9.3189e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5631 loss: tensor(9.3287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5632 loss: tensor(9.3332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5633 loss: tensor(9.3308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5634 loss: tensor(9.3235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5635 loss: tensor(9.3150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5636 loss: tensor(9.3086e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5637 loss: tensor(9.3061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5638 loss: tensor(9.3078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5639 loss: tensor(9.3118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5640 loss: tensor(9.3165e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5641 loss: tensor(9.3195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5642 loss: tensor(9.3207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5643 loss: tensor(9.3202e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5644 loss: tensor(9.3188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5645 loss: tensor(9.3183e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5646 loss: tensor(9.3193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5647 loss: tensor(9.3224e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5648 loss: tensor(9.3280e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5649 loss: tensor(9.3361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5650 loss: tensor(9.3463e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5651 loss: tensor(9.3586e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5652 loss: tensor(9.3736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5653 loss: tensor(9.3924e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5654 loss: tensor(9.4163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5655 loss: tensor(9.4475e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5656 loss: tensor(9.4881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5657 loss: tensor(9.5401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5658 loss: tensor(9.6043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5659 loss: tensor(9.6804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5660 loss: tensor(9.7660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5661 loss: tensor(9.8557e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5662 loss: tensor(9.9380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5663 loss: tensor(9.9985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5664 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5665 loss: tensor(9.9853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5666 loss: tensor(9.8914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5667 loss: tensor(9.7501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5668 loss: tensor(9.5895e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5669 loss: tensor(9.4456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5670 loss: tensor(9.3470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5671 loss: tensor(9.3058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5672 loss: tensor(9.3162e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5673 loss: tensor(9.3598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5674 loss: tensor(9.4131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5675 loss: tensor(9.4555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5676 loss: tensor(9.4743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5677 loss: tensor(9.4658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5678 loss: tensor(9.4349e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5679 loss: tensor(9.3922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5680 loss: tensor(9.3506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5681 loss: tensor(9.3203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5682 loss: tensor(9.3066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5683 loss: tensor(9.3084e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5684 loss: tensor(9.3201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5685 loss: tensor(9.3348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5686 loss: tensor(9.3465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5687 loss: tensor(9.3509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5688 loss: tensor(9.3470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5689 loss: tensor(9.3358e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5690 loss: tensor(9.3209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5691 loss: tensor(9.3057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5692 loss: tensor(9.2936e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5693 loss: tensor(9.2862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5694 loss: tensor(9.2839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5695 loss: tensor(9.2859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5696 loss: tensor(9.2909e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5697 loss: tensor(9.2968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5698 loss: tensor(9.3020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5699 loss: tensor(9.3054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5700 loss: tensor(9.3067e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5701 loss: tensor(9.3055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5702 loss: tensor(9.3027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5703 loss: tensor(9.2989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5704 loss: tensor(9.2949e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5705 loss: tensor(9.2913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5706 loss: tensor(9.2886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5707 loss: tensor(9.2867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5708 loss: tensor(9.2860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5709 loss: tensor(9.2863e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5710 loss: tensor(9.2870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5711 loss: tensor(9.2884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5712 loss: tensor(9.2899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5713 loss: tensor(9.2916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5714 loss: tensor(9.2933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5715 loss: tensor(9.2951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5716 loss: tensor(9.2970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5717 loss: tensor(9.2993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5718 loss: tensor(9.3024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5719 loss: tensor(9.3064e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5720 loss: tensor(9.3119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5721 loss: tensor(9.3192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5722 loss: tensor(9.3296e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5723 loss: tensor(9.3432e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5724 loss: tensor(9.3615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5725 loss: tensor(9.3858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5726 loss: tensor(9.4177e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5727 loss: tensor(9.4596e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5728 loss: tensor(9.5140e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5729 loss: tensor(9.5839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5730 loss: tensor(9.6708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5731 loss: tensor(9.7745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5732 loss: tensor(9.8908e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5736 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5737 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5738 loss: tensor(9.9488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5739 loss: tensor(9.7811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5740 loss: tensor(9.6351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5741 loss: tensor(9.5490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5742 loss: tensor(9.5348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5743 loss: tensor(9.5767e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5744 loss: tensor(9.6411e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5745 loss: tensor(9.6910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5746 loss: tensor(9.6992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5747 loss: tensor(9.6553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5748 loss: tensor(9.5683e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5749 loss: tensor(9.4619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5750 loss: tensor(9.3647e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5751 loss: tensor(9.2989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5752 loss: tensor(9.2736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5753 loss: tensor(9.2831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5754 loss: tensor(9.3128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5755 loss: tensor(9.3457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5756 loss: tensor(9.3686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5757 loss: tensor(9.3751e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5758 loss: tensor(9.3664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5759 loss: tensor(9.3480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5760 loss: tensor(9.3284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5761 loss: tensor(9.3145e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5762 loss: tensor(9.3096e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5763 loss: tensor(9.3128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5764 loss: tensor(9.3210e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5765 loss: tensor(9.3295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5766 loss: tensor(9.3343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5767 loss: tensor(9.3332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5768 loss: tensor(9.3262e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5769 loss: tensor(9.3149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5770 loss: tensor(9.3020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5771 loss: tensor(9.2896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5772 loss: tensor(9.2797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5773 loss: tensor(9.2738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5774 loss: tensor(9.2711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5775 loss: tensor(9.2712e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5776 loss: tensor(9.2725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5777 loss: tensor(9.2739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5778 loss: tensor(9.2744e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5779 loss: tensor(9.2736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5780 loss: tensor(9.2716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5781 loss: tensor(9.2690e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5782 loss: tensor(9.2660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5783 loss: tensor(9.2633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5784 loss: tensor(9.2612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5785 loss: tensor(9.2598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5786 loss: tensor(9.2593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5787 loss: tensor(9.2594e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5788 loss: tensor(9.2602e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5789 loss: tensor(9.2615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5790 loss: tensor(9.2632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5791 loss: tensor(9.2653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5792 loss: tensor(9.2676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5793 loss: tensor(9.2704e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5794 loss: tensor(9.2739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5795 loss: tensor(9.2786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5796 loss: tensor(9.2851e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5797 loss: tensor(9.2941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5798 loss: tensor(9.3066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5799 loss: tensor(9.3243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5800 loss: tensor(9.3488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5801 loss: tensor(9.3829e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5802 loss: tensor(9.4303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5803 loss: tensor(9.4950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5804 loss: tensor(9.5814e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5805 loss: tensor(9.6943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5806 loss: tensor(9.8355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5807 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5808 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5809 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5810 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5811 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5812 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5813 loss: tensor(9.9550e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5814 loss: tensor(9.6545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5815 loss: tensor(9.4264e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5816 loss: tensor(9.3342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5817 loss: tensor(9.3769e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5818 loss: tensor(9.5000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5819 loss: tensor(9.6275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5820 loss: tensor(9.6943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5821 loss: tensor(9.6709e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5822 loss: tensor(9.5701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5823 loss: tensor(9.4388e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5824 loss: tensor(9.3314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5825 loss: tensor(9.2828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5826 loss: tensor(9.2951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5827 loss: tensor(9.3430e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5828 loss: tensor(9.3911e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5829 loss: tensor(9.4114e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5830 loss: tensor(9.3938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5831 loss: tensor(9.3479e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5832 loss: tensor(9.2953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5833 loss: tensor(9.2566e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5834 loss: tensor(9.2435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5835 loss: tensor(9.2539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5836 loss: tensor(9.2764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5837 loss: tensor(9.2966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5838 loss: tensor(9.3049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5839 loss: tensor(9.2982e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5840 loss: tensor(9.2804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5841 loss: tensor(9.2601e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5842 loss: tensor(9.2452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5843 loss: tensor(9.2395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5844 loss: tensor(9.2430e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5845 loss: tensor(9.2518e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5846 loss: tensor(9.2606e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5847 loss: tensor(9.2655e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5848 loss: tensor(9.2653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5849 loss: tensor(9.2609e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5850 loss: tensor(9.2544e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5851 loss: tensor(9.2487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5852 loss: tensor(9.2461e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5853 loss: tensor(9.2475e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5854 loss: tensor(9.2528e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5855 loss: tensor(9.2609e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5856 loss: tensor(9.2710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5857 loss: tensor(9.2827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5858 loss: tensor(9.2971e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5859 loss: tensor(9.3155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5860 loss: tensor(9.3416e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5861 loss: tensor(9.3791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5862 loss: tensor(9.4329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5863 loss: tensor(9.5091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5864 loss: tensor(9.6131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5865 loss: tensor(9.7499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5866 loss: tensor(9.9194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5867 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5868 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5869 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5870 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5871 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5872 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5873 loss: tensor(9.6816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5874 loss: tensor(9.3917e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5875 loss: tensor(9.2524e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5876 loss: tensor(9.2787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5877 loss: tensor(9.4116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5878 loss: tensor(9.5593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5879 loss: tensor(9.6400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5880 loss: tensor(9.6155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5881 loss: tensor(9.5038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5882 loss: tensor(9.3642e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5883 loss: tensor(9.2629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5884 loss: tensor(9.2363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5885 loss: tensor(9.2770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5886 loss: tensor(9.3454e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5887 loss: tensor(9.3967e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5888 loss: tensor(9.4030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5889 loss: tensor(9.3639e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5890 loss: tensor(9.3029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5891 loss: tensor(9.2501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5892 loss: tensor(9.2264e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5893 loss: tensor(9.2343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5894 loss: tensor(9.2609e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5895 loss: tensor(9.2867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5896 loss: tensor(9.2975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5897 loss: tensor(9.2886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5898 loss: tensor(9.2667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5899 loss: tensor(9.2428e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5900 loss: tensor(9.2275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5901 loss: tensor(9.2250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5902 loss: tensor(9.2328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5903 loss: tensor(9.2445e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5904 loss: tensor(9.2527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5905 loss: tensor(9.2538e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5906 loss: tensor(9.2478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5907 loss: tensor(9.2379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5908 loss: tensor(9.2282e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5909 loss: tensor(9.2222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5910 loss: tensor(9.2209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5911 loss: tensor(9.2233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5912 loss: tensor(9.2272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5913 loss: tensor(9.2303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5914 loss: tensor(9.2310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5915 loss: tensor(9.2293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5916 loss: tensor(9.2259e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5917 loss: tensor(9.2222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5918 loss: tensor(9.2190e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5919 loss: tensor(9.2175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5920 loss: tensor(9.2175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5921 loss: tensor(9.2185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5922 loss: tensor(9.2197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5923 loss: tensor(9.2205e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5924 loss: tensor(9.2208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5925 loss: tensor(9.2200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5926 loss: tensor(9.2186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5927 loss: tensor(9.2171e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5928 loss: tensor(9.2158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5929 loss: tensor(9.2150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5930 loss: tensor(9.2148e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5931 loss: tensor(9.2150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5932 loss: tensor(9.2155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5933 loss: tensor(9.2161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5934 loss: tensor(9.2167e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5935 loss: tensor(9.2172e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5936 loss: tensor(9.2180e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5937 loss: tensor(9.2189e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5938 loss: tensor(9.2205e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5939 loss: tensor(9.2231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5940 loss: tensor(9.2268e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5941 loss: tensor(9.2326e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5942 loss: tensor(9.2413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5943 loss: tensor(9.2541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5944 loss: tensor(9.2727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5945 loss: tensor(9.3001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5946 loss: tensor(9.3403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5947 loss: tensor(9.3993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5948 loss: tensor(9.4855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5949 loss: tensor(9.6093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5950 loss: tensor(9.7823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5951 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5952 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5953 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5954 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5955 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5956 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5957 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5958 loss: tensor(9.8187e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5959 loss: tensor(9.4023e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5960 loss: tensor(9.2653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5961 loss: tensor(9.3951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5962 loss: tensor(9.6421e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5963 loss: tensor(9.8217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5964 loss: tensor(9.8154e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5965 loss: tensor(9.6300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5966 loss: tensor(9.3854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5967 loss: tensor(9.2260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5968 loss: tensor(9.2209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5969 loss: tensor(9.3313e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5970 loss: tensor(9.4555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5971 loss: tensor(9.5030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5972 loss: tensor(9.4481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5973 loss: tensor(9.3373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5974 loss: tensor(9.2457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5975 loss: tensor(9.2219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5976 loss: tensor(9.2615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5977 loss: tensor(9.3207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5978 loss: tensor(9.3516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5979 loss: tensor(9.3335e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5980 loss: tensor(9.2813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5981 loss: tensor(9.2293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5982 loss: tensor(9.2055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5983 loss: tensor(9.2153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5984 loss: tensor(9.2419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5985 loss: tensor(9.2625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5986 loss: tensor(9.2621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5987 loss: tensor(9.2423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5988 loss: tensor(9.2165e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5989 loss: tensor(9.1996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5990 loss: tensor(9.1984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5991 loss: tensor(9.2086e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5992 loss: tensor(9.2208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5993 loss: tensor(9.2261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5994 loss: tensor(9.2216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5995 loss: tensor(9.2108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5996 loss: tensor(9.2006e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5997 loss: tensor(9.1955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5998 loss: tensor(9.1970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 5999 loss: tensor(9.2024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6000 loss: tensor(9.2075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6001 loss: tensor(9.2090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6002 loss: tensor(9.2069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6003 loss: tensor(9.2025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6004 loss: tensor(9.1987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6005 loss: tensor(9.1974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6006 loss: tensor(9.1992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6007 loss: tensor(9.2030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6008 loss: tensor(9.2076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6009 loss: tensor(9.2117e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6010 loss: tensor(9.2153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6011 loss: tensor(9.2193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6012 loss: tensor(9.2253e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6013 loss: tensor(9.2355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6014 loss: tensor(9.2515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6015 loss: tensor(9.2748e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6016 loss: tensor(9.3077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6017 loss: tensor(9.3532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6018 loss: tensor(9.4154e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6019 loss: tensor(9.4995e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6020 loss: tensor(9.6114e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6021 loss: tensor(9.7545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6022 loss: tensor(9.9261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6023 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6024 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6025 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6026 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6027 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6028 loss: tensor(9.8549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6029 loss: tensor(9.5234e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6030 loss: tensor(9.2793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6031 loss: tensor(9.1903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6032 loss: tensor(9.2490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6033 loss: tensor(9.3886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6034 loss: tensor(9.5222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6035 loss: tensor(9.5817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6036 loss: tensor(9.5428e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6037 loss: tensor(9.4301e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6038 loss: tensor(9.3016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6039 loss: tensor(9.2149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6040 loss: tensor(9.1966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6041 loss: tensor(9.2352e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6042 loss: tensor(9.2940e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6043 loss: tensor(9.3347e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6044 loss: tensor(9.3358e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6045 loss: tensor(9.3001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6046 loss: tensor(9.2486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6047 loss: tensor(9.2063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6048 loss: tensor(9.1894e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6049 loss: tensor(9.1985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6050 loss: tensor(9.2217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6051 loss: tensor(9.2426e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6052 loss: tensor(9.2496e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6053 loss: tensor(9.2398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6054 loss: tensor(9.2191e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6055 loss: tensor(9.1970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6056 loss: tensor(9.1826e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6057 loss: tensor(9.1799e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6058 loss: tensor(9.1867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6059 loss: tensor(9.1973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6060 loss: tensor(9.2053e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6061 loss: tensor(9.2073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6062 loss: tensor(9.2027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6063 loss: tensor(9.1938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6064 loss: tensor(9.1846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6065 loss: tensor(9.1780e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6066 loss: tensor(9.1757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6067 loss: tensor(9.1771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6068 loss: tensor(9.1804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6069 loss: tensor(9.1837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6070 loss: tensor(9.1854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6071 loss: tensor(9.1847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6072 loss: tensor(9.1823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6073 loss: tensor(9.1791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6074 loss: tensor(9.1760e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6075 loss: tensor(9.1740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6076 loss: tensor(9.1734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6077 loss: tensor(9.1738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6078 loss: tensor(9.1747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6079 loss: tensor(9.1757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6080 loss: tensor(9.1762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6081 loss: tensor(9.1759e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6082 loss: tensor(9.1749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6083 loss: tensor(9.1737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6084 loss: tensor(9.1723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6085 loss: tensor(9.1711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6086 loss: tensor(9.1703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6087 loss: tensor(9.1697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6088 loss: tensor(9.1696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6089 loss: tensor(9.1696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6090 loss: tensor(9.1696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6091 loss: tensor(9.1696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6092 loss: tensor(9.1694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6093 loss: tensor(9.1692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6094 loss: tensor(9.1687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6095 loss: tensor(9.1683e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6096 loss: tensor(9.1677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6097 loss: tensor(9.1672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6098 loss: tensor(9.1668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6099 loss: tensor(9.1664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6100 loss: tensor(9.1661e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6101 loss: tensor(9.1659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6102 loss: tensor(9.1657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6103 loss: tensor(9.1656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6104 loss: tensor(9.1654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6105 loss: tensor(9.1653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6106 loss: tensor(9.1652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6107 loss: tensor(9.1651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6108 loss: tensor(9.1650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6109 loss: tensor(9.1650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6110 loss: tensor(9.1652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6111 loss: tensor(9.1652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6112 loss: tensor(9.1657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6113 loss: tensor(9.1665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6114 loss: tensor(9.1676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6115 loss: tensor(9.1695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6116 loss: tensor(9.1722e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6117 loss: tensor(9.1763e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6118 loss: tensor(9.1823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6119 loss: tensor(9.1912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6120 loss: tensor(9.2046e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6121 loss: tensor(9.2244e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6122 loss: tensor(9.2537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6123 loss: tensor(9.2975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6124 loss: tensor(9.3622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6125 loss: tensor(9.4568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6126 loss: tensor(9.5925e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6127 loss: tensor(9.7810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6128 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6129 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6130 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6131 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6132 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6133 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6134 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6135 loss: tensor(9.8412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6136 loss: tensor(9.5078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6137 loss: tensor(9.4704e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6138 loss: tensor(9.6744e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6139 loss: tensor(9.9404e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6140 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6141 loss: tensor(9.9891e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6142 loss: tensor(9.7193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6143 loss: tensor(9.4225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6144 loss: tensor(9.2490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6145 loss: tensor(9.2467e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6146 loss: tensor(9.3494e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6147 loss: tensor(9.4421e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6148 loss: tensor(9.4447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6149 loss: tensor(9.3577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6150 loss: tensor(9.2470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6151 loss: tensor(9.1871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6152 loss: tensor(9.2075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6153 loss: tensor(9.2783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6154 loss: tensor(9.3420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6155 loss: tensor(9.3549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6156 loss: tensor(9.3132e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6157 loss: tensor(9.2488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6158 loss: tensor(9.2010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6159 loss: tensor(9.1900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6160 loss: tensor(9.2072e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6161 loss: tensor(9.2279e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6162 loss: tensor(9.2302e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6163 loss: tensor(9.2095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6164 loss: tensor(9.1780e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6165 loss: tensor(9.1539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6166 loss: tensor(9.1477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6167 loss: tensor(9.1579e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6168 loss: tensor(9.1735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6169 loss: tensor(9.1830e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6170 loss: tensor(9.1813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6171 loss: tensor(9.1715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6172 loss: tensor(9.1611e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6173 loss: tensor(9.1565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6174 loss: tensor(9.1596e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6175 loss: tensor(9.1669e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6176 loss: tensor(9.1737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6177 loss: tensor(9.1764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6178 loss: tensor(9.1742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6179 loss: tensor(9.1691e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6180 loss: tensor(9.1651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6181 loss: tensor(9.1640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6182 loss: tensor(9.1666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6183 loss: tensor(9.1710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6184 loss: tensor(9.1754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6185 loss: tensor(9.1781e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6186 loss: tensor(9.1793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6187 loss: tensor(9.1801e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6188 loss: tensor(9.1816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6189 loss: tensor(9.1854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6190 loss: tensor(9.1921e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6191 loss: tensor(9.2011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6192 loss: tensor(9.2122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6193 loss: tensor(9.2254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6194 loss: tensor(9.2409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6195 loss: tensor(9.2591e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6196 loss: tensor(9.2811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6197 loss: tensor(9.3077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6198 loss: tensor(9.3398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6199 loss: tensor(9.3772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6200 loss: tensor(9.4186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6201 loss: tensor(9.4625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6202 loss: tensor(9.5061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6203 loss: tensor(9.5446e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6204 loss: tensor(9.5720e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6205 loss: tensor(9.5822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6206 loss: tensor(9.5705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6207 loss: tensor(9.5342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6208 loss: tensor(9.4749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6209 loss: tensor(9.3999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6210 loss: tensor(9.3194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6211 loss: tensor(9.2450e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6212 loss: tensor(9.1868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6213 loss: tensor(9.1502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6214 loss: tensor(9.1357e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6215 loss: tensor(9.1401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6216 loss: tensor(9.1572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6217 loss: tensor(9.1798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6218 loss: tensor(9.2024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6219 loss: tensor(9.2200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6220 loss: tensor(9.2298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6221 loss: tensor(9.2309e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6222 loss: tensor(9.2239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6223 loss: tensor(9.2102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6224 loss: tensor(9.1927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6225 loss: tensor(9.1745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6226 loss: tensor(9.1580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6227 loss: tensor(9.1447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6228 loss: tensor(9.1357e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6229 loss: tensor(9.1308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6230 loss: tensor(9.1296e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6231 loss: tensor(9.1313e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6232 loss: tensor(9.1348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6233 loss: tensor(9.1390e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6234 loss: tensor(9.1432e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6235 loss: tensor(9.1468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6236 loss: tensor(9.1495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6237 loss: tensor(9.1510e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6238 loss: tensor(9.1515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6239 loss: tensor(9.1510e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6240 loss: tensor(9.1499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6241 loss: tensor(9.1481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6242 loss: tensor(9.1458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6243 loss: tensor(9.1433e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6244 loss: tensor(9.1406e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6245 loss: tensor(9.1380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6246 loss: tensor(9.1355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6247 loss: tensor(9.1333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6248 loss: tensor(9.1314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6249 loss: tensor(9.1298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6250 loss: tensor(9.1284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6251 loss: tensor(9.1272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6252 loss: tensor(9.1263e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6253 loss: tensor(9.1256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6254 loss: tensor(9.1249e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6255 loss: tensor(9.1243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6256 loss: tensor(9.1238e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6257 loss: tensor(9.1234e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6258 loss: tensor(9.1231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6259 loss: tensor(9.1227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6260 loss: tensor(9.1225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6261 loss: tensor(9.1222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6262 loss: tensor(9.1220e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6263 loss: tensor(9.1219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6264 loss: tensor(9.1218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6265 loss: tensor(9.1218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6266 loss: tensor(9.1218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6267 loss: tensor(9.1221e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6268 loss: tensor(9.1225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6269 loss: tensor(9.1232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6270 loss: tensor(9.1242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6271 loss: tensor(9.1259e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6272 loss: tensor(9.1281e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6273 loss: tensor(9.1314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6274 loss: tensor(9.1361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6275 loss: tensor(9.1426e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6276 loss: tensor(9.1522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6277 loss: tensor(9.1658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6278 loss: tensor(9.1853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6279 loss: tensor(9.2135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6280 loss: tensor(9.2544e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6281 loss: tensor(9.3132e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6282 loss: tensor(9.3968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6283 loss: tensor(9.5128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6284 loss: tensor(9.6695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6285 loss: tensor(9.8721e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6286 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6287 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6288 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6289 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6290 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6291 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6292 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6293 loss: tensor(9.9031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6294 loss: tensor(9.8465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6295 loss: tensor(9.9613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6299 loss: tensor(9.8668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6300 loss: tensor(9.5078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6301 loss: tensor(9.2202e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6302 loss: tensor(9.1094e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6303 loss: tensor(9.1790e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6304 loss: tensor(9.3443e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6305 loss: tensor(9.4934e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6306 loss: tensor(9.5465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6307 loss: tensor(9.4896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6308 loss: tensor(9.3676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6309 loss: tensor(9.2487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6310 loss: tensor(9.1819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6311 loss: tensor(9.1745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6312 loss: tensor(9.2012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6313 loss: tensor(9.2265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6314 loss: tensor(9.2295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6315 loss: tensor(9.2110e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6316 loss: tensor(9.1871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6317 loss: tensor(9.1737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6318 loss: tensor(9.1754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6319 loss: tensor(9.1842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6320 loss: tensor(9.1873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6321 loss: tensor(9.1766e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6322 loss: tensor(9.1536e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6323 loss: tensor(9.1283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6324 loss: tensor(9.1115e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6325 loss: tensor(9.1096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6326 loss: tensor(9.1207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6327 loss: tensor(9.1365e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6328 loss: tensor(9.1478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6329 loss: tensor(9.1491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6330 loss: tensor(9.1407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6331 loss: tensor(9.1267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6332 loss: tensor(9.1134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6333 loss: tensor(9.1048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6334 loss: tensor(9.1025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6335 loss: tensor(9.1049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6336 loss: tensor(9.1088e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6337 loss: tensor(9.1118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6338 loss: tensor(9.1122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6339 loss: tensor(9.1105e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6340 loss: tensor(9.1079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6341 loss: tensor(9.1057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6342 loss: tensor(9.1048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6343 loss: tensor(9.1048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6344 loss: tensor(9.1050e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6345 loss: tensor(9.1049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6346 loss: tensor(9.1040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6347 loss: tensor(9.1019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6348 loss: tensor(9.0996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6349 loss: tensor(9.0975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6350 loss: tensor(9.0959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6351 loss: tensor(9.0953e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6352 loss: tensor(9.0954e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6353 loss: tensor(9.0959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6354 loss: tensor(9.0966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6355 loss: tensor(9.0969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6356 loss: tensor(9.0968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6357 loss: tensor(9.0963e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6358 loss: tensor(9.0955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6359 loss: tensor(9.0948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6360 loss: tensor(9.0943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6361 loss: tensor(9.0941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6362 loss: tensor(9.0939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6363 loss: tensor(9.0938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6364 loss: tensor(9.0938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6365 loss: tensor(9.0935e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6366 loss: tensor(9.0933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6367 loss: tensor(9.0928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6368 loss: tensor(9.0925e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6369 loss: tensor(9.0919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6370 loss: tensor(9.0914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6371 loss: tensor(9.0910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6372 loss: tensor(9.0907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6373 loss: tensor(9.0905e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6374 loss: tensor(9.0903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6375 loss: tensor(9.0903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6376 loss: tensor(9.0903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6377 loss: tensor(9.0903e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6378 loss: tensor(9.0906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6379 loss: tensor(9.0907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6380 loss: tensor(9.0912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6381 loss: tensor(9.0918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6382 loss: tensor(9.0927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6383 loss: tensor(9.0937e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6384 loss: tensor(9.0953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6385 loss: tensor(9.0978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6386 loss: tensor(9.1012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6387 loss: tensor(9.1061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6388 loss: tensor(9.1132e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6389 loss: tensor(9.1232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6390 loss: tensor(9.1373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6391 loss: tensor(9.1571e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6392 loss: tensor(9.1850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6393 loss: tensor(9.2239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6394 loss: tensor(9.2791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6395 loss: tensor(9.3551e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6396 loss: tensor(9.4585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6397 loss: tensor(9.5943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6398 loss: tensor(9.7650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6399 loss: tensor(9.9633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6400 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6401 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6402 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6403 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6404 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6405 loss: tensor(9.7085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6406 loss: tensor(9.3878e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6407 loss: tensor(9.1999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6408 loss: tensor(9.1828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6409 loss: tensor(9.2949e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6410 loss: tensor(9.4471e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6411 loss: tensor(9.5480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6412 loss: tensor(9.5438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6413 loss: tensor(9.4368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6414 loss: tensor(9.2802e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6415 loss: tensor(9.1463e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6416 loss: tensor(9.0857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6417 loss: tensor(9.1043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6418 loss: tensor(9.1684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6419 loss: tensor(9.2309e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6420 loss: tensor(9.2554e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6421 loss: tensor(9.2316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6422 loss: tensor(9.1762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6423 loss: tensor(9.1188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6424 loss: tensor(9.0853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6425 loss: tensor(9.0853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6426 loss: tensor(9.1102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6427 loss: tensor(9.1412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6428 loss: tensor(9.1606e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6429 loss: tensor(9.1600e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6430 loss: tensor(9.1421e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6431 loss: tensor(9.1177e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6432 loss: tensor(9.0989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6433 loss: tensor(9.0927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6434 loss: tensor(9.0993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6435 loss: tensor(9.1133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6436 loss: tensor(9.1275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6437 loss: tensor(9.1363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6438 loss: tensor(9.1382e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6439 loss: tensor(9.1355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6440 loss: tensor(9.1327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6441 loss: tensor(9.1339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6442 loss: tensor(9.1418e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6443 loss: tensor(9.1567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6444 loss: tensor(9.1770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6445 loss: tensor(9.2008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6446 loss: tensor(9.2269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6447 loss: tensor(9.2550e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6448 loss: tensor(9.2863e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6449 loss: tensor(9.3215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6450 loss: tensor(9.3620e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6451 loss: tensor(9.4065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6452 loss: tensor(9.4517e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6453 loss: tensor(9.4919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6454 loss: tensor(9.5200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6455 loss: tensor(9.5279e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6456 loss: tensor(9.5102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6457 loss: tensor(9.4647e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6458 loss: tensor(9.3947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6459 loss: tensor(9.3096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6460 loss: tensor(9.2233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6461 loss: tensor(9.1493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6462 loss: tensor(9.0974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6463 loss: tensor(9.0710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6464 loss: tensor(9.0678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6465 loss: tensor(9.0817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6466 loss: tensor(9.1048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6467 loss: tensor(9.1298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6468 loss: tensor(9.1507e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6469 loss: tensor(9.1637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6470 loss: tensor(9.1670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6471 loss: tensor(9.1613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6472 loss: tensor(9.1483e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6473 loss: tensor(9.1308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6474 loss: tensor(9.1122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6475 loss: tensor(9.0952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6476 loss: tensor(9.0813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6477 loss: tensor(9.0716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6478 loss: tensor(9.0660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6479 loss: tensor(9.0641e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6480 loss: tensor(9.0648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6481 loss: tensor(9.0672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6482 loss: tensor(9.0705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6483 loss: tensor(9.0738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6484 loss: tensor(9.0767e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6485 loss: tensor(9.0785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6486 loss: tensor(9.0797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6487 loss: tensor(9.0800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6488 loss: tensor(9.0795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6489 loss: tensor(9.0785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6490 loss: tensor(9.0768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6491 loss: tensor(9.0749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6492 loss: tensor(9.0729e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6493 loss: tensor(9.0707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6494 loss: tensor(9.0685e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6495 loss: tensor(9.0662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6496 loss: tensor(9.0640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6497 loss: tensor(9.0619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6498 loss: tensor(9.0602e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6499 loss: tensor(9.0585e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6500 loss: tensor(9.0571e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6501 loss: tensor(9.0559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6502 loss: tensor(9.0549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6503 loss: tensor(9.0540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6504 loss: tensor(9.0532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6505 loss: tensor(9.0525e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6506 loss: tensor(9.0520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6507 loss: tensor(9.0515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6508 loss: tensor(9.0512e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6509 loss: tensor(9.0508e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6510 loss: tensor(9.0504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6511 loss: tensor(9.0501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6512 loss: tensor(9.0498e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6513 loss: tensor(9.0495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6514 loss: tensor(9.0494e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6515 loss: tensor(9.0491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6516 loss: tensor(9.0488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6517 loss: tensor(9.0487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6518 loss: tensor(9.0486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6519 loss: tensor(9.0486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6520 loss: tensor(9.0485e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6521 loss: tensor(9.0488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6522 loss: tensor(9.0491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6523 loss: tensor(9.0495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6524 loss: tensor(9.0504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6525 loss: tensor(9.0518e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6526 loss: tensor(9.0538e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6527 loss: tensor(9.0568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6528 loss: tensor(9.0616e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6529 loss: tensor(9.0688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6530 loss: tensor(9.0794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6531 loss: tensor(9.0952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6532 loss: tensor(9.1190e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6533 loss: tensor(9.1542e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6534 loss: tensor(9.2066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6535 loss: tensor(9.2845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6536 loss: tensor(9.3987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6537 loss: tensor(9.5643e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6538 loss: tensor(9.7963e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6539 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6540 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6541 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6542 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6543 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6544 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6545 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6546 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6547 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6548 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6549 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6550 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6551 loss: tensor(9.9068e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6552 loss: tensor(9.5990e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6553 loss: tensor(9.3424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6554 loss: tensor(9.2726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6555 loss: tensor(9.4069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6556 loss: tensor(9.6190e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6557 loss: tensor(9.7303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6558 loss: tensor(9.6403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6559 loss: tensor(9.3953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6560 loss: tensor(9.1500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6561 loss: tensor(9.0488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6562 loss: tensor(9.1212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6563 loss: tensor(9.2773e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6564 loss: tensor(9.3861e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6565 loss: tensor(9.3703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6566 loss: tensor(9.2498e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6567 loss: tensor(9.1124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6568 loss: tensor(9.0422e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6569 loss: tensor(9.0617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6570 loss: tensor(9.1293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6571 loss: tensor(9.1833e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6572 loss: tensor(9.1861e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6573 loss: tensor(9.1442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6574 loss: tensor(9.0917e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6575 loss: tensor(9.0607e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6576 loss: tensor(9.0597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6577 loss: tensor(9.0751e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6578 loss: tensor(9.0873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6579 loss: tensor(9.0862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6580 loss: tensor(9.0750e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6581 loss: tensor(9.0635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6582 loss: tensor(9.0584e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6583 loss: tensor(9.0592e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6584 loss: tensor(9.0602e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6585 loss: tensor(9.0567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6586 loss: tensor(9.0486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6587 loss: tensor(9.0404e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6588 loss: tensor(9.0372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6589 loss: tensor(9.0402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6590 loss: tensor(9.0463e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6591 loss: tensor(9.0501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6592 loss: tensor(9.0483e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6593 loss: tensor(9.0415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6594 loss: tensor(9.0333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6595 loss: tensor(9.0278e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6596 loss: tensor(9.0270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6597 loss: tensor(9.0301e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6598 loss: tensor(9.0343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6599 loss: tensor(9.0368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6600 loss: tensor(9.0361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6601 loss: tensor(9.0328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6602 loss: tensor(9.0287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6603 loss: tensor(9.0259e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6604 loss: tensor(9.0248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6605 loss: tensor(9.0254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6606 loss: tensor(9.0265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6607 loss: tensor(9.0270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6608 loss: tensor(9.0267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6609 loss: tensor(9.0256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6610 loss: tensor(9.0244e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6611 loss: tensor(9.0234e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6612 loss: tensor(9.0231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6613 loss: tensor(9.0229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6614 loss: tensor(9.0227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6615 loss: tensor(9.0223e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6616 loss: tensor(9.0217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6617 loss: tensor(9.0207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6618 loss: tensor(9.0201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6619 loss: tensor(9.0196e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6620 loss: tensor(9.0195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6621 loss: tensor(9.0193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6622 loss: tensor(9.0194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6623 loss: tensor(9.0193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6624 loss: tensor(9.0189e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6625 loss: tensor(9.0185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6626 loss: tensor(9.0178e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6627 loss: tensor(9.0172e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6628 loss: tensor(9.0167e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6629 loss: tensor(9.0163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6630 loss: tensor(9.0161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6631 loss: tensor(9.0159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6632 loss: tensor(9.0156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6633 loss: tensor(9.0153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6634 loss: tensor(9.0152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6635 loss: tensor(9.0149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6636 loss: tensor(9.0145e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6637 loss: tensor(9.0141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6638 loss: tensor(9.0139e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6639 loss: tensor(9.0136e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6640 loss: tensor(9.0134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6641 loss: tensor(9.0131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6642 loss: tensor(9.0130e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6643 loss: tensor(9.0126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6644 loss: tensor(9.0123e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6645 loss: tensor(9.0120e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6646 loss: tensor(9.0117e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6647 loss: tensor(9.0113e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6648 loss: tensor(9.0110e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6649 loss: tensor(9.0107e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6650 loss: tensor(9.0105e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6651 loss: tensor(9.0102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6652 loss: tensor(9.0099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6653 loss: tensor(9.0096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6654 loss: tensor(9.0094e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6655 loss: tensor(9.0091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6656 loss: tensor(9.0089e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6657 loss: tensor(9.0087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6658 loss: tensor(9.0085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6659 loss: tensor(9.0083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6660 loss: tensor(9.0081e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6661 loss: tensor(9.0079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6662 loss: tensor(9.0079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6663 loss: tensor(9.0077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6664 loss: tensor(9.0077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6665 loss: tensor(9.0077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6666 loss: tensor(9.0080e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6667 loss: tensor(9.0085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6668 loss: tensor(9.0091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6669 loss: tensor(9.0100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6670 loss: tensor(9.0116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6671 loss: tensor(9.0138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6672 loss: tensor(9.0170e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6673 loss: tensor(9.0212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6674 loss: tensor(9.0274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6675 loss: tensor(9.0361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6676 loss: tensor(9.0490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6677 loss: tensor(9.0672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6678 loss: tensor(9.0933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6679 loss: tensor(9.1308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6680 loss: tensor(9.1841e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6681 loss: tensor(9.2598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6682 loss: tensor(9.3651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6683 loss: tensor(9.5073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6684 loss: tensor(9.6918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6685 loss: tensor(9.9134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6686 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6687 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6688 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6689 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6690 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6691 loss: tensor(9.6341e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6692 loss: tensor(9.2504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6693 loss: tensor(9.0392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6694 loss: tensor(9.0448e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6695 loss: tensor(9.2049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6696 loss: tensor(9.3982e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6697 loss: tensor(9.5105e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6698 loss: tensor(9.4841e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6699 loss: tensor(9.3402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6700 loss: tensor(9.1614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6701 loss: tensor(9.0394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6702 loss: tensor(9.0198e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6703 loss: tensor(9.0842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6704 loss: tensor(9.1735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6705 loss: tensor(9.2268e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6706 loss: tensor(9.2149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6707 loss: tensor(9.1500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6708 loss: tensor(9.0726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6709 loss: tensor(9.0234e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6710 loss: tensor(9.0203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6711 loss: tensor(9.0533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6712 loss: tensor(9.0952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6713 loss: tensor(9.1200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6714 loss: tensor(9.1165e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6715 loss: tensor(9.0918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6716 loss: tensor(9.0640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6717 loss: tensor(9.0506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6718 loss: tensor(9.0594e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6719 loss: tensor(9.0863e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6720 loss: tensor(9.1204e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6721 loss: tensor(9.1512e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6722 loss: tensor(9.1747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6723 loss: tensor(9.1939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6724 loss: tensor(9.2163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6725 loss: tensor(9.2493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6726 loss: tensor(9.2959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6727 loss: tensor(9.3533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6728 loss: tensor(9.4144e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6729 loss: tensor(9.4683e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6730 loss: tensor(9.5037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6731 loss: tensor(9.5112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6732 loss: tensor(9.4859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6733 loss: tensor(9.4280e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6734 loss: tensor(9.3443e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6735 loss: tensor(9.2471e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6736 loss: tensor(9.1520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6737 loss: tensor(9.0733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6738 loss: tensor(9.0206e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6739 loss: tensor(8.9968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6740 loss: tensor(8.9983e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6741 loss: tensor(9.0179e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6742 loss: tensor(9.0467e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6743 loss: tensor(9.0758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6744 loss: tensor(9.0980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6745 loss: tensor(9.1087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6746 loss: tensor(9.1058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6747 loss: tensor(9.0906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6748 loss: tensor(9.0672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6749 loss: tensor(9.0408e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6750 loss: tensor(9.0161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6751 loss: tensor(8.9968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6752 loss: tensor(8.9849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6753 loss: tensor(8.9808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6754 loss: tensor(8.9829e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6755 loss: tensor(8.9893e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6756 loss: tensor(8.9977e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6757 loss: tensor(9.0057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6758 loss: tensor(9.0119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6759 loss: tensor(9.0153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6760 loss: tensor(9.0157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6761 loss: tensor(9.0133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6762 loss: tensor(9.0086e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6763 loss: tensor(9.0028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6764 loss: tensor(8.9965e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6765 loss: tensor(8.9906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6766 loss: tensor(8.9854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6767 loss: tensor(8.9813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6768 loss: tensor(8.9786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6769 loss: tensor(8.9768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6770 loss: tensor(8.9761e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6771 loss: tensor(8.9759e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6772 loss: tensor(8.9763e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6773 loss: tensor(8.9769e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6774 loss: tensor(8.9779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6775 loss: tensor(8.9788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6776 loss: tensor(8.9797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6777 loss: tensor(8.9804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6778 loss: tensor(8.9808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6779 loss: tensor(8.9813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6780 loss: tensor(8.9816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6781 loss: tensor(8.9818e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6782 loss: tensor(8.9820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6783 loss: tensor(8.9822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6784 loss: tensor(8.9823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6785 loss: tensor(8.9823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6786 loss: tensor(8.9825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6787 loss: tensor(8.9825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6788 loss: tensor(8.9828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6789 loss: tensor(8.9835e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6790 loss: tensor(8.9842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6791 loss: tensor(8.9854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6792 loss: tensor(8.9870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6793 loss: tensor(8.9893e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6794 loss: tensor(8.9922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6795 loss: tensor(8.9960e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6796 loss: tensor(9.0010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6797 loss: tensor(9.0073e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6798 loss: tensor(9.0157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6799 loss: tensor(9.0265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6800 loss: tensor(9.0407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6801 loss: tensor(9.0594e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6802 loss: tensor(9.0838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6803 loss: tensor(9.1149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6804 loss: tensor(9.1544e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6805 loss: tensor(9.2036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6806 loss: tensor(9.2632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6807 loss: tensor(9.3332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6808 loss: tensor(9.4113e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6809 loss: tensor(9.4928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6810 loss: tensor(9.5690e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6811 loss: tensor(9.6272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6812 loss: tensor(9.6523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6813 loss: tensor(9.6324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6814 loss: tensor(9.5638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6815 loss: tensor(9.4553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6816 loss: tensor(9.3303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6817 loss: tensor(9.2186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6818 loss: tensor(9.1461e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6819 loss: tensor(9.1252e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6820 loss: tensor(9.1531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6821 loss: tensor(9.2146e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6822 loss: tensor(9.2891e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6823 loss: tensor(9.3553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6824 loss: tensor(9.3962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6825 loss: tensor(9.4030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6826 loss: tensor(9.3761e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6827 loss: tensor(9.3235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6828 loss: tensor(9.2583e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6829 loss: tensor(9.1942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6830 loss: tensor(9.1409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6831 loss: tensor(9.1031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6832 loss: tensor(9.0798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6833 loss: tensor(9.0673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6834 loss: tensor(9.0594e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6835 loss: tensor(9.0516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6836 loss: tensor(9.0401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6837 loss: tensor(9.0254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6838 loss: tensor(9.0087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6839 loss: tensor(8.9930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6840 loss: tensor(8.9811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6841 loss: tensor(8.9751e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6842 loss: tensor(8.9757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6843 loss: tensor(8.9817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6844 loss: tensor(8.9914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6845 loss: tensor(9.0025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6846 loss: tensor(9.0129e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6847 loss: tensor(9.0207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6848 loss: tensor(9.0255e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6849 loss: tensor(9.0267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6850 loss: tensor(9.0248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6851 loss: tensor(9.0209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6852 loss: tensor(9.0157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6853 loss: tensor(9.0103e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6854 loss: tensor(9.0051e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6855 loss: tensor(9.0008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6856 loss: tensor(8.9975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6857 loss: tensor(8.9955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6858 loss: tensor(8.9944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6859 loss: tensor(8.9942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6860 loss: tensor(8.9942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6861 loss: tensor(8.9948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6862 loss: tensor(8.9950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6863 loss: tensor(8.9949e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6864 loss: tensor(8.9947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6865 loss: tensor(8.9947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6866 loss: tensor(8.9950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6867 loss: tensor(8.9957e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6868 loss: tensor(8.9971e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6869 loss: tensor(8.9992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6870 loss: tensor(9.0024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6871 loss: tensor(9.0069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6872 loss: tensor(9.0126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6873 loss: tensor(9.0200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6874 loss: tensor(9.0296e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6875 loss: tensor(9.0417e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6876 loss: tensor(9.0571e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6877 loss: tensor(9.0758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6878 loss: tensor(9.0985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6879 loss: tensor(9.1257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6880 loss: tensor(9.1574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6881 loss: tensor(9.1931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6882 loss: tensor(9.2317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6883 loss: tensor(9.2722e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6884 loss: tensor(9.3125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6885 loss: tensor(9.3490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6886 loss: tensor(9.3777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6887 loss: tensor(9.3946e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6888 loss: tensor(9.3960e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6889 loss: tensor(9.3805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6890 loss: tensor(9.3493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6891 loss: tensor(9.3063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6892 loss: tensor(9.2588e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6893 loss: tensor(9.2153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6894 loss: tensor(9.1837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6895 loss: tensor(9.1682e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6896 loss: tensor(9.1695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6897 loss: tensor(9.1846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6898 loss: tensor(9.2076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6899 loss: tensor(9.2310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6900 loss: tensor(9.2482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6901 loss: tensor(9.2540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6902 loss: tensor(9.2446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6903 loss: tensor(9.2197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6904 loss: tensor(9.1809e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6905 loss: tensor(9.1330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6906 loss: tensor(9.0820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6907 loss: tensor(9.0334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6908 loss: tensor(8.9924e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6909 loss: tensor(8.9622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6910 loss: tensor(8.9439e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6911 loss: tensor(8.9367e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6912 loss: tensor(8.9383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6913 loss: tensor(8.9464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6914 loss: tensor(8.9580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6915 loss: tensor(8.9705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6916 loss: tensor(8.9825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6917 loss: tensor(8.9923e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6918 loss: tensor(8.9992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6919 loss: tensor(9.0029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6920 loss: tensor(9.0032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6921 loss: tensor(9.0006e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6922 loss: tensor(8.9959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6923 loss: tensor(8.9895e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6924 loss: tensor(8.9823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6925 loss: tensor(8.9749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6926 loss: tensor(8.9676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6927 loss: tensor(8.9608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6928 loss: tensor(8.9546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6929 loss: tensor(8.9492e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6930 loss: tensor(8.9447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6931 loss: tensor(8.9410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6932 loss: tensor(8.9380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6933 loss: tensor(8.9357e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6934 loss: tensor(8.9340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6935 loss: tensor(8.9329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6936 loss: tensor(8.9320e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6937 loss: tensor(8.9317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6938 loss: tensor(8.9317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6939 loss: tensor(8.9318e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6940 loss: tensor(8.9326e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6941 loss: tensor(8.9336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6942 loss: tensor(8.9352e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6943 loss: tensor(8.9372e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6944 loss: tensor(8.9400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6945 loss: tensor(8.9438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6946 loss: tensor(8.9489e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6947 loss: tensor(8.9556e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6948 loss: tensor(8.9648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6949 loss: tensor(8.9777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6950 loss: tensor(8.9953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6951 loss: tensor(9.0193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6952 loss: tensor(9.0522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6953 loss: tensor(9.0975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6954 loss: tensor(9.1597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6955 loss: tensor(9.2435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6956 loss: tensor(9.3545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6957 loss: tensor(9.4978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6958 loss: tensor(9.6758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6959 loss: tensor(9.8835e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6960 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6961 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6962 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6963 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6964 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6965 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6966 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6967 loss: tensor(9.8000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6968 loss: tensor(9.6444e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6969 loss: tensor(9.5401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6970 loss: tensor(9.4732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6971 loss: tensor(9.4232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6972 loss: tensor(9.3692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6973 loss: tensor(9.2996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6974 loss: tensor(9.2212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6975 loss: tensor(9.1571e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6976 loss: tensor(9.1293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6977 loss: tensor(9.1414e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6978 loss: tensor(9.1747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6979 loss: tensor(9.1997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6980 loss: tensor(9.1931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6981 loss: tensor(9.1480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6982 loss: tensor(9.0777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6983 loss: tensor(9.0083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6984 loss: tensor(8.9644e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6985 loss: tensor(8.9582e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6986 loss: tensor(8.9837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6987 loss: tensor(9.0211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6988 loss: tensor(9.0489e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6989 loss: tensor(9.0530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6990 loss: tensor(9.0307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6991 loss: tensor(8.9914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6992 loss: tensor(8.9506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6993 loss: tensor(8.9228e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6994 loss: tensor(8.9149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6995 loss: tensor(8.9249e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6996 loss: tensor(8.9444e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6997 loss: tensor(8.9625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6998 loss: tensor(8.9713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 6999 loss: tensor(8.9680e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7000 loss: tensor(8.9548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7001 loss: tensor(8.9372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7002 loss: tensor(8.9215e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7003 loss: tensor(8.9118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7004 loss: tensor(8.9096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7005 loss: tensor(8.9134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7006 loss: tensor(8.9200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7007 loss: tensor(8.9260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7008 loss: tensor(8.9291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7009 loss: tensor(8.9289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7010 loss: tensor(8.9256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7011 loss: tensor(8.9208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7012 loss: tensor(8.9160e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7013 loss: tensor(8.9123e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7014 loss: tensor(8.9102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7015 loss: tensor(8.9093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7016 loss: tensor(8.9093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7017 loss: tensor(8.9097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7018 loss: tensor(8.9098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7019 loss: tensor(8.9096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7020 loss: tensor(8.9091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7021 loss: tensor(8.9083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7022 loss: tensor(8.9076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7023 loss: tensor(8.9069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7024 loss: tensor(8.9066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7025 loss: tensor(8.9064e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7026 loss: tensor(8.9063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7027 loss: tensor(8.9062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7028 loss: tensor(8.9060e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7029 loss: tensor(8.9054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7030 loss: tensor(8.9045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7031 loss: tensor(8.9037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7032 loss: tensor(8.9028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7033 loss: tensor(8.9019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7034 loss: tensor(8.9010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7035 loss: tensor(8.9005e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7036 loss: tensor(8.9002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7037 loss: tensor(8.9000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7038 loss: tensor(8.8998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7039 loss: tensor(8.8997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7040 loss: tensor(8.8998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7041 loss: tensor(8.8998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7042 loss: tensor(8.8997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7043 loss: tensor(8.8996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7044 loss: tensor(8.8995e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7045 loss: tensor(8.8992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7046 loss: tensor(8.8988e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7047 loss: tensor(8.8984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7048 loss: tensor(8.8980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7049 loss: tensor(8.8976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7050 loss: tensor(8.8974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7051 loss: tensor(8.8972e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7052 loss: tensor(8.8970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7053 loss: tensor(8.8969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7054 loss: tensor(8.8967e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7055 loss: tensor(8.8968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7056 loss: tensor(8.8969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7057 loss: tensor(8.8972e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7058 loss: tensor(8.8976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7059 loss: tensor(8.8984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7060 loss: tensor(8.8996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7061 loss: tensor(8.9011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7062 loss: tensor(8.9033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7063 loss: tensor(8.9065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7064 loss: tensor(8.9108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7065 loss: tensor(8.9170e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7066 loss: tensor(8.9257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7067 loss: tensor(8.9380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7068 loss: tensor(8.9558e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7069 loss: tensor(8.9810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7070 loss: tensor(9.0168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7071 loss: tensor(9.0673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7072 loss: tensor(9.1381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7073 loss: tensor(9.2355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7074 loss: tensor(9.3654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7075 loss: tensor(9.5321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7076 loss: tensor(9.7312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7077 loss: tensor(9.9423e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7078 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7079 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7080 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7081 loss: tensor(9.8893e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7082 loss: tensor(9.5346e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7083 loss: tensor(9.2000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7084 loss: tensor(9.0100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7085 loss: tensor(9.0135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7086 loss: tensor(9.1687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7087 loss: tensor(9.3772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7088 loss: tensor(9.5365e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7089 loss: tensor(9.5839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7090 loss: tensor(9.5231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7091 loss: tensor(9.4151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7092 loss: tensor(9.3408e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7093 loss: tensor(9.3497e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7094 loss: tensor(9.4328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7095 loss: tensor(9.5351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7096 loss: tensor(9.5885e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7097 loss: tensor(9.5499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7098 loss: tensor(9.4212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7099 loss: tensor(9.2459e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7100 loss: tensor(9.0842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7101 loss: tensor(8.9795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7102 loss: tensor(8.9422e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7103 loss: tensor(8.9526e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7104 loss: tensor(8.9798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7105 loss: tensor(8.9996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7106 loss: tensor(9.0045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7107 loss: tensor(9.0003e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7108 loss: tensor(8.9981e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7109 loss: tensor(9.0032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7110 loss: tensor(9.0125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7111 loss: tensor(9.0166e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7112 loss: tensor(9.0071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7113 loss: tensor(8.9817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7114 loss: tensor(8.9465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7115 loss: tensor(8.9117e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7116 loss: tensor(8.8870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7117 loss: tensor(8.8779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7118 loss: tensor(8.8828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7119 loss: tensor(8.8964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7120 loss: tensor(8.9109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7121 loss: tensor(8.9206e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7122 loss: tensor(8.9235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7123 loss: tensor(8.9207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7124 loss: tensor(8.9148e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7125 loss: tensor(8.9087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7126 loss: tensor(8.9039e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7127 loss: tensor(8.9003e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7128 loss: tensor(8.8975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7129 loss: tensor(8.8940e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7130 loss: tensor(8.8896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7131 loss: tensor(8.8846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7132 loss: tensor(8.8795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7133 loss: tensor(8.8756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7134 loss: tensor(8.8736e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7135 loss: tensor(8.8734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7136 loss: tensor(8.8747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7137 loss: tensor(8.8765e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7138 loss: tensor(8.8784e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7139 loss: tensor(8.8797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7140 loss: tensor(8.8803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7141 loss: tensor(8.8804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7142 loss: tensor(8.8803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7143 loss: tensor(8.8797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7144 loss: tensor(8.8797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7145 loss: tensor(8.8796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7146 loss: tensor(8.8798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7147 loss: tensor(8.8801e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7148 loss: tensor(8.8805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7149 loss: tensor(8.8806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7150 loss: tensor(8.8806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7151 loss: tensor(8.8805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7152 loss: tensor(8.8806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7153 loss: tensor(8.8807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7154 loss: tensor(8.8811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7155 loss: tensor(8.8819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7156 loss: tensor(8.8831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7157 loss: tensor(8.8848e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7158 loss: tensor(8.8870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7159 loss: tensor(8.8902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7160 loss: tensor(8.8944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7161 loss: tensor(8.8999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7162 loss: tensor(8.9070e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7163 loss: tensor(8.9161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7164 loss: tensor(8.9284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7165 loss: tensor(8.9442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7166 loss: tensor(8.9645e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7167 loss: tensor(8.9910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7168 loss: tensor(9.0249e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7169 loss: tensor(9.0678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7170 loss: tensor(9.1214e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7171 loss: tensor(9.1871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7172 loss: tensor(9.2646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7173 loss: tensor(9.3510e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7174 loss: tensor(9.4397e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7175 loss: tensor(9.5195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7176 loss: tensor(9.5747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7177 loss: tensor(9.5872e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7178 loss: tensor(9.5435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7179 loss: tensor(9.4408e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7180 loss: tensor(9.2941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7181 loss: tensor(9.1339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7182 loss: tensor(8.9953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7183 loss: tensor(8.9057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7184 loss: tensor(8.8755e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7185 loss: tensor(8.8963e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7186 loss: tensor(8.9474e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7187 loss: tensor(9.0050e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7188 loss: tensor(9.0481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7189 loss: tensor(9.0631e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7190 loss: tensor(9.0466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7191 loss: tensor(9.0061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7192 loss: tensor(8.9545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7193 loss: tensor(8.9060e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7194 loss: tensor(8.8723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7195 loss: tensor(8.8584e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7196 loss: tensor(8.8626e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7197 loss: tensor(8.8789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7198 loss: tensor(8.8993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7199 loss: tensor(8.9168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7200 loss: tensor(8.9263e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7201 loss: tensor(8.9261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7202 loss: tensor(8.9177e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7203 loss: tensor(8.9039e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7204 loss: tensor(8.8886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7205 loss: tensor(8.8757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7206 loss: tensor(8.8672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7207 loss: tensor(8.8639e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7208 loss: tensor(8.8658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7209 loss: tensor(8.8713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7210 loss: tensor(8.8788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7211 loss: tensor(8.8866e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7212 loss: tensor(8.8936e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7213 loss: tensor(8.8992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7214 loss: tensor(8.9038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7215 loss: tensor(8.9080e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7216 loss: tensor(8.9128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7217 loss: tensor(8.9199e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7218 loss: tensor(8.9308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7219 loss: tensor(8.9468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7220 loss: tensor(8.9692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7221 loss: tensor(8.9997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7222 loss: tensor(9.0399e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7223 loss: tensor(9.0910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7224 loss: tensor(9.1536e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7225 loss: tensor(9.2274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7226 loss: tensor(9.3097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7227 loss: tensor(9.3942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7228 loss: tensor(9.4698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7229 loss: tensor(9.5214e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7230 loss: tensor(9.5319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7231 loss: tensor(9.4877e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7232 loss: tensor(9.3876e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7233 loss: tensor(9.2468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7234 loss: tensor(9.0949e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7235 loss: tensor(8.9656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7236 loss: tensor(8.8840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7237 loss: tensor(8.8583e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7238 loss: tensor(8.8802e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7239 loss: tensor(8.9299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7240 loss: tensor(8.9848e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7241 loss: tensor(9.0253e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7242 loss: tensor(9.0393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7243 loss: tensor(9.0244e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7244 loss: tensor(8.9867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7245 loss: tensor(8.9383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7246 loss: tensor(8.8926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7247 loss: tensor(8.8597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7248 loss: tensor(8.8448e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7249 loss: tensor(8.8466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7250 loss: tensor(8.8597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7251 loss: tensor(8.8775e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7252 loss: tensor(8.8933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7253 loss: tensor(8.9021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7254 loss: tensor(8.9023e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7255 loss: tensor(8.8945e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7256 loss: tensor(8.8815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7257 loss: tensor(8.8666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7258 loss: tensor(8.8534e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7259 loss: tensor(8.8440e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7260 loss: tensor(8.8394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7261 loss: tensor(8.8393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7262 loss: tensor(8.8424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7263 loss: tensor(8.8468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7264 loss: tensor(8.8513e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7265 loss: tensor(8.8547e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7266 loss: tensor(8.8563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7267 loss: tensor(8.8559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7268 loss: tensor(8.8539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7269 loss: tensor(8.8507e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7270 loss: tensor(8.8470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7271 loss: tensor(8.8433e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7272 loss: tensor(8.8402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7273 loss: tensor(8.8379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7274 loss: tensor(8.8363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7275 loss: tensor(8.8358e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7276 loss: tensor(8.8360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7277 loss: tensor(8.8370e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7278 loss: tensor(8.8384e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7279 loss: tensor(8.8403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7280 loss: tensor(8.8428e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7281 loss: tensor(8.8460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7282 loss: tensor(8.8508e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7283 loss: tensor(8.8581e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7284 loss: tensor(8.8686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7285 loss: tensor(8.8850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7286 loss: tensor(8.9109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7287 loss: tensor(8.9513e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7288 loss: tensor(9.0147e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7289 loss: tensor(9.1130e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7290 loss: tensor(9.2632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7291 loss: tensor(9.4865e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7292 loss: tensor(9.8032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7293 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7294 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7295 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7296 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7297 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7298 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7299 loss: tensor(9.3501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7300 loss: tensor(8.9415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7301 loss: tensor(9.0548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7302 loss: tensor(9.4728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7303 loss: tensor(9.8151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7304 loss: tensor(9.8061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7305 loss: tensor(9.4599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7306 loss: tensor(9.0536e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7307 loss: tensor(8.8784e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7308 loss: tensor(8.9943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7309 loss: tensor(9.2194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7310 loss: tensor(9.3209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7311 loss: tensor(9.2079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7312 loss: tensor(8.9868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7313 loss: tensor(8.8411e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7314 loss: tensor(8.8606e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7315 loss: tensor(8.9807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7316 loss: tensor(9.0662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7317 loss: tensor(9.0380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7318 loss: tensor(8.9298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7319 loss: tensor(8.8394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7320 loss: tensor(8.8324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7321 loss: tensor(8.8914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7322 loss: tensor(8.9478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7323 loss: tensor(8.9484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7324 loss: tensor(8.8987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7325 loss: tensor(8.8457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7326 loss: tensor(8.8308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7327 loss: tensor(8.8565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7328 loss: tensor(8.8913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7329 loss: tensor(8.9026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7330 loss: tensor(8.8838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7331 loss: tensor(8.8548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7332 loss: tensor(8.8416e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7333 loss: tensor(8.8523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7334 loss: tensor(8.8752e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7335 loss: tensor(8.8921e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7336 loss: tensor(8.8944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7337 loss: tensor(8.8885e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7338 loss: tensor(8.8883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7339 loss: tensor(8.9029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7340 loss: tensor(8.9312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7341 loss: tensor(8.9658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7342 loss: tensor(9.0002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7343 loss: tensor(9.0356e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7344 loss: tensor(9.0779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7345 loss: tensor(9.1330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7346 loss: tensor(9.2020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7347 loss: tensor(9.2787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7348 loss: tensor(9.3518e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7349 loss: tensor(9.4079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7350 loss: tensor(9.4342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7351 loss: tensor(9.4209e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7352 loss: tensor(9.3633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7353 loss: tensor(9.2652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7354 loss: tensor(9.1406e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7355 loss: tensor(9.0124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7356 loss: tensor(8.9051e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7357 loss: tensor(8.8366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7358 loss: tensor(8.8137e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7359 loss: tensor(8.8299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7360 loss: tensor(8.8708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7361 loss: tensor(8.9183e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7362 loss: tensor(8.9563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7363 loss: tensor(8.9741e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7364 loss: tensor(8.9686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7365 loss: tensor(8.9437e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7366 loss: tensor(8.9074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7367 loss: tensor(8.8694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7368 loss: tensor(8.8380e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7369 loss: tensor(8.8180e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7370 loss: tensor(8.8107e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7371 loss: tensor(8.8142e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7372 loss: tensor(8.8247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7373 loss: tensor(8.8378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7374 loss: tensor(8.8492e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7375 loss: tensor(8.8562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7376 loss: tensor(8.8575e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7377 loss: tensor(8.8529e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7378 loss: tensor(8.8442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7379 loss: tensor(8.8335e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7380 loss: tensor(8.8231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7381 loss: tensor(8.8147e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7382 loss: tensor(8.8091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7383 loss: tensor(8.8066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7384 loss: tensor(8.8065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7385 loss: tensor(8.8083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7386 loss: tensor(8.8110e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7387 loss: tensor(8.8137e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7388 loss: tensor(8.8160e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7389 loss: tensor(8.8177e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7390 loss: tensor(8.8182e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7391 loss: tensor(8.8177e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7392 loss: tensor(8.8163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7393 loss: tensor(8.8144e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7394 loss: tensor(8.8122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7395 loss: tensor(8.8099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7396 loss: tensor(8.8077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7397 loss: tensor(8.8057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7398 loss: tensor(8.8041e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7399 loss: tensor(8.8028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7400 loss: tensor(8.8019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7401 loss: tensor(8.8013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7402 loss: tensor(8.8010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7403 loss: tensor(8.8008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7404 loss: tensor(8.8007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7405 loss: tensor(8.8007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7406 loss: tensor(8.8008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7407 loss: tensor(8.8009e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7408 loss: tensor(8.8011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7409 loss: tensor(8.8011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7410 loss: tensor(8.8013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7411 loss: tensor(8.8014e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7412 loss: tensor(8.8015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7413 loss: tensor(8.8016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7414 loss: tensor(8.8018e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7415 loss: tensor(8.8022e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7416 loss: tensor(8.8027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7417 loss: tensor(8.8032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7418 loss: tensor(8.8038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7419 loss: tensor(8.8049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7420 loss: tensor(8.8063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7421 loss: tensor(8.8081e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7422 loss: tensor(8.8105e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7423 loss: tensor(8.8138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7424 loss: tensor(8.8181e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7425 loss: tensor(8.8236e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7426 loss: tensor(8.8308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7427 loss: tensor(8.8403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7428 loss: tensor(8.8530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7429 loss: tensor(8.8700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7430 loss: tensor(8.8928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7431 loss: tensor(8.9229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7432 loss: tensor(8.9624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7433 loss: tensor(9.0138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7434 loss: tensor(9.0790e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7435 loss: tensor(9.1596e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7436 loss: tensor(9.2548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7437 loss: tensor(9.3600e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7438 loss: tensor(9.4654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7439 loss: tensor(9.5531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7440 loss: tensor(9.5995e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7441 loss: tensor(9.5815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7442 loss: tensor(9.4871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7443 loss: tensor(9.3266e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7444 loss: tensor(9.1353e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7445 loss: tensor(8.9610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7446 loss: tensor(8.8446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7447 loss: tensor(8.8035e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7448 loss: tensor(8.8286e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7449 loss: tensor(8.8923e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7450 loss: tensor(8.9612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7451 loss: tensor(9.0075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7452 loss: tensor(9.0154e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7453 loss: tensor(8.9843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7454 loss: tensor(8.9276e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7455 loss: tensor(8.8662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7456 loss: tensor(8.8188e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7457 loss: tensor(8.7964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7458 loss: tensor(8.7992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7459 loss: tensor(8.8197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7460 loss: tensor(8.8458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7461 loss: tensor(8.8662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7462 loss: tensor(8.8738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7463 loss: tensor(8.8668e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7464 loss: tensor(8.8488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7465 loss: tensor(8.8261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7466 loss: tensor(8.8052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7467 loss: tensor(8.7911e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7468 loss: tensor(8.7855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7469 loss: tensor(8.7873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7470 loss: tensor(8.7938e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7471 loss: tensor(8.8015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7472 loss: tensor(8.8073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7473 loss: tensor(8.8095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7474 loss: tensor(8.8077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7475 loss: tensor(8.8025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7476 loss: tensor(8.7958e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7477 loss: tensor(8.7891e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7478 loss: tensor(8.7839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7479 loss: tensor(8.7807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7480 loss: tensor(8.7797e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7481 loss: tensor(8.7804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7482 loss: tensor(8.7819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7483 loss: tensor(8.7839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7484 loss: tensor(8.7855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7485 loss: tensor(8.7864e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7486 loss: tensor(8.7865e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7487 loss: tensor(8.7857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7488 loss: tensor(8.7845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7489 loss: tensor(8.7830e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7490 loss: tensor(8.7816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7491 loss: tensor(8.7804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7492 loss: tensor(8.7796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7493 loss: tensor(8.7793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7494 loss: tensor(8.7795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7495 loss: tensor(8.7805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7496 loss: tensor(8.7821e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7497 loss: tensor(8.7846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7498 loss: tensor(8.7881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7499 loss: tensor(8.7930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7500 loss: tensor(8.8001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7501 loss: tensor(8.8102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7502 loss: tensor(8.8245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7503 loss: tensor(8.8452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7504 loss: tensor(8.8753e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7505 loss: tensor(8.9192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7506 loss: tensor(8.9827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7507 loss: tensor(9.0742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7508 loss: tensor(9.2034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7509 loss: tensor(9.3800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7510 loss: tensor(9.6085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7511 loss: tensor(9.8807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7512 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7513 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7514 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7515 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7516 loss: tensor(9.7871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7517 loss: tensor(9.3164e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7518 loss: tensor(8.9897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7519 loss: tensor(8.9219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7520 loss: tensor(9.0805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7521 loss: tensor(9.3237e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7522 loss: tensor(9.4884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7523 loss: tensor(9.4743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7524 loss: tensor(9.2931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7525 loss: tensor(9.0523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7526 loss: tensor(8.8822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7527 loss: tensor(8.8486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7528 loss: tensor(8.9242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7529 loss: tensor(9.0227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7530 loss: tensor(9.0610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7531 loss: tensor(9.0096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7532 loss: tensor(8.9020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7533 loss: tensor(8.8041e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7534 loss: tensor(8.7651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7535 loss: tensor(8.7908e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7536 loss: tensor(8.8473e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7537 loss: tensor(8.8899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7538 loss: tensor(8.8917e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7539 loss: tensor(8.8565e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7540 loss: tensor(8.8106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7541 loss: tensor(8.7825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7542 loss: tensor(8.7847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7543 loss: tensor(8.8089e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7544 loss: tensor(8.8358e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7545 loss: tensor(8.8482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7546 loss: tensor(8.8407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7547 loss: tensor(8.8211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7548 loss: tensor(8.8027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7549 loss: tensor(8.7960e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7550 loss: tensor(8.8025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7551 loss: tensor(8.8166e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7552 loss: tensor(8.8299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7553 loss: tensor(8.8364e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7554 loss: tensor(8.8355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7555 loss: tensor(8.8315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7556 loss: tensor(8.8303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7557 loss: tensor(8.8355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7558 loss: tensor(8.8480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7559 loss: tensor(8.8658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7560 loss: tensor(8.8853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7561 loss: tensor(8.9043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7562 loss: tensor(8.9227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7563 loss: tensor(8.9425e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7564 loss: tensor(8.9652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7565 loss: tensor(8.9917e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7566 loss: tensor(9.0206e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7567 loss: tensor(9.0495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7568 loss: tensor(9.0742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7569 loss: tensor(9.0904e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7570 loss: tensor(9.0950e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7571 loss: tensor(9.0855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7572 loss: tensor(9.0614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7573 loss: tensor(9.0242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7574 loss: tensor(8.9772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7575 loss: tensor(8.9255e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7576 loss: tensor(8.8742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7577 loss: tensor(8.8285e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7578 loss: tensor(8.7922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7579 loss: tensor(8.7677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7580 loss: tensor(8.7552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7581 loss: tensor(8.7533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7582 loss: tensor(8.7593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7583 loss: tensor(8.7706e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7584 loss: tensor(8.7840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7585 loss: tensor(8.7970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7586 loss: tensor(8.8077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7587 loss: tensor(8.8150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7588 loss: tensor(8.8185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7589 loss: tensor(8.8183e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7590 loss: tensor(8.8150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7591 loss: tensor(8.8089e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7592 loss: tensor(8.8014e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7593 loss: tensor(8.7931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7594 loss: tensor(8.7844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7595 loss: tensor(8.7761e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7596 loss: tensor(8.7685e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7597 loss: tensor(8.7621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7598 loss: tensor(8.7569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7599 loss: tensor(8.7529e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7600 loss: tensor(8.7499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7601 loss: tensor(8.7480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7602 loss: tensor(8.7468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7603 loss: tensor(8.7465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7604 loss: tensor(8.7466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7605 loss: tensor(8.7472e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7606 loss: tensor(8.7482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7607 loss: tensor(8.7493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7608 loss: tensor(8.7503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7609 loss: tensor(8.7516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7610 loss: tensor(8.7530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7611 loss: tensor(8.7543e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7612 loss: tensor(8.7560e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7613 loss: tensor(8.7577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7614 loss: tensor(8.7598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7615 loss: tensor(8.7622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7616 loss: tensor(8.7652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7617 loss: tensor(8.7687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7618 loss: tensor(8.7730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7619 loss: tensor(8.7785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7620 loss: tensor(8.7854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7621 loss: tensor(8.7943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7622 loss: tensor(8.8055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7623 loss: tensor(8.8202e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7624 loss: tensor(8.8387e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7625 loss: tensor(8.8624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7626 loss: tensor(8.8920e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7627 loss: tensor(8.9291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7628 loss: tensor(8.9745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7629 loss: tensor(9.0286e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7630 loss: tensor(9.0912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7631 loss: tensor(9.1599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7632 loss: tensor(9.2306e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7633 loss: tensor(9.2955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7634 loss: tensor(9.3435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7635 loss: tensor(9.3621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7636 loss: tensor(9.3415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7637 loss: tensor(9.2785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7638 loss: tensor(9.1808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7639 loss: tensor(9.0660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7640 loss: tensor(8.9575e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7641 loss: tensor(8.8763e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7642 loss: tensor(8.8339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7643 loss: tensor(8.8290e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7644 loss: tensor(8.8514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7645 loss: tensor(8.8857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7646 loss: tensor(8.9161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7647 loss: tensor(8.9315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7648 loss: tensor(8.9267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7649 loss: tensor(8.9027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7650 loss: tensor(8.8654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7651 loss: tensor(8.8233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7652 loss: tensor(8.7849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7653 loss: tensor(8.7563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7654 loss: tensor(8.7407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7655 loss: tensor(8.7377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7656 loss: tensor(8.7444e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7657 loss: tensor(8.7559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7658 loss: tensor(8.7678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7659 loss: tensor(8.7765e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7660 loss: tensor(8.7803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7661 loss: tensor(8.7784e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7662 loss: tensor(8.7718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7663 loss: tensor(8.7624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7664 loss: tensor(8.7525e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7665 loss: tensor(8.7433e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7666 loss: tensor(8.7367e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7667 loss: tensor(8.7330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7668 loss: tensor(8.7321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7669 loss: tensor(8.7336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7670 loss: tensor(8.7368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7671 loss: tensor(8.7410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7672 loss: tensor(8.7455e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7673 loss: tensor(8.7499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7674 loss: tensor(8.7543e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7675 loss: tensor(8.7588e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7676 loss: tensor(8.7638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7677 loss: tensor(8.7701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7678 loss: tensor(8.7783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7679 loss: tensor(8.7900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7680 loss: tensor(8.8065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7681 loss: tensor(8.8300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7682 loss: tensor(8.8633e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7683 loss: tensor(8.9100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7684 loss: tensor(8.9738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7685 loss: tensor(9.0595e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7686 loss: tensor(9.1704e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7687 loss: tensor(9.3077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7688 loss: tensor(9.4676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7689 loss: tensor(9.6347e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7690 loss: tensor(9.7776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7691 loss: tensor(9.8519e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7692 loss: tensor(9.8142e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7693 loss: tensor(9.6458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7694 loss: tensor(9.3770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7695 loss: tensor(9.0883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7696 loss: tensor(8.8712e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7697 loss: tensor(8.7827e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7698 loss: tensor(8.8208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7699 loss: tensor(8.9351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7700 loss: tensor(9.0561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7701 loss: tensor(9.1245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7702 loss: tensor(9.1110e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7703 loss: tensor(9.0250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7704 loss: tensor(8.9068e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7705 loss: tensor(8.8048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7706 loss: tensor(8.7534e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7707 loss: tensor(8.7587e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7708 loss: tensor(8.8012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7709 loss: tensor(8.8500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7710 loss: tensor(8.8771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7711 loss: tensor(8.8705e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7712 loss: tensor(8.8351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7713 loss: tensor(8.7876e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7714 loss: tensor(8.7478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7715 loss: tensor(8.7283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7716 loss: tensor(8.7311e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7717 loss: tensor(8.7484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7718 loss: tensor(8.7685e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7719 loss: tensor(8.7813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7720 loss: tensor(8.7816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7721 loss: tensor(8.7707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7722 loss: tensor(8.7545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7723 loss: tensor(8.7397e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7724 loss: tensor(8.7317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7725 loss: tensor(8.7324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7726 loss: tensor(8.7405e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7727 loss: tensor(8.7525e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7728 loss: tensor(8.7648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7729 loss: tensor(8.7753e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7730 loss: tensor(8.7835e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7731 loss: tensor(8.7913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7732 loss: tensor(8.8016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7733 loss: tensor(8.8182e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7734 loss: tensor(8.8445e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7735 loss: tensor(8.8825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7736 loss: tensor(8.9337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7737 loss: tensor(8.9987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7738 loss: tensor(9.0770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7739 loss: tensor(9.1672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7740 loss: tensor(9.2646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7741 loss: tensor(9.3585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7742 loss: tensor(9.4332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7743 loss: tensor(9.4686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7744 loss: tensor(9.4456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7745 loss: tensor(9.3561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7746 loss: tensor(9.2095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7747 loss: tensor(9.0368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7748 loss: tensor(8.8786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7749 loss: tensor(8.7695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7750 loss: tensor(8.7256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7751 loss: tensor(8.7404e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7752 loss: tensor(8.7918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7753 loss: tensor(8.8520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7754 loss: tensor(8.8966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7755 loss: tensor(8.9112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7756 loss: tensor(8.8932e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7757 loss: tensor(8.8515e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7758 loss: tensor(8.8008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7759 loss: tensor(8.7564e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7760 loss: tensor(8.7293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7761 loss: tensor(8.7225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7762 loss: tensor(8.7317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7763 loss: tensor(8.7487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7764 loss: tensor(8.7649e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7765 loss: tensor(8.7737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7766 loss: tensor(8.7724e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7767 loss: tensor(8.7619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7768 loss: tensor(8.7457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7769 loss: tensor(8.7289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7770 loss: tensor(8.7153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7771 loss: tensor(8.7079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7772 loss: tensor(8.7069e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7773 loss: tensor(8.7109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7774 loss: tensor(8.7174e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7775 loss: tensor(8.7239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7776 loss: tensor(8.7283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7777 loss: tensor(8.7295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7778 loss: tensor(8.7275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7779 loss: tensor(8.7230e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7780 loss: tensor(8.7170e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7781 loss: tensor(8.7108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7782 loss: tensor(8.7053e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7783 loss: tensor(8.7013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7784 loss: tensor(8.6992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7785 loss: tensor(8.6985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7786 loss: tensor(8.6991e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7787 loss: tensor(8.7002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7788 loss: tensor(8.7017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7789 loss: tensor(8.7030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7790 loss: tensor(8.7036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7791 loss: tensor(8.7037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7792 loss: tensor(8.7032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7793 loss: tensor(8.7023e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7794 loss: tensor(8.7010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7795 loss: tensor(8.6997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7796 loss: tensor(8.6985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7797 loss: tensor(8.6975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7798 loss: tensor(8.6966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7799 loss: tensor(8.6959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7800 loss: tensor(8.6955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7801 loss: tensor(8.6954e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7802 loss: tensor(8.6953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7803 loss: tensor(8.6957e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7804 loss: tensor(8.6962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7805 loss: tensor(8.6969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7806 loss: tensor(8.6979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7807 loss: tensor(8.6993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7808 loss: tensor(8.7011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7809 loss: tensor(8.7036e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7810 loss: tensor(8.7071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7811 loss: tensor(8.7118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7812 loss: tensor(8.7186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7813 loss: tensor(8.7281e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7814 loss: tensor(8.7415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7815 loss: tensor(8.7603e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7816 loss: tensor(8.7870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7817 loss: tensor(8.8247e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7818 loss: tensor(8.8775e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7819 loss: tensor(8.9510e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7820 loss: tensor(9.0522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7821 loss: tensor(9.1884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7822 loss: tensor(9.3650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7823 loss: tensor(9.5817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7824 loss: tensor(9.8217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7825 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7826 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7827 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7828 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7829 loss: tensor(9.7044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7830 loss: tensor(9.3697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7831 loss: tensor(9.1452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7832 loss: tensor(9.0969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7833 loss: tensor(9.1949e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7834 loss: tensor(9.3417e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7835 loss: tensor(9.4276e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7836 loss: tensor(9.3815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7837 loss: tensor(9.2045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7838 loss: tensor(8.9686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7839 loss: tensor(8.7737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7840 loss: tensor(8.6890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7841 loss: tensor(8.7192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7842 loss: tensor(8.8143e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7843 loss: tensor(8.9055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7844 loss: tensor(8.9437e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7845 loss: tensor(8.9189e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7846 loss: tensor(8.8563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7847 loss: tensor(8.7955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7848 loss: tensor(8.7654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7849 loss: tensor(8.7703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7850 loss: tensor(8.7929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7851 loss: tensor(8.8082e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7852 loss: tensor(8.7999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7853 loss: tensor(8.7677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7854 loss: tensor(8.7260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7855 loss: tensor(8.6926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7856 loss: tensor(8.6795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7857 loss: tensor(8.6874e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7858 loss: tensor(8.7079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7859 loss: tensor(8.7277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7860 loss: tensor(8.7377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7861 loss: tensor(8.7348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7862 loss: tensor(8.7236e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7863 loss: tensor(8.7104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7864 loss: tensor(8.7017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7865 loss: tensor(8.6996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7866 loss: tensor(8.7025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7867 loss: tensor(8.7064e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7868 loss: tensor(8.7079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7869 loss: tensor(8.7049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7870 loss: tensor(8.6980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7871 loss: tensor(8.6895e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7872 loss: tensor(8.6820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7873 loss: tensor(8.6774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7874 loss: tensor(8.6761e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7875 loss: tensor(8.6772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7876 loss: tensor(8.6792e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7877 loss: tensor(8.6803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7878 loss: tensor(8.6803e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7879 loss: tensor(8.6788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7880 loss: tensor(8.6766e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7881 loss: tensor(8.6747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7882 loss: tensor(8.6732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7883 loss: tensor(8.6728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7884 loss: tensor(8.6734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7885 loss: tensor(8.6745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7886 loss: tensor(8.6756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7887 loss: tensor(8.6765e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7888 loss: tensor(8.6771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7889 loss: tensor(8.6772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7890 loss: tensor(8.6774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7891 loss: tensor(8.6779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7892 loss: tensor(8.6787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7893 loss: tensor(8.6805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7894 loss: tensor(8.6831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7895 loss: tensor(8.6871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7896 loss: tensor(8.6924e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7897 loss: tensor(8.6996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7898 loss: tensor(8.7093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7899 loss: tensor(8.7222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7900 loss: tensor(8.7395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7901 loss: tensor(8.7630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7902 loss: tensor(8.7945e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7903 loss: tensor(8.8368e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7904 loss: tensor(8.8933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7905 loss: tensor(8.9674e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7906 loss: tensor(9.0615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7907 loss: tensor(9.1757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7908 loss: tensor(9.3056e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7909 loss: tensor(9.4390e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7910 loss: tensor(9.5522e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7911 loss: tensor(9.6118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7912 loss: tensor(9.5852e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7913 loss: tensor(9.4570e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7914 loss: tensor(9.2447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7915 loss: tensor(9.0027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7916 loss: tensor(8.7999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7917 loss: tensor(8.6882e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7918 loss: tensor(8.6793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7919 loss: tensor(8.7477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7920 loss: tensor(8.8460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7921 loss: tensor(8.9262e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7922 loss: tensor(8.9550e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7923 loss: tensor(8.9241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7924 loss: tensor(8.8489e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7925 loss: tensor(8.7617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7926 loss: tensor(8.6948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7927 loss: tensor(8.6671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7928 loss: tensor(8.6785e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7929 loss: tensor(8.7140e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7930 loss: tensor(8.7526e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7931 loss: tensor(8.7764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7932 loss: tensor(8.7761e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7933 loss: tensor(8.7540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7934 loss: tensor(8.7202e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7935 loss: tensor(8.6875e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7936 loss: tensor(8.6662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7937 loss: tensor(8.6601e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7938 loss: tensor(8.6671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7939 loss: tensor(8.6805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7940 loss: tensor(8.6930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7941 loss: tensor(8.6994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7942 loss: tensor(8.6977e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7943 loss: tensor(8.6894e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7944 loss: tensor(8.6777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7945 loss: tensor(8.6665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7946 loss: tensor(8.6586e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7947 loss: tensor(8.6554e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7948 loss: tensor(8.6566e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7949 loss: tensor(8.6604e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7950 loss: tensor(8.6649e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7951 loss: tensor(8.6684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7952 loss: tensor(8.6697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7953 loss: tensor(8.6687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7954 loss: tensor(8.6659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7955 loss: tensor(8.6624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7956 loss: tensor(8.6589e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7957 loss: tensor(8.6564e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7958 loss: tensor(8.6556e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7959 loss: tensor(8.6560e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7960 loss: tensor(8.6577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7961 loss: tensor(8.6601e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7962 loss: tensor(8.6629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7963 loss: tensor(8.6660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7964 loss: tensor(8.6694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7965 loss: tensor(8.6735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7966 loss: tensor(8.6789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7967 loss: tensor(8.6861e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7968 loss: tensor(8.6968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7969 loss: tensor(8.7124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7970 loss: tensor(8.7347e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7971 loss: tensor(8.7670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7972 loss: tensor(8.8131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7973 loss: tensor(8.8780e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7974 loss: tensor(8.9669e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7975 loss: tensor(9.0860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7976 loss: tensor(9.2401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7977 loss: tensor(9.4282e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7978 loss: tensor(9.6364e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7979 loss: tensor(9.8318e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7980 loss: tensor(9.9571e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7981 loss: tensor(9.9465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7982 loss: tensor(9.7619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7983 loss: tensor(9.4323e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7984 loss: tensor(9.0618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7985 loss: tensor(8.7815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7986 loss: tensor(8.6747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7987 loss: tensor(8.7372e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7988 loss: tensor(8.8921e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7989 loss: tensor(9.0386e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7990 loss: tensor(9.0966e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7991 loss: tensor(9.0388e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7992 loss: tensor(8.8989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7993 loss: tensor(8.7491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7994 loss: tensor(8.6569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7995 loss: tensor(8.6502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7996 loss: tensor(8.7092e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7997 loss: tensor(8.7855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7998 loss: tensor(8.8319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 7999 loss: tensor(8.8258e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8000 loss: tensor(8.7757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8001 loss: tensor(8.7106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8002 loss: tensor(8.6630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8003 loss: tensor(8.6499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8004 loss: tensor(8.6684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8005 loss: tensor(8.7008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8006 loss: tensor(8.7258e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8007 loss: tensor(8.7303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8008 loss: tensor(8.7137e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8009 loss: tensor(8.6864e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8010 loss: tensor(8.6618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8011 loss: tensor(8.6500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8012 loss: tensor(8.6530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8013 loss: tensor(8.6656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8014 loss: tensor(8.6793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8015 loss: tensor(8.6870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8016 loss: tensor(8.6862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8017 loss: tensor(8.6790e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8018 loss: tensor(8.6699e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8019 loss: tensor(8.6637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8020 loss: tensor(8.6638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8021 loss: tensor(8.6704e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8022 loss: tensor(8.6818e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8023 loss: tensor(8.6956e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8024 loss: tensor(8.7095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8025 loss: tensor(8.7232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8026 loss: tensor(8.7379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8027 loss: tensor(8.7562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8028 loss: tensor(8.7809e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8029 loss: tensor(8.8149e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8030 loss: tensor(8.8598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8031 loss: tensor(8.9159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8032 loss: tensor(8.9819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8033 loss: tensor(9.0548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8034 loss: tensor(9.1293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8035 loss: tensor(9.1968e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8036 loss: tensor(9.2448e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8037 loss: tensor(9.2600e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8038 loss: tensor(9.2312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8039 loss: tensor(9.1546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8040 loss: tensor(9.0391e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8041 loss: tensor(8.9058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8042 loss: tensor(8.7815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8043 loss: tensor(8.6902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8044 loss: tensor(8.6438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8045 loss: tensor(8.6410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8046 loss: tensor(8.6702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8047 loss: tensor(8.7146e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8048 loss: tensor(8.7572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8049 loss: tensor(8.7860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8050 loss: tensor(8.7936e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8051 loss: tensor(8.7801e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8052 loss: tensor(8.7503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8053 loss: tensor(8.7135e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8054 loss: tensor(8.6786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8055 loss: tensor(8.6520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8056 loss: tensor(8.6377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8057 loss: tensor(8.6349e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8058 loss: tensor(8.6410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8059 loss: tensor(8.6516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8060 loss: tensor(8.6623e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8061 loss: tensor(8.6696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8062 loss: tensor(8.6719e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8063 loss: tensor(8.6692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8064 loss: tensor(8.6626e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8065 loss: tensor(8.6541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8066 loss: tensor(8.6453e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8067 loss: tensor(8.6379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8068 loss: tensor(8.6327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8069 loss: tensor(8.6298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8070 loss: tensor(8.6289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8071 loss: tensor(8.6294e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8072 loss: tensor(8.6307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8073 loss: tensor(8.6319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8074 loss: tensor(8.6328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8075 loss: tensor(8.6332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8076 loss: tensor(8.6328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8077 loss: tensor(8.6319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8078 loss: tensor(8.6305e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8079 loss: tensor(8.6288e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8080 loss: tensor(8.6272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8081 loss: tensor(8.6257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8082 loss: tensor(8.6244e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8083 loss: tensor(8.6235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8084 loss: tensor(8.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8085 loss: tensor(8.6226e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8086 loss: tensor(8.6223e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8087 loss: tensor(8.6224e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8088 loss: tensor(8.6223e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8089 loss: tensor(8.6225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8090 loss: tensor(8.6227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8091 loss: tensor(8.6228e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8092 loss: tensor(8.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8093 loss: tensor(8.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8094 loss: tensor(8.6229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8095 loss: tensor(8.6230e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8096 loss: tensor(8.6231e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8097 loss: tensor(8.6230e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8098 loss: tensor(8.6232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8099 loss: tensor(8.6236e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8100 loss: tensor(8.6241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8101 loss: tensor(8.6248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8102 loss: tensor(8.6259e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8103 loss: tensor(8.6273e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8104 loss: tensor(8.6294e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8105 loss: tensor(8.6321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8106 loss: tensor(8.6359e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8107 loss: tensor(8.6410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8108 loss: tensor(8.6477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8109 loss: tensor(8.6569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8110 loss: tensor(8.6695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8111 loss: tensor(8.6863e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8112 loss: tensor(8.7092e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8113 loss: tensor(8.7405e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8114 loss: tensor(8.7825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8115 loss: tensor(8.8385e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8116 loss: tensor(8.9121e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8117 loss: tensor(9.0065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8118 loss: tensor(9.1235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8119 loss: tensor(9.2619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8120 loss: tensor(9.4125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8121 loss: tensor(9.5579e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8122 loss: tensor(9.6716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8123 loss: tensor(9.7256e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8124 loss: tensor(9.7027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8125 loss: tensor(9.6122e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8126 loss: tensor(9.4995e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8127 loss: tensor(9.4266e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8128 loss: tensor(9.4399e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8129 loss: tensor(9.5417e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8130 loss: tensor(9.6813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8131 loss: tensor(9.7732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8132 loss: tensor(9.7383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8133 loss: tensor(9.5476e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8134 loss: tensor(9.2461e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8135 loss: tensor(8.9356e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8136 loss: tensor(8.7210e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8137 loss: tensor(8.6569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8138 loss: tensor(8.7284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8139 loss: tensor(8.8679e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8140 loss: tensor(8.9928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8141 loss: tensor(9.0384e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8142 loss: tensor(8.9852e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8143 loss: tensor(8.8629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8144 loss: tensor(8.7298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8145 loss: tensor(8.6412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8146 loss: tensor(8.6222e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8147 loss: tensor(8.6607e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8148 loss: tensor(8.7220e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8149 loss: tensor(8.7681e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8150 loss: tensor(8.7758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8151 loss: tensor(8.7438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8152 loss: tensor(8.6901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8153 loss: tensor(8.6402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8154 loss: tensor(8.6126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8155 loss: tensor(8.6124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8156 loss: tensor(8.6316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8157 loss: tensor(8.6556e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8158 loss: tensor(8.6713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8159 loss: tensor(8.6713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8160 loss: tensor(8.6568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8161 loss: tensor(8.6353e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8162 loss: tensor(8.6156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8163 loss: tensor(8.6044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8164 loss: tensor(8.6039e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8165 loss: tensor(8.6109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8166 loss: tensor(8.6203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8167 loss: tensor(8.6274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8168 loss: tensor(8.6285e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8169 loss: tensor(8.6237e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8170 loss: tensor(8.6153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8171 loss: tensor(8.6065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8172 loss: tensor(8.6000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8173 loss: tensor(8.5973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8174 loss: tensor(8.5980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8175 loss: tensor(8.6011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8176 loss: tensor(8.6046e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8177 loss: tensor(8.6070e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8178 loss: tensor(8.6074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8179 loss: tensor(8.6057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8180 loss: tensor(8.6026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8181 loss: tensor(8.5991e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8182 loss: tensor(8.5961e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8183 loss: tensor(8.5943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8184 loss: tensor(8.5936e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8185 loss: tensor(8.5939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8186 loss: tensor(8.5948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8187 loss: tensor(8.5958e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8188 loss: tensor(8.5964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8189 loss: tensor(8.5967e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8190 loss: tensor(8.5962e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8191 loss: tensor(8.5953e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8192 loss: tensor(8.5941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8193 loss: tensor(8.5928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8194 loss: tensor(8.5917e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8195 loss: tensor(8.5909e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8196 loss: tensor(8.5904e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8197 loss: tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8198 loss: tensor(8.5901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8199 loss: tensor(8.5901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8200 loss: tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8201 loss: tensor(8.5900e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8202 loss: tensor(8.5899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8203 loss: tensor(8.5897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8204 loss: tensor(8.5892e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8205 loss: tensor(8.5889e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8206 loss: tensor(8.5884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8207 loss: tensor(8.5880e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8208 loss: tensor(8.5876e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8209 loss: tensor(8.5871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8210 loss: tensor(8.5869e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8211 loss: tensor(8.5866e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8212 loss: tensor(8.5862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8213 loss: tensor(8.5860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8214 loss: tensor(8.5858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8215 loss: tensor(8.5855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8216 loss: tensor(8.5853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8217 loss: tensor(8.5851e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8218 loss: tensor(8.5849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8219 loss: tensor(8.5847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8220 loss: tensor(8.5845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8221 loss: tensor(8.5844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8222 loss: tensor(8.5843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8223 loss: tensor(8.5840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8224 loss: tensor(8.5838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8225 loss: tensor(8.5837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8226 loss: tensor(8.5837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8227 loss: tensor(8.5837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8228 loss: tensor(8.5838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8229 loss: tensor(8.5841e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8230 loss: tensor(8.5845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8231 loss: tensor(8.5852e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8232 loss: tensor(8.5862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8233 loss: tensor(8.5875e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8234 loss: tensor(8.5897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8235 loss: tensor(8.5928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8236 loss: tensor(8.5976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8237 loss: tensor(8.6049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8238 loss: tensor(8.6157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8239 loss: tensor(8.6322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8240 loss: tensor(8.6573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8241 loss: tensor(8.6954e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8242 loss: tensor(8.7531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8243 loss: tensor(8.8407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8244 loss: tensor(8.9730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8245 loss: tensor(9.1684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8246 loss: tensor(9.4481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8247 loss: tensor(9.8285e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8248 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8249 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8250 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8251 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8252 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8253 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8254 loss: tensor(9.6032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8255 loss: tensor(9.2082e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8256 loss: tensor(9.1985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8257 loss: tensor(9.4016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8258 loss: tensor(9.5396e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8259 loss: tensor(9.4251e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8260 loss: tensor(9.0952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8261 loss: tensor(8.7816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8262 loss: tensor(8.7031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8263 loss: tensor(8.8762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8264 loss: tensor(9.1193e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8265 loss: tensor(9.2159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8266 loss: tensor(9.0832e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8267 loss: tensor(8.8232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8268 loss: tensor(8.6232e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8269 loss: tensor(8.5940e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8270 loss: tensor(8.6985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8271 loss: tensor(8.8109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8272 loss: tensor(8.8328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8273 loss: tensor(8.7630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8274 loss: tensor(8.6748e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8275 loss: tensor(8.6391e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8276 loss: tensor(8.6638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8277 loss: tensor(8.7018e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8278 loss: tensor(8.7026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8279 loss: tensor(8.6574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8280 loss: tensor(8.6008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8281 loss: tensor(8.5745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8282 loss: tensor(8.5918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8283 loss: tensor(8.6304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8284 loss: tensor(8.6552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8285 loss: tensor(8.6482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8286 loss: tensor(8.6179e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8287 loss: tensor(8.5879e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8288 loss: tensor(8.5764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8289 loss: tensor(8.5832e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8290 loss: tensor(8.5948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8291 loss: tensor(8.5977e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8292 loss: tensor(8.5896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8293 loss: tensor(8.5779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8294 loss: tensor(8.5717e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8295 loss: tensor(8.5747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8296 loss: tensor(8.5826e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8297 loss: tensor(8.5881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8298 loss: tensor(8.5865e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8299 loss: tensor(8.5788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8300 loss: tensor(8.5701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8301 loss: tensor(8.5651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8302 loss: tensor(8.5653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8303 loss: tensor(8.5683e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8304 loss: tensor(8.5707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8305 loss: tensor(8.5703e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8306 loss: tensor(8.5676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8307 loss: tensor(8.5646e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8308 loss: tensor(8.5634e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8309 loss: tensor(8.5643e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8310 loss: tensor(8.5662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8311 loss: tensor(8.5675e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8312 loss: tensor(8.5672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8313 loss: tensor(8.5653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8314 loss: tensor(8.5630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8315 loss: tensor(8.5615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8316 loss: tensor(8.5610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8317 loss: tensor(8.5612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8318 loss: tensor(8.5615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8319 loss: tensor(8.5612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8320 loss: tensor(8.5604e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8321 loss: tensor(8.5592e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8322 loss: tensor(8.5582e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8323 loss: tensor(8.5576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8324 loss: tensor(8.5575e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8325 loss: tensor(8.5576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8326 loss: tensor(8.5577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8327 loss: tensor(8.5576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8328 loss: tensor(8.5573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8329 loss: tensor(8.5568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8330 loss: tensor(8.5565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8331 loss: tensor(8.5563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8332 loss: tensor(8.5562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8333 loss: tensor(8.5563e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8334 loss: tensor(8.5565e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8335 loss: tensor(8.5566e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8336 loss: tensor(8.5567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8337 loss: tensor(8.5568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8338 loss: tensor(8.5569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8339 loss: tensor(8.5572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8340 loss: tensor(8.5577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8341 loss: tensor(8.5587e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8342 loss: tensor(8.5599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8343 loss: tensor(8.5615e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8344 loss: tensor(8.5634e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8345 loss: tensor(8.5660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8346 loss: tensor(8.5695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8347 loss: tensor(8.5742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8348 loss: tensor(8.5807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8349 loss: tensor(8.5898e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8350 loss: tensor(8.6019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8351 loss: tensor(8.6184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8352 loss: tensor(8.6408e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8353 loss: tensor(8.6711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8354 loss: tensor(8.7123e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8355 loss: tensor(8.7679e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8356 loss: tensor(8.8410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8357 loss: tensor(8.9350e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8358 loss: tensor(9.0509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8359 loss: tensor(9.1860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8360 loss: tensor(9.3284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8361 loss: tensor(9.4541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8362 loss: tensor(9.5278e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8363 loss: tensor(9.5119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8364 loss: tensor(9.3856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8365 loss: tensor(9.1639e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8366 loss: tensor(8.9044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8367 loss: tensor(8.6843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8368 loss: tensor(8.5630e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8369 loss: tensor(8.5562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8370 loss: tensor(8.6354e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8371 loss: tensor(8.7466e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8372 loss: tensor(8.8348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8373 loss: tensor(8.8629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8374 loss: tensor(8.8233e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8375 loss: tensor(8.7361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8376 loss: tensor(8.6388e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8377 loss: tensor(8.5684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8378 loss: tensor(8.5441e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8379 loss: tensor(8.5628e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8380 loss: tensor(8.6049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8381 loss: tensor(8.6452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8382 loss: tensor(8.6648e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8383 loss: tensor(8.6567e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8384 loss: tensor(8.6269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8385 loss: tensor(8.5888e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8386 loss: tensor(8.5576e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8387 loss: tensor(8.5426e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8388 loss: tensor(8.5449e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8389 loss: tensor(8.5591e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8390 loss: tensor(8.5760e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8391 loss: tensor(8.5871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8392 loss: tensor(8.5888e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8393 loss: tensor(8.5808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8394 loss: tensor(8.5671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8395 loss: tensor(8.5530e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8396 loss: tensor(8.5428e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8397 loss: tensor(8.5387e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8398 loss: tensor(8.5402e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8399 loss: tensor(8.5453e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8400 loss: tensor(8.5512e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8401 loss: tensor(8.5552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8402 loss: tensor(8.5561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8403 loss: tensor(8.5537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8404 loss: tensor(8.5493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8405 loss: tensor(8.5442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8406 loss: tensor(8.5398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8407 loss: tensor(8.5370e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8408 loss: tensor(8.5360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8409 loss: tensor(8.5366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8410 loss: tensor(8.5381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8411 loss: tensor(8.5398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8412 loss: tensor(8.5409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8413 loss: tensor(8.5412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8414 loss: tensor(8.5405e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8415 loss: tensor(8.5391e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8416 loss: tensor(8.5374e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8417 loss: tensor(8.5357e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8418 loss: tensor(8.5342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8419 loss: tensor(8.5333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8420 loss: tensor(8.5327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8421 loss: tensor(8.5326e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8422 loss: tensor(8.5328e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8423 loss: tensor(8.5330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8424 loss: tensor(8.5331e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8425 loss: tensor(8.5332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8426 loss: tensor(8.5331e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8427 loss: tensor(8.5328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8428 loss: tensor(8.5324e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8429 loss: tensor(8.5320e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8430 loss: tensor(8.5315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8431 loss: tensor(8.5310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8432 loss: tensor(8.5306e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8433 loss: tensor(8.5302e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8434 loss: tensor(8.5299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8435 loss: tensor(8.5300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8436 loss: tensor(8.5301e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8437 loss: tensor(8.5304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8438 loss: tensor(8.5310e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8439 loss: tensor(8.5320e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8440 loss: tensor(8.5335e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8441 loss: tensor(8.5355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8442 loss: tensor(8.5389e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8443 loss: tensor(8.5438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8444 loss: tensor(8.5511e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8445 loss: tensor(8.5617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8446 loss: tensor(8.5772e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8447 loss: tensor(8.6000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8448 loss: tensor(8.6337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8449 loss: tensor(8.6833e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8450 loss: tensor(8.7560e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8451 loss: tensor(8.8612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8452 loss: tensor(9.0107e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8453 loss: tensor(9.2156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8454 loss: tensor(9.4798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8455 loss: tensor(9.7873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8456 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8457 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8458 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8459 loss: tensor(9.8770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8460 loss: tensor(9.3342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8461 loss: tensor(8.8157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8462 loss: tensor(8.5434e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8463 loss: tensor(8.5850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8464 loss: tensor(8.8322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8465 loss: tensor(9.0890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8466 loss: tensor(9.1856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8467 loss: tensor(9.0676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8468 loss: tensor(8.8195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8469 loss: tensor(8.6011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8470 loss: tensor(8.5308e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8471 loss: tensor(8.6114e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8472 loss: tensor(8.7508e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8473 loss: tensor(8.8377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8474 loss: tensor(8.8163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8475 loss: tensor(8.7133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8476 loss: tensor(8.6070e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8477 loss: tensor(8.5665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8478 loss: tensor(8.6072e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8479 loss: tensor(8.6907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8480 loss: tensor(8.7616e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8481 loss: tensor(8.7881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8482 loss: tensor(8.7795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8483 loss: tensor(8.7733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8484 loss: tensor(8.8062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8485 loss: tensor(8.8907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8486 loss: tensor(9.0109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8487 loss: tensor(9.1355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8488 loss: tensor(9.2347e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8489 loss: tensor(9.2905e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8490 loss: tensor(9.2960e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8491 loss: tensor(9.2499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8492 loss: tensor(9.1525e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8493 loss: tensor(9.0108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8494 loss: tensor(8.8454e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8495 loss: tensor(8.6889e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8496 loss: tensor(8.5753e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8497 loss: tensor(8.5261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8498 loss: tensor(8.5412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8499 loss: tensor(8.6010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8500 loss: tensor(8.6745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8501 loss: tensor(8.7305e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8502 loss: tensor(8.7484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8503 loss: tensor(8.7235e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8504 loss: tensor(8.6673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8505 loss: tensor(8.6013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8506 loss: tensor(8.5469e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8507 loss: tensor(8.5178e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8508 loss: tensor(8.5156e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8509 loss: tensor(8.5329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8510 loss: tensor(8.5580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8511 loss: tensor(8.5795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8512 loss: tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8513 loss: tensor(8.5879e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8514 loss: tensor(8.5754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8515 loss: tensor(8.5569e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8516 loss: tensor(8.5381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8517 loss: tensor(8.5229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8518 loss: tensor(8.5138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8519 loss: tensor(8.5112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8520 loss: tensor(8.5139e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8521 loss: tensor(8.5199e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8522 loss: tensor(8.5267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8523 loss: tensor(8.5319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8524 loss: tensor(8.5341e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8525 loss: tensor(8.5327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8526 loss: tensor(8.5280e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8527 loss: tensor(8.5216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8528 loss: tensor(8.5150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8529 loss: tensor(8.5095e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8530 loss: tensor(8.5059e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8531 loss: tensor(8.5046e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8532 loss: tensor(8.5049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8533 loss: tensor(8.5068e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8534 loss: tensor(8.5088e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8535 loss: tensor(8.5109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8536 loss: tensor(8.5120e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8537 loss: tensor(8.5125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8538 loss: tensor(8.5121e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8539 loss: tensor(8.5111e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8540 loss: tensor(8.5097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8541 loss: tensor(8.5079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8542 loss: tensor(8.5060e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8543 loss: tensor(8.5043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8544 loss: tensor(8.5029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8545 loss: tensor(8.5018e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8546 loss: tensor(8.5011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8547 loss: tensor(8.5006e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8548 loss: tensor(8.5004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8549 loss: tensor(8.5004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8550 loss: tensor(8.5004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8551 loss: tensor(8.5006e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8552 loss: tensor(8.5009e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8553 loss: tensor(8.5010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8554 loss: tensor(8.5013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8555 loss: tensor(8.5015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8556 loss: tensor(8.5014e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8557 loss: tensor(8.5014e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8558 loss: tensor(8.5013e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8559 loss: tensor(8.5011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8560 loss: tensor(8.5009e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8561 loss: tensor(8.5007e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8562 loss: tensor(8.5005e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8563 loss: tensor(8.5002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8564 loss: tensor(8.5000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8565 loss: tensor(8.4998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8566 loss: tensor(8.4997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8567 loss: tensor(8.4996e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8568 loss: tensor(8.4997e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8569 loss: tensor(8.5000e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8570 loss: tensor(8.5004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8571 loss: tensor(8.5010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8572 loss: tensor(8.5019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8573 loss: tensor(8.5031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8574 loss: tensor(8.5050e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8575 loss: tensor(8.5074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8576 loss: tensor(8.5106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8577 loss: tensor(8.5151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8578 loss: tensor(8.5211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8579 loss: tensor(8.5291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8580 loss: tensor(8.5399e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8581 loss: tensor(8.5544e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8582 loss: tensor(8.5739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8583 loss: tensor(8.6002e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8584 loss: tensor(8.6355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8585 loss: tensor(8.6823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8586 loss: tensor(8.7434e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8587 loss: tensor(8.8221e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8588 loss: tensor(8.9201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8589 loss: tensor(9.0355e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8590 loss: tensor(9.1611e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8591 loss: tensor(9.2811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8592 loss: tensor(9.3702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8593 loss: tensor(9.3977e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8594 loss: tensor(9.3381e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8595 loss: tensor(9.1883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8596 loss: tensor(8.9776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8597 loss: tensor(8.7625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8598 loss: tensor(8.6026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8599 loss: tensor(8.5333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8600 loss: tensor(8.5541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8601 loss: tensor(8.6335e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8602 loss: tensor(8.7273e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8603 loss: tensor(8.7951e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8604 loss: tensor(8.8124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8605 loss: tensor(8.7757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8606 loss: tensor(8.7034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8607 loss: tensor(8.6243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8608 loss: tensor(8.5662e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8609 loss: tensor(8.5442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8610 loss: tensor(8.5570e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8611 loss: tensor(8.5918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8612 loss: tensor(8.6301e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8613 loss: tensor(8.6562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8614 loss: tensor(8.6621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8615 loss: tensor(8.6493e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8616 loss: tensor(8.6262e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8617 loss: tensor(8.6035e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8618 loss: tensor(8.5908e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8619 loss: tensor(8.5925e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8620 loss: tensor(8.6071e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8621 loss: tensor(8.6295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8622 loss: tensor(8.6526e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8623 loss: tensor(8.6711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8624 loss: tensor(8.6821e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8625 loss: tensor(8.6854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8626 loss: tensor(8.6835e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8627 loss: tensor(8.6800e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8628 loss: tensor(8.6768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8629 loss: tensor(8.6747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8630 loss: tensor(8.6735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8631 loss: tensor(8.6718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8632 loss: tensor(8.6673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8633 loss: tensor(8.6584e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8634 loss: tensor(8.6446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8635 loss: tensor(8.6260e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8636 loss: tensor(8.6039e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8637 loss: tensor(8.5798e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8638 loss: tensor(8.5559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8639 loss: tensor(8.5344e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8640 loss: tensor(8.5161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8641 loss: tensor(8.5020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8642 loss: tensor(8.4919e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8643 loss: tensor(8.4854e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8644 loss: tensor(8.4820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8645 loss: tensor(8.4807e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8646 loss: tensor(8.4805e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8647 loss: tensor(8.4812e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8648 loss: tensor(8.4824e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8649 loss: tensor(8.4838e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8650 loss: tensor(8.4852e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8651 loss: tensor(8.4871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8652 loss: tensor(8.4890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8653 loss: tensor(8.4914e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8654 loss: tensor(8.4941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8655 loss: tensor(8.4974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8656 loss: tensor(8.5016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8657 loss: tensor(8.5066e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8658 loss: tensor(8.5124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8659 loss: tensor(8.5192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8660 loss: tensor(8.5271e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8661 loss: tensor(8.5366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8662 loss: tensor(8.5481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8663 loss: tensor(8.5617e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8664 loss: tensor(8.5779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8665 loss: tensor(8.5970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8666 loss: tensor(8.6197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8667 loss: tensor(8.6464e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8668 loss: tensor(8.6778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8669 loss: tensor(8.7133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8670 loss: tensor(8.7523e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8671 loss: tensor(8.7932e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8672 loss: tensor(8.8340e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8673 loss: tensor(8.8704e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8674 loss: tensor(8.8970e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8675 loss: tensor(8.9078e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8676 loss: tensor(8.8986e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8677 loss: tensor(8.8680e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8678 loss: tensor(8.8175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8679 loss: tensor(8.7531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8680 loss: tensor(8.6837e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8681 loss: tensor(8.6195e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8682 loss: tensor(8.5696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8683 loss: tensor(8.5391e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8684 loss: tensor(8.5291e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8685 loss: tensor(8.5362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8686 loss: tensor(8.5559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8687 loss: tensor(8.5817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8688 loss: tensor(8.6079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8689 loss: tensor(8.6304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8690 loss: tensor(8.6461e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8691 loss: tensor(8.6537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8692 loss: tensor(8.6531e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8693 loss: tensor(8.6455e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8694 loss: tensor(8.6336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8695 loss: tensor(8.6196e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8696 loss: tensor(8.6058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8697 loss: tensor(8.5941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8698 loss: tensor(8.5849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8699 loss: tensor(8.5789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8700 loss: tensor(8.5764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8701 loss: tensor(8.5768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8702 loss: tensor(8.5791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8703 loss: tensor(8.5823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8704 loss: tensor(8.5856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8705 loss: tensor(8.5883e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8706 loss: tensor(8.5899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8707 loss: tensor(8.5897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8708 loss: tensor(8.5884e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8709 loss: tensor(8.5852e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8710 loss: tensor(8.5808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8711 loss: tensor(8.5757e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8712 loss: tensor(8.5698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8713 loss: tensor(8.5636e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8714 loss: tensor(8.5575e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8715 loss: tensor(8.5516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8716 loss: tensor(8.5458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8717 loss: tensor(8.5407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8718 loss: tensor(8.5363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8719 loss: tensor(8.5328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8720 loss: tensor(8.5298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8721 loss: tensor(8.5274e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8722 loss: tensor(8.5255e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8723 loss: tensor(8.5243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8724 loss: tensor(8.5239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8725 loss: tensor(8.5239e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8726 loss: tensor(8.5246e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8727 loss: tensor(8.5261e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8728 loss: tensor(8.5284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8729 loss: tensor(8.5317e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8730 loss: tensor(8.5363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8731 loss: tensor(8.5420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8732 loss: tensor(8.5489e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8733 loss: tensor(8.5572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8734 loss: tensor(8.5671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8735 loss: tensor(8.5788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8736 loss: tensor(8.5924e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8737 loss: tensor(8.6085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8738 loss: tensor(8.6272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8739 loss: tensor(8.6481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8740 loss: tensor(8.6720e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8741 loss: tensor(8.6989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8742 loss: tensor(8.7287e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8743 loss: tensor(8.7607e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8744 loss: tensor(8.7944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8745 loss: tensor(8.8299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8746 loss: tensor(8.8673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8747 loss: tensor(8.9056e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8748 loss: tensor(8.9441e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8749 loss: tensor(8.9816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8750 loss: tensor(9.0159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8751 loss: tensor(9.0425e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8752 loss: tensor(9.0559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8753 loss: tensor(9.0498e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8754 loss: tensor(9.0192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8755 loss: tensor(8.9608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8756 loss: tensor(8.8763e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8757 loss: tensor(8.7748e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8758 loss: tensor(8.6716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8759 loss: tensor(8.5824e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8760 loss: tensor(8.5213e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8761 loss: tensor(8.4943e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8762 loss: tensor(8.4989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8763 loss: tensor(8.5268e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8764 loss: tensor(8.5661e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8765 loss: tensor(8.6049e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8766 loss: tensor(8.6336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8767 loss: tensor(8.6461e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8768 loss: tensor(8.6410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8769 loss: tensor(8.6200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8770 loss: tensor(8.5880e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8771 loss: tensor(8.5516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8772 loss: tensor(8.5168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8773 loss: tensor(8.4881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8774 loss: tensor(8.4684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8775 loss: tensor(8.4581e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8776 loss: tensor(8.4561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8777 loss: tensor(8.4602e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8778 loss: tensor(8.4673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8779 loss: tensor(8.4749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8780 loss: tensor(8.4808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8781 loss: tensor(8.4841e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8782 loss: tensor(8.4842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8783 loss: tensor(8.4815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8784 loss: tensor(8.4765e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8785 loss: tensor(8.4699e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8786 loss: tensor(8.4629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8787 loss: tensor(8.4559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8788 loss: tensor(8.4499e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8789 loss: tensor(8.4452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8790 loss: tensor(8.4420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8791 loss: tensor(8.4401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8792 loss: tensor(8.4395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8793 loss: tensor(8.4397e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8794 loss: tensor(8.4407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8795 loss: tensor(8.4418e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8796 loss: tensor(8.4432e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8797 loss: tensor(8.4445e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8798 loss: tensor(8.4457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8799 loss: tensor(8.4468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8800 loss: tensor(8.4479e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8801 loss: tensor(8.4490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8802 loss: tensor(8.4502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8803 loss: tensor(8.4519e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8804 loss: tensor(8.4541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8805 loss: tensor(8.4574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8806 loss: tensor(8.4618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8807 loss: tensor(8.4681e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8808 loss: tensor(8.4773e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8809 loss: tensor(8.4910e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8810 loss: tensor(8.5109e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8811 loss: tensor(8.5401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8812 loss: tensor(8.5828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8813 loss: tensor(8.6447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8814 loss: tensor(8.7332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8815 loss: tensor(8.8583e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8816 loss: tensor(9.0299e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8817 loss: tensor(9.2546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8818 loss: tensor(9.5265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8819 loss: tensor(9.8124e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8820 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8821 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8822 loss: tensor(9.9419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8823 loss: tensor(9.5451e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8824 loss: tensor(9.0698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8825 loss: tensor(8.7227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8826 loss: tensor(8.6342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8827 loss: tensor(8.7843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8828 loss: tensor(9.0329e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8829 loss: tensor(9.2108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8830 loss: tensor(9.2080e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8831 loss: tensor(9.0284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8832 loss: tensor(8.7817e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8833 loss: tensor(8.6051e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8834 loss: tensor(8.5686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8835 loss: tensor(8.6419e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8836 loss: tensor(8.7328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8837 loss: tensor(8.7557e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8838 loss: tensor(8.6853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8839 loss: tensor(8.5635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8840 loss: tensor(8.4623e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8841 loss: tensor(8.4303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8842 loss: tensor(8.4654e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8843 loss: tensor(8.5252e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8844 loss: tensor(8.5618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8845 loss: tensor(8.5527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8846 loss: tensor(8.5097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8847 loss: tensor(8.4652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8848 loss: tensor(8.4471e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8849 loss: tensor(8.4610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8850 loss: tensor(8.4920e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8851 loss: tensor(8.5170e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8852 loss: tensor(8.5216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8853 loss: tensor(8.5065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8854 loss: tensor(8.4845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8855 loss: tensor(8.4701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8856 loss: tensor(8.4702e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8857 loss: tensor(8.4821e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8858 loss: tensor(8.4961e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8859 loss: tensor(8.5034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8860 loss: tensor(8.5009e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8861 loss: tensor(8.4920e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8862 loss: tensor(8.4839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8863 loss: tensor(8.4818e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8864 loss: tensor(8.4867e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8865 loss: tensor(8.4959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8866 loss: tensor(8.5058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8867 loss: tensor(8.5125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8868 loss: tensor(8.5159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8869 loss: tensor(8.5178e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8870 loss: tensor(8.5212e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8871 loss: tensor(8.5284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8872 loss: tensor(8.5394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8873 loss: tensor(8.5533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8874 loss: tensor(8.5686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8875 loss: tensor(8.5840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8876 loss: tensor(8.5984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8877 loss: tensor(8.6118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8878 loss: tensor(8.6245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8879 loss: tensor(8.6360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8880 loss: tensor(8.6459e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8881 loss: tensor(8.6527e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8882 loss: tensor(8.6548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8883 loss: tensor(8.6513e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8884 loss: tensor(8.6411e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8885 loss: tensor(8.6240e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8886 loss: tensor(8.6010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8887 loss: tensor(8.5738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8888 loss: tensor(8.5450e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8889 loss: tensor(8.5164e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8890 loss: tensor(8.4894e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8891 loss: tensor(8.4657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8892 loss: tensor(8.4460e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8893 loss: tensor(8.4313e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8894 loss: tensor(8.4213e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8895 loss: tensor(8.4158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8896 loss: tensor(8.4141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8897 loss: tensor(8.4152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8898 loss: tensor(8.4184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8899 loss: tensor(8.4229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8900 loss: tensor(8.4281e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8901 loss: tensor(8.4334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8902 loss: tensor(8.4383e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8903 loss: tensor(8.4429e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8904 loss: tensor(8.4472e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8905 loss: tensor(8.4511e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8906 loss: tensor(8.4548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8907 loss: tensor(8.4580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8908 loss: tensor(8.4608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8909 loss: tensor(8.4637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8910 loss: tensor(8.4666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8911 loss: tensor(8.4696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8912 loss: tensor(8.4733e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8913 loss: tensor(8.4774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8914 loss: tensor(8.4818e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8915 loss: tensor(8.4870e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8916 loss: tensor(8.4926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8917 loss: tensor(8.4989e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8918 loss: tensor(8.5063e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8919 loss: tensor(8.5148e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8920 loss: tensor(8.5240e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8921 loss: tensor(8.5339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8922 loss: tensor(8.5446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8923 loss: tensor(8.5559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8924 loss: tensor(8.5677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8925 loss: tensor(8.5794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8926 loss: tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8927 loss: tensor(8.5999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8928 loss: tensor(8.6073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8929 loss: tensor(8.6115e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8930 loss: tensor(8.6126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8931 loss: tensor(8.6096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8932 loss: tensor(8.6020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8933 loss: tensor(8.5901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8934 loss: tensor(8.5743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8935 loss: tensor(8.5553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8936 loss: tensor(8.5348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8937 loss: tensor(8.5134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8938 loss: tensor(8.4921e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8939 loss: tensor(8.4725e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8940 loss: tensor(8.4548e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8941 loss: tensor(8.4398e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8942 loss: tensor(8.4277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8943 loss: tensor(8.4185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8944 loss: tensor(8.4119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8945 loss: tensor(8.4077e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8946 loss: tensor(8.4054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8947 loss: tensor(8.4045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8948 loss: tensor(8.4045e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8949 loss: tensor(8.4050e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8950 loss: tensor(8.4061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8951 loss: tensor(8.4072e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8952 loss: tensor(8.4085e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8953 loss: tensor(8.4097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8954 loss: tensor(8.4112e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8955 loss: tensor(8.4128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8956 loss: tensor(8.4147e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8957 loss: tensor(8.4168e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8958 loss: tensor(8.4191e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8959 loss: tensor(8.4218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8960 loss: tensor(8.4249e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8961 loss: tensor(8.4289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8962 loss: tensor(8.4338e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8963 loss: tensor(8.4401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8964 loss: tensor(8.4478e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8965 loss: tensor(8.4573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8966 loss: tensor(8.4693e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8967 loss: tensor(8.4844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8968 loss: tensor(8.5037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8969 loss: tensor(8.5282e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8970 loss: tensor(8.5590e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8971 loss: tensor(8.5974e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8972 loss: tensor(8.6452e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8973 loss: tensor(8.7032e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8974 loss: tensor(8.7719e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8975 loss: tensor(8.8508e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8976 loss: tensor(8.9378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8977 loss: tensor(9.0300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8978 loss: tensor(9.1210e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8979 loss: tensor(9.2024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8980 loss: tensor(9.2670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8981 loss: tensor(9.3087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8982 loss: tensor(9.3269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8983 loss: tensor(9.3243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8984 loss: tensor(9.3026e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8985 loss: tensor(9.2588e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8986 loss: tensor(9.1858e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8987 loss: tensor(9.0775e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8988 loss: tensor(8.9409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8989 loss: tensor(8.7969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8990 loss: tensor(8.6756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8991 loss: tensor(8.6009e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8992 loss: tensor(8.5792e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8993 loss: tensor(8.5972e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8994 loss: tensor(8.6304e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8995 loss: tensor(8.6550e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8996 loss: tensor(8.6551e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8997 loss: tensor(8.6265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8998 loss: tensor(8.5758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 8999 loss: tensor(8.5181e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9000 loss: tensor(8.4698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9001 loss: tensor(8.4430e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9002 loss: tensor(8.4409e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9003 loss: tensor(8.4577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9004 loss: tensor(8.4820e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9005 loss: tensor(8.5022e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9006 loss: tensor(8.5093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9007 loss: tensor(8.5000e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9008 loss: tensor(8.4771e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9009 loss: tensor(8.4481e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9010 loss: tensor(8.4203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9011 loss: tensor(8.3999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9012 loss: tensor(8.3902e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9013 loss: tensor(8.3911e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9014 loss: tensor(8.3998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9015 loss: tensor(8.4119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9016 loss: tensor(8.4229e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9017 loss: tensor(8.4300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9018 loss: tensor(8.4315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9019 loss: tensor(8.4277e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9020 loss: tensor(8.4198e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9021 loss: tensor(8.4099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9022 loss: tensor(8.3999e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9023 loss: tensor(8.3915e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9024 loss: tensor(8.3860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9025 loss: tensor(8.3834e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9026 loss: tensor(8.3832e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9027 loss: tensor(8.3849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9028 loss: tensor(8.3874e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9029 loss: tensor(8.3899e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9030 loss: tensor(8.3918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9031 loss: tensor(8.3930e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9032 loss: tensor(8.3929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9033 loss: tensor(8.3920e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9034 loss: tensor(8.3906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9035 loss: tensor(8.3891e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9036 loss: tensor(8.3875e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9037 loss: tensor(8.3862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9038 loss: tensor(8.3850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9039 loss: tensor(8.3843e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9040 loss: tensor(8.3840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9041 loss: tensor(8.3839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9042 loss: tensor(8.3840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9043 loss: tensor(8.3842e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9044 loss: tensor(8.3844e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9045 loss: tensor(8.3846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9046 loss: tensor(8.3849e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9047 loss: tensor(8.3850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9048 loss: tensor(8.3853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9049 loss: tensor(8.3857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9050 loss: tensor(8.3862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9051 loss: tensor(8.3869e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9052 loss: tensor(8.3877e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9053 loss: tensor(8.3890e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9054 loss: tensor(8.3907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9055 loss: tensor(8.3929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9056 loss: tensor(8.3959e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9057 loss: tensor(8.4000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9058 loss: tensor(8.4056e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9059 loss: tensor(8.4133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9060 loss: tensor(8.4238e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9061 loss: tensor(8.4377e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9062 loss: tensor(8.4562e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9063 loss: tensor(8.4810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9064 loss: tensor(8.5146e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9065 loss: tensor(8.5591e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9066 loss: tensor(8.6175e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9067 loss: tensor(8.6927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9068 loss: tensor(8.7878e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9069 loss: tensor(8.9037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9070 loss: tensor(9.0362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9071 loss: tensor(9.1742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9072 loss: tensor(9.2967e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9073 loss: tensor(9.3742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9074 loss: tensor(9.3759e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9075 loss: tensor(9.2859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9076 loss: tensor(9.1159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9077 loss: tensor(8.9107e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9078 loss: tensor(8.7321e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9079 loss: tensor(8.6311e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9080 loss: tensor(8.6265e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9081 loss: tensor(8.7012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9082 loss: tensor(8.8134e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9083 loss: tensor(8.9138e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9084 loss: tensor(8.9628e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9085 loss: tensor(8.9403e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9086 loss: tensor(8.8521e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9087 loss: tensor(8.7267e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9088 loss: tensor(8.6020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9089 loss: tensor(8.5087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9090 loss: tensor(8.4593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9091 loss: tensor(8.4494e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9092 loss: tensor(8.4621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9093 loss: tensor(8.4775e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9094 loss: tensor(8.4816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9095 loss: tensor(8.4697e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9096 loss: tensor(8.4468e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9097 loss: tensor(8.4227e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9098 loss: tensor(8.4070e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9099 loss: tensor(8.4047e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9100 loss: tensor(8.4153e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9101 loss: tensor(8.4332e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9102 loss: tensor(8.4506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9103 loss: tensor(8.4610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9104 loss: tensor(8.4612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9105 loss: tensor(8.4514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9106 loss: tensor(8.4348e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9107 loss: tensor(8.4161e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9108 loss: tensor(8.3998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9109 loss: tensor(8.3882e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9110 loss: tensor(8.3822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9111 loss: tensor(8.3806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9112 loss: tensor(8.3815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9113 loss: tensor(8.3825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9114 loss: tensor(8.3819e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9115 loss: tensor(8.3792e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9116 loss: tensor(8.3750e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9117 loss: tensor(8.3700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9118 loss: tensor(8.3652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9119 loss: tensor(8.3616e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9120 loss: tensor(8.3597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9121 loss: tensor(8.3593e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9122 loss: tensor(8.3599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9123 loss: tensor(8.3613e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9124 loss: tensor(8.3629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9125 loss: tensor(8.3642e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9126 loss: tensor(8.3652e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9127 loss: tensor(8.3659e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9128 loss: tensor(8.3664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9129 loss: tensor(8.3666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9130 loss: tensor(8.3671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9131 loss: tensor(8.3682e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9132 loss: tensor(8.3700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9133 loss: tensor(8.3728e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9134 loss: tensor(8.3768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9135 loss: tensor(8.3823e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9136 loss: tensor(8.3896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9137 loss: tensor(8.3994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9138 loss: tensor(8.4126e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9139 loss: tensor(8.4303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9140 loss: tensor(8.4541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9141 loss: tensor(8.4856e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9142 loss: tensor(8.5272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9143 loss: tensor(8.5811e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9144 loss: tensor(8.6501e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9145 loss: tensor(8.7359e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9146 loss: tensor(8.8379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9147 loss: tensor(8.9514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9148 loss: tensor(9.0645e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9149 loss: tensor(9.1573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9150 loss: tensor(9.2028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9151 loss: tensor(9.1760e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9152 loss: tensor(9.0658e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9153 loss: tensor(8.8871e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9154 loss: tensor(8.6816e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9155 loss: tensor(8.5037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9156 loss: tensor(8.3963e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9157 loss: tensor(8.3735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9158 loss: tensor(8.4200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9159 loss: tensor(8.5010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9160 loss: tensor(8.5776e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9161 loss: tensor(8.6200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9162 loss: tensor(8.6142e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9163 loss: tensor(8.5649e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9164 loss: tensor(8.4922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9165 loss: tensor(8.4220e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9166 loss: tensor(8.3748e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9167 loss: tensor(8.3600e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9168 loss: tensor(8.3735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9169 loss: tensor(8.4023e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9170 loss: tensor(8.4312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9171 loss: tensor(8.4484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9172 loss: tensor(8.4489e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9173 loss: tensor(8.4337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9174 loss: tensor(8.4098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9175 loss: tensor(8.3859e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9176 loss: tensor(8.3691e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9177 loss: tensor(8.3631e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9178 loss: tensor(8.3675e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9179 loss: tensor(8.3795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9180 loss: tensor(8.3941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9181 loss: tensor(8.4076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9182 loss: tensor(8.4179e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9183 loss: tensor(8.4246e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9184 loss: tensor(8.4301e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9185 loss: tensor(8.4373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9186 loss: tensor(8.4503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9187 loss: tensor(8.4715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9188 loss: tensor(8.5030e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9189 loss: tensor(8.5465e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9190 loss: tensor(8.6033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9191 loss: tensor(8.6740e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9192 loss: tensor(8.7570e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9193 loss: tensor(8.8491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9194 loss: tensor(8.9430e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9195 loss: tensor(9.0275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9196 loss: tensor(9.0865e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9197 loss: tensor(9.0998e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9198 loss: tensor(9.0517e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9199 loss: tensor(8.9401e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9200 loss: tensor(8.7813e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9201 loss: tensor(8.6087e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9202 loss: tensor(8.4612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9203 loss: tensor(8.3680e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9204 loss: tensor(8.3392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9205 loss: tensor(8.3657e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9206 loss: tensor(8.4241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9207 loss: tensor(8.4888e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9208 loss: tensor(8.5369e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9209 loss: tensor(8.5546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9210 loss: tensor(8.5387e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9211 loss: tensor(8.4964e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9212 loss: tensor(8.4417e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9213 loss: tensor(8.3907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9214 loss: tensor(8.3558e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9215 loss: tensor(8.3421e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9216 loss: tensor(8.3474e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9217 loss: tensor(8.3649e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9218 loss: tensor(8.3855e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9219 loss: tensor(8.4012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9220 loss: tensor(8.4074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9221 loss: tensor(8.4028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9222 loss: tensor(8.3897e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9223 loss: tensor(8.3726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9224 loss: tensor(8.3559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9225 loss: tensor(8.3431e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9226 loss: tensor(8.3361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9227 loss: tensor(8.3351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9228 loss: tensor(8.3386e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9229 loss: tensor(8.3445e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9230 loss: tensor(8.3507e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9231 loss: tensor(8.3553e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9232 loss: tensor(8.3577e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9233 loss: tensor(8.3573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9234 loss: tensor(8.3547e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9235 loss: tensor(8.3505e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9236 loss: tensor(8.3459e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9237 loss: tensor(8.3414e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9238 loss: tensor(8.3379e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9239 loss: tensor(8.3353e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9240 loss: tensor(8.3343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9241 loss: tensor(8.3345e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9242 loss: tensor(8.3356e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9243 loss: tensor(8.3374e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9244 loss: tensor(8.3395e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9245 loss: tensor(8.3417e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9246 loss: tensor(8.3439e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9247 loss: tensor(8.3462e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9248 loss: tensor(8.3488e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9249 loss: tensor(8.3516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9250 loss: tensor(8.3552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9251 loss: tensor(8.3600e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9252 loss: tensor(8.3667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9253 loss: tensor(8.3759e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9254 loss: tensor(8.3886e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9255 loss: tensor(8.4062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9256 loss: tensor(8.4302e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9257 loss: tensor(8.4627e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9258 loss: tensor(8.5065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9259 loss: tensor(8.5644e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9260 loss: tensor(8.6392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9261 loss: tensor(8.7336e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9262 loss: tensor(8.8470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9263 loss: tensor(8.9731e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9264 loss: tensor(9.0983e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9265 loss: tensor(9.1993e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9266 loss: tensor(9.2442e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9267 loss: tensor(9.2043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9268 loss: tensor(9.0691e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9269 loss: tensor(8.8610e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9270 loss: tensor(8.6346e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9271 loss: tensor(8.4538e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9272 loss: tensor(8.3625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9273 loss: tensor(8.3684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9274 loss: tensor(8.4438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9275 loss: tensor(8.5440e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9276 loss: tensor(8.6246e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9277 loss: tensor(8.6559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9278 loss: tensor(8.6307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9279 loss: tensor(8.5638e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9280 loss: tensor(8.4850e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9281 loss: tensor(8.4250e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9282 loss: tensor(8.4028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9283 loss: tensor(8.4194e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9284 loss: tensor(8.4622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9285 loss: tensor(8.5118e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9286 loss: tensor(8.5506e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9287 loss: tensor(8.5690e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9288 loss: tensor(8.5672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9289 loss: tensor(8.5533e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9290 loss: tensor(8.5399e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9291 loss: tensor(8.5361e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9292 loss: tensor(8.5456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9293 loss: tensor(8.5660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9294 loss: tensor(8.5905e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9295 loss: tensor(8.6099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9296 loss: tensor(8.6169e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9297 loss: tensor(8.6075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9298 loss: tensor(8.5825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9299 loss: tensor(8.5457e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9300 loss: tensor(8.5031e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9301 loss: tensor(8.4614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9302 loss: tensor(8.4243e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9303 loss: tensor(8.3948e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9304 loss: tensor(8.3729e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9305 loss: tensor(8.3573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9306 loss: tensor(8.3463e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9307 loss: tensor(8.3385e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9308 loss: tensor(8.3327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9309 loss: tensor(8.3288e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9310 loss: tensor(8.3269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9311 loss: tensor(8.3272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9312 loss: tensor(8.3298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9313 loss: tensor(8.3347e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9314 loss: tensor(8.3410e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9315 loss: tensor(8.3483e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9316 loss: tensor(8.3555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9317 loss: tensor(8.3618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9318 loss: tensor(8.3665e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9319 loss: tensor(8.3696e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9320 loss: tensor(8.3711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9321 loss: tensor(8.3717e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9322 loss: tensor(8.3715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9323 loss: tensor(8.3708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9324 loss: tensor(8.3700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9325 loss: tensor(8.3694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9326 loss: tensor(8.3689e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9327 loss: tensor(8.3686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9328 loss: tensor(8.3682e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9329 loss: tensor(8.3680e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9330 loss: tensor(8.3677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9331 loss: tensor(8.3677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9332 loss: tensor(8.3679e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9333 loss: tensor(8.3686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9334 loss: tensor(8.3694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9335 loss: tensor(8.3707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9336 loss: tensor(8.3727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9337 loss: tensor(8.3754e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9338 loss: tensor(8.3787e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9339 loss: tensor(8.3828e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9340 loss: tensor(8.3877e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9341 loss: tensor(8.3939e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9342 loss: tensor(8.4016e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9343 loss: tensor(8.4104e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9344 loss: tensor(8.4207e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9345 loss: tensor(8.4330e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9346 loss: tensor(8.4470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9347 loss: tensor(8.4624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9348 loss: tensor(8.4791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9349 loss: tensor(8.4973e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9350 loss: tensor(8.5160e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9351 loss: tensor(8.5343e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9352 loss: tensor(8.5516e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9353 loss: tensor(8.5660e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9354 loss: tensor(8.5762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9355 loss: tensor(8.5808e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9356 loss: tensor(8.5796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9357 loss: tensor(8.5723e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9358 loss: tensor(8.5592e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9359 loss: tensor(8.5407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9360 loss: tensor(8.5185e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9361 loss: tensor(8.4952e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9362 loss: tensor(8.4737e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9363 loss: tensor(8.4559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9364 loss: tensor(8.4436e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9365 loss: tensor(8.4376e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9366 loss: tensor(8.4382e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9367 loss: tensor(8.4447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9368 loss: tensor(8.4559e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9369 loss: tensor(8.4710e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9370 loss: tensor(8.4882e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9371 loss: tensor(8.5057e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9372 loss: tensor(8.5218e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9373 loss: tensor(8.5345e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9374 loss: tensor(8.5422e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9375 loss: tensor(8.5438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9376 loss: tensor(8.5382e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9377 loss: tensor(8.5253e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9378 loss: tensor(8.5054e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9379 loss: tensor(8.4795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9380 loss: tensor(8.4497e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9381 loss: tensor(8.4183e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9382 loss: tensor(8.3881e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9383 loss: tensor(8.3612e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9384 loss: tensor(8.3390e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9385 loss: tensor(8.3225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9386 loss: tensor(8.3113e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9387 loss: tensor(8.3052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9388 loss: tensor(8.3034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9389 loss: tensor(8.3047e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9390 loss: tensor(8.3083e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9391 loss: tensor(8.3133e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9392 loss: tensor(8.3190e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9393 loss: tensor(8.3252e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9394 loss: tensor(8.3312e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9395 loss: tensor(8.3373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9396 loss: tensor(8.3432e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9397 loss: tensor(8.3490e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9398 loss: tensor(8.3550e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9399 loss: tensor(8.3614e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9400 loss: tensor(8.3688e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9401 loss: tensor(8.3777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9402 loss: tensor(8.3888e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9403 loss: tensor(8.4028e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9404 loss: tensor(8.4208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9405 loss: tensor(8.4438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9406 loss: tensor(8.4732e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9407 loss: tensor(8.5111e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9408 loss: tensor(8.5597e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9409 loss: tensor(8.6219e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9410 loss: tensor(8.7008e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9411 loss: tensor(8.7969e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9412 loss: tensor(8.9091e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9413 loss: tensor(9.0313e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9414 loss: tensor(9.1502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9415 loss: tensor(9.2438e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9416 loss: tensor(9.2840e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9417 loss: tensor(9.2456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9418 loss: tensor(9.1184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9419 loss: tensor(8.9186e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9420 loss: tensor(8.6916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9421 loss: tensor(8.4947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9422 loss: tensor(8.3722e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9423 loss: tensor(8.3393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9424 loss: tensor(8.3795e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9425 loss: tensor(8.4572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9426 loss: tensor(8.5325e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9427 loss: tensor(8.5735e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9428 loss: tensor(8.5651e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9429 loss: tensor(8.5116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9430 loss: tensor(8.4328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9431 loss: tensor(8.3561e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9432 loss: tensor(8.3040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9433 loss: tensor(8.2862e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9434 loss: tensor(8.2995e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9435 loss: tensor(8.3306e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9436 loss: tensor(8.3625e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9437 loss: tensor(8.3821e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9438 loss: tensor(8.3829e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9439 loss: tensor(8.3664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9440 loss: tensor(8.3400e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9441 loss: tensor(8.3129e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9442 loss: tensor(8.2928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9443 loss: tensor(8.2845e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9444 loss: tensor(8.2873e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9445 loss: tensor(8.2975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9446 loss: tensor(8.3097e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9447 loss: tensor(8.3197e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9448 loss: tensor(8.3245e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9449 loss: tensor(8.3237e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9450 loss: tensor(8.3190e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9451 loss: tensor(8.3125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9452 loss: tensor(8.3073e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9453 loss: tensor(8.3059e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9454 loss: tensor(8.3098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9455 loss: tensor(8.3200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9456 loss: tensor(8.3365e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9457 loss: tensor(8.3598e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9458 loss: tensor(8.3901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9459 loss: tensor(8.4292e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9460 loss: tensor(8.4804e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9461 loss: tensor(8.5480e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9462 loss: tensor(8.6373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9463 loss: tensor(8.7520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9464 loss: tensor(8.8935e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9465 loss: tensor(9.0543e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9466 loss: tensor(9.2142e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9467 loss: tensor(9.3366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9468 loss: tensor(9.3745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9469 loss: tensor(9.2869e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9470 loss: tensor(9.0689e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9471 loss: tensor(8.7727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9472 loss: tensor(8.4927e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9473 loss: tensor(8.3163e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9474 loss: tensor(8.2806e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9475 loss: tensor(8.3608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9476 loss: tensor(8.4926e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9477 loss: tensor(8.6034e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9478 loss: tensor(8.6415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9479 loss: tensor(8.5933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9480 loss: tensor(8.4857e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9481 loss: tensor(8.3692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9482 loss: tensor(8.2915e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9483 loss: tensor(8.2750e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9484 loss: tensor(8.3102e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9485 loss: tensor(8.3667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9486 loss: tensor(8.4106e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9487 loss: tensor(8.4205e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9488 loss: tensor(8.3947e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9489 loss: tensor(8.3479e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9490 loss: tensor(8.3024e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9491 loss: tensor(8.2756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9492 loss: tensor(8.2739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9493 loss: tensor(8.2912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9494 loss: tensor(8.3148e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9495 loss: tensor(8.3314e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9496 loss: tensor(8.3337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9497 loss: tensor(8.3217e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9498 loss: tensor(8.3020e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9499 loss: tensor(8.2831e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9500 loss: tensor(8.2716e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9501 loss: tensor(8.2699e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9502 loss: tensor(8.2758e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9503 loss: tensor(8.2846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9504 loss: tensor(8.2916e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9505 loss: tensor(8.2941e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9506 loss: tensor(8.2912e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9507 loss: tensor(8.2846e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9508 loss: tensor(8.2770e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9509 loss: tensor(8.2708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9510 loss: tensor(8.2676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9511 loss: tensor(8.2676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9512 loss: tensor(8.2698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9513 loss: tensor(8.2726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9514 loss: tensor(8.2749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9515 loss: tensor(8.2759e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9516 loss: tensor(8.2755e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9517 loss: tensor(8.2738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9518 loss: tensor(8.2718e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9519 loss: tensor(8.2699e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9520 loss: tensor(8.2691e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9521 loss: tensor(8.2694e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9522 loss: tensor(8.2711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9523 loss: tensor(8.2741e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9524 loss: tensor(8.2784e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9525 loss: tensor(8.2839e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9526 loss: tensor(8.2913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9527 loss: tensor(8.3012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9528 loss: tensor(8.3152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9529 loss: tensor(8.3351e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9530 loss: tensor(8.3641e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9531 loss: tensor(8.4062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9532 loss: tensor(8.4673e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9533 loss: tensor(8.5549e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9534 loss: tensor(8.6782e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9535 loss: tensor(8.8453e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9536 loss: tensor(9.0599e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9537 loss: tensor(9.3131e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9538 loss: tensor(9.5700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9539 loss: tensor(9.7606e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9540 loss: tensor(9.7936e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9541 loss: tensor(9.5983e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9542 loss: tensor(9.1961e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9543 loss: tensor(8.7262e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9544 loss: tensor(8.3756e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9545 loss: tensor(8.2632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9546 loss: tensor(8.3760e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9547 loss: tensor(8.5948e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9548 loss: tensor(8.7721e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9549 loss: tensor(8.8042e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9550 loss: tensor(8.6794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9551 loss: tensor(8.4768e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9552 loss: tensor(8.3108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9553 loss: tensor(8.2581e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9554 loss: tensor(8.3164e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9555 loss: tensor(8.4216e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9556 loss: tensor(8.4955e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9557 loss: tensor(8.4922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9558 loss: tensor(8.4200e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9559 loss: tensor(8.3271e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9560 loss: tensor(8.2664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9561 loss: tensor(8.2623e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9562 loss: tensor(8.3017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9563 loss: tensor(8.3487e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9564 loss: tensor(8.3700e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9565 loss: tensor(8.3540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9566 loss: tensor(8.3140e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9567 loss: tensor(8.2742e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9568 loss: tensor(8.2546e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9569 loss: tensor(8.2603e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9570 loss: tensor(8.2810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9571 loss: tensor(8.3000e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9572 loss: tensor(8.3052e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9573 loss: tensor(8.2945e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9574 loss: tensor(8.2755e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9575 loss: tensor(8.2588e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9576 loss: tensor(8.2517e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9577 loss: tensor(8.2552e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9578 loss: tensor(8.2644e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9579 loss: tensor(8.2726e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9580 loss: tensor(8.2751e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9581 loss: tensor(8.2709e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9582 loss: tensor(8.2626e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9583 loss: tensor(8.2545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9584 loss: tensor(8.2502e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9585 loss: tensor(8.2503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9586 loss: tensor(8.2534e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9587 loss: tensor(8.2572e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9588 loss: tensor(8.2592e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9589 loss: tensor(8.2583e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9590 loss: tensor(8.2555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9591 loss: tensor(8.2520e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9592 loss: tensor(8.2493e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9593 loss: tensor(8.2484e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9594 loss: tensor(8.2491e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9595 loss: tensor(8.2509e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9596 loss: tensor(8.2526e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9597 loss: tensor(8.2537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9598 loss: tensor(8.2540e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9599 loss: tensor(8.2539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9600 loss: tensor(8.2542e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9601 loss: tensor(8.2555e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9602 loss: tensor(8.2585e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9603 loss: tensor(8.2643e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9604 loss: tensor(8.2730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9605 loss: tensor(8.2866e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9606 loss: tensor(8.3065e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9607 loss: tensor(8.3363e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9608 loss: tensor(8.3810e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9609 loss: tensor(8.4486e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9610 loss: tensor(8.5498e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9611 loss: tensor(8.6980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9612 loss: tensor(8.9081e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9613 loss: tensor(9.1896e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9614 loss: tensor(9.5316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9615 loss: tensor(9.8791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9616 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9617 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9618 loss: tensor(9.7203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9619 loss: tensor(9.1033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9620 loss: tensor(8.5236e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9621 loss: tensor(8.2519e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9622 loss: tensor(8.3514e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9623 loss: tensor(8.6605e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9624 loss: tensor(8.9254e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9625 loss: tensor(8.9573e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9626 loss: tensor(8.7425e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9627 loss: tensor(8.4413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9628 loss: tensor(8.2570e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9629 loss: tensor(8.2786e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9630 loss: tensor(8.4342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9631 loss: tensor(8.5713e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9632 loss: tensor(8.5788e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9633 loss: tensor(8.4601e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9634 loss: tensor(8.3123e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9635 loss: tensor(8.2394e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9636 loss: tensor(8.2707e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9637 loss: tensor(8.3541e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9638 loss: tensor(8.4096e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9639 loss: tensor(8.3937e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9640 loss: tensor(8.3251e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9641 loss: tensor(8.2586e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9642 loss: tensor(8.2378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9643 loss: tensor(8.2641e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9644 loss: tensor(8.3053e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9645 loss: tensor(8.3241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9646 loss: tensor(8.3075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9647 loss: tensor(8.2711e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9648 loss: tensor(8.2415e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9649 loss: tensor(8.2362e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9650 loss: tensor(8.2517e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9651 loss: tensor(8.2708e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9652 loss: tensor(8.2775e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9653 loss: tensor(8.2674e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9654 loss: tensor(8.2492e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9655 loss: tensor(8.2358e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9656 loss: tensor(8.2341e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9657 loss: tensor(8.2420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9658 loss: tensor(8.2513e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9659 loss: tensor(8.2544e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9660 loss: tensor(8.2495e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9661 loss: tensor(8.2407e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9662 loss: tensor(8.2337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9663 loss: tensor(8.2319e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9664 loss: tensor(8.2350e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9665 loss: tensor(8.2392e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9666 loss: tensor(8.2414e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9667 loss: tensor(8.2399e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9668 loss: tensor(8.2360e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9669 loss: tensor(8.2320e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9670 loss: tensor(8.2300e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9671 loss: tensor(8.2305e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9672 loss: tensor(8.2323e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9673 loss: tensor(8.2339e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9674 loss: tensor(8.2342e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9675 loss: tensor(8.2328e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9676 loss: tensor(8.2307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9677 loss: tensor(8.2288e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9678 loss: tensor(8.2281e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9679 loss: tensor(8.2284e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9680 loss: tensor(8.2293e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9681 loss: tensor(8.2298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9682 loss: tensor(8.2298e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9683 loss: tensor(8.2292e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9684 loss: tensor(8.2283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9685 loss: tensor(8.2275e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9686 loss: tensor(8.2270e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9687 loss: tensor(8.2271e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9688 loss: tensor(8.2276e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9689 loss: tensor(8.2283e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9690 loss: tensor(8.2289e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9691 loss: tensor(8.2295e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9692 loss: tensor(8.2303e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9693 loss: tensor(8.2315e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9694 loss: tensor(8.2337e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9695 loss: tensor(8.2371e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9696 loss: tensor(8.2421e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9697 loss: tensor(8.2496e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9698 loss: tensor(8.2608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9699 loss: tensor(8.2774e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9700 loss: tensor(8.3015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9701 loss: tensor(8.3373e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9702 loss: tensor(8.3898e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9703 loss: tensor(8.4672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9704 loss: tensor(8.5796e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9705 loss: tensor(8.7378e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9706 loss: tensor(8.9525e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9707 loss: tensor(9.2248e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9708 loss: tensor(9.5322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9709 loss: tensor(9.8136e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9710 loss: tensor(9.9640e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9711 loss: tensor(9.8676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9712 loss: tensor(9.4868e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9713 loss: tensor(8.9382e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9714 loss: tensor(8.4545e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9715 loss: tensor(8.2346e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9716 loss: tensor(8.3136e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9717 loss: tensor(8.5650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9718 loss: tensor(8.7956e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9719 loss: tensor(8.8551e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9720 loss: tensor(8.7132e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9721 loss: tensor(8.4701e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9722 loss: tensor(8.2777e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9723 loss: tensor(8.2333e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9724 loss: tensor(8.3225e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9725 loss: tensor(8.4500e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9726 loss: tensor(8.5139e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9727 loss: tensor(8.4727e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9728 loss: tensor(8.3608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9729 loss: tensor(8.2556e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9730 loss: tensor(8.2170e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9731 loss: tensor(8.2511e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9732 loss: tensor(8.3158e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9733 loss: tensor(8.3574e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9734 loss: tensor(8.3482e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9735 loss: tensor(8.2984e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9736 loss: tensor(8.2435e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9737 loss: tensor(8.2159e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9738 loss: tensor(8.2242e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9739 loss: tensor(8.2532e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9740 loss: tensor(8.2771e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9741 loss: tensor(8.2794e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9742 loss: tensor(8.2603e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9743 loss: tensor(8.2338e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9744 loss: tensor(8.2157e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9745 loss: tensor(8.2143e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9746 loss: tensor(8.2257e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9747 loss: tensor(8.2389e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9748 loss: tensor(8.2446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9749 loss: tensor(8.2393e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9750 loss: tensor(8.2271e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9751 loss: tensor(8.2155e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9752 loss: tensor(8.2099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9753 loss: tensor(8.2119e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9754 loss: tensor(8.2178e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9755 loss: tensor(8.2230e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9756 loss: tensor(8.2241e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9757 loss: tensor(8.2206e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9758 loss: tensor(8.2150e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9759 loss: tensor(8.2101e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9760 loss: tensor(8.2082e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9761 loss: tensor(8.2090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9762 loss: tensor(8.2116e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9763 loss: tensor(8.2136e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9764 loss: tensor(8.2140e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9765 loss: tensor(8.2125e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9766 loss: tensor(8.2099e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9767 loss: tensor(8.2075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9768 loss: tensor(8.2060e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9769 loss: tensor(8.2059e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9770 loss: tensor(8.2067e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9771 loss: tensor(8.2075e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9772 loss: tensor(8.2079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9773 loss: tensor(8.2076e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9774 loss: tensor(8.2067e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9775 loss: tensor(8.2055e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9776 loss: tensor(8.2043e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9777 loss: tensor(8.2037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9778 loss: tensor(8.2035e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9779 loss: tensor(8.2038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9780 loss: tensor(8.2039e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9781 loss: tensor(8.2040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9782 loss: tensor(8.2038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9783 loss: tensor(8.2033e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9784 loss: tensor(8.2027e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9785 loss: tensor(8.2021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9786 loss: tensor(8.2019e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9787 loss: tensor(8.2017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9788 loss: tensor(8.2017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9789 loss: tensor(8.2018e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9790 loss: tensor(8.2021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9791 loss: tensor(8.2021e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9792 loss: tensor(8.2023e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9793 loss: tensor(8.2025e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9794 loss: tensor(8.2029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9795 loss: tensor(8.2037e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9796 loss: tensor(8.2048e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9797 loss: tensor(8.2067e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9798 loss: tensor(8.2098e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9799 loss: tensor(8.2141e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9800 loss: tensor(8.2208e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9801 loss: tensor(8.2305e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9802 loss: tensor(8.2446e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9803 loss: tensor(8.2653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9804 loss: tensor(8.2960e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9805 loss: tensor(8.3413e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9806 loss: tensor(8.4081e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9807 loss: tensor(8.5053e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9808 loss: tensor(8.6437e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9809 loss: tensor(8.8334e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9810 loss: tensor(9.0789e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9811 loss: tensor(9.3667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9812 loss: tensor(9.6503e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9813 loss: tensor(9.8385e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9814 loss: tensor(9.8203e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9815 loss: tensor(9.5322e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9816 loss: tensor(9.0426e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9817 loss: tensor(8.5504e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9818 loss: tensor(8.2666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9819 loss: tensor(8.2698e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9820 loss: tensor(8.4743e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9821 loss: tensor(8.7040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9822 loss: tensor(8.8001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9823 loss: tensor(8.7038e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9824 loss: tensor(8.4825e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9825 loss: tensor(8.2767e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9826 loss: tensor(8.1992e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9827 loss: tensor(8.2628e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9828 loss: tensor(8.3898e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9829 loss: tensor(8.4778e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9830 loss: tensor(8.4678e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9831 loss: tensor(8.3747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9832 loss: tensor(8.2650e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9833 loss: tensor(8.2047e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9834 loss: tensor(8.2152e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9835 loss: tensor(8.2686e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9836 loss: tensor(8.3151e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9837 loss: tensor(8.3199e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9838 loss: tensor(8.2815e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9839 loss: tensor(8.2282e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9840 loss: tensor(8.1933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9841 loss: tensor(8.1922e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9842 loss: tensor(8.2165e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9843 loss: tensor(8.2436e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9844 loss: tensor(8.2539e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9845 loss: tensor(8.2424e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9846 loss: tensor(8.2184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9847 loss: tensor(8.1975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9848 loss: tensor(8.1907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9849 loss: tensor(8.1980e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9850 loss: tensor(8.2108e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9851 loss: tensor(8.2192e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9852 loss: tensor(8.2182e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9853 loss: tensor(8.2090e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9854 loss: tensor(8.1979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9855 loss: tensor(8.1907e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9856 loss: tensor(8.1901e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9857 loss: tensor(8.1946e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9858 loss: tensor(8.2001e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9859 loss: tensor(8.2029e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9860 loss: tensor(8.2017e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9861 loss: tensor(8.1976e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9862 loss: tensor(8.1931e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9863 loss: tensor(8.1906e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9864 loss: tensor(8.1913e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9865 loss: tensor(8.1942e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9866 loss: tensor(8.1982e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9867 loss: tensor(8.2015e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9868 loss: tensor(8.2040e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9869 loss: tensor(8.2058e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9870 loss: tensor(8.2084e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9871 loss: tensor(8.2129e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9872 loss: tensor(8.2205e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9873 loss: tensor(8.2318e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9874 loss: tensor(8.2470e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9875 loss: tensor(8.2672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9876 loss: tensor(8.2933e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9877 loss: tensor(8.3272e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9878 loss: tensor(8.3715e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9879 loss: tensor(8.4297e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9880 loss: tensor(8.5044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9881 loss: tensor(8.5978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9882 loss: tensor(8.7093e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9883 loss: tensor(8.8327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9884 loss: tensor(8.9538e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9885 loss: tensor(9.0494e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9886 loss: tensor(9.0888e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9887 loss: tensor(9.0447e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9888 loss: tensor(8.9100e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9889 loss: tensor(8.7061e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9890 loss: tensor(8.4822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9891 loss: tensor(8.2985e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9892 loss: tensor(8.1975e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9893 loss: tensor(8.1885e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9894 loss: tensor(8.2483e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9895 loss: tensor(8.3366e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9896 loss: tensor(8.4128e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9897 loss: tensor(8.4477e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9898 loss: tensor(8.4313e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9899 loss: tensor(8.3734e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9900 loss: tensor(8.2979e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9901 loss: tensor(8.2316e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9902 loss: tensor(8.1929e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9903 loss: tensor(8.1864e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9904 loss: tensor(8.2044e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9905 loss: tensor(8.2327e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9906 loss: tensor(8.2568e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9907 loss: tensor(8.2670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9908 loss: tensor(8.2608e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9909 loss: tensor(8.2420e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9910 loss: tensor(8.2184e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9911 loss: tensor(8.1978e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9912 loss: tensor(8.1853e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9913 loss: tensor(8.1822e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9914 loss: tensor(8.1860e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9915 loss: tensor(8.1928e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9916 loss: tensor(8.1987e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9917 loss: tensor(8.2012e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9918 loss: tensor(8.1994e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9919 loss: tensor(8.1944e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9920 loss: tensor(8.1879e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9921 loss: tensor(8.1814e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9922 loss: tensor(8.1769e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9923 loss: tensor(8.1747e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9924 loss: tensor(8.1749e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9925 loss: tensor(8.1762e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9926 loss: tensor(8.1779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9927 loss: tensor(8.1791e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9928 loss: tensor(8.1793e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9929 loss: tensor(8.1783e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9930 loss: tensor(8.1764e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9931 loss: tensor(8.1739e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9932 loss: tensor(8.1714e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9933 loss: tensor(8.1692e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9934 loss: tensor(8.1676e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9935 loss: tensor(8.1667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9936 loss: tensor(8.1663e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9937 loss: tensor(8.1666e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9938 loss: tensor(8.1671e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9939 loss: tensor(8.1677e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9940 loss: tensor(8.1683e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9941 loss: tensor(8.1687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9942 loss: tensor(8.1687e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9943 loss: tensor(8.1684e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9944 loss: tensor(8.1679e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9945 loss: tensor(8.1672e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9946 loss: tensor(8.1664e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9947 loss: tensor(8.1656e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9948 loss: tensor(8.1649e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9949 loss: tensor(8.1643e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9950 loss: tensor(8.1637e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9951 loss: tensor(8.1632e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9952 loss: tensor(8.1629e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9953 loss: tensor(8.1626e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9954 loss: tensor(8.1624e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9955 loss: tensor(8.1622e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9956 loss: tensor(8.1620e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9957 loss: tensor(8.1619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9958 loss: tensor(8.1618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9959 loss: tensor(8.1618e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9960 loss: tensor(8.1619e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9961 loss: tensor(8.1621e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9962 loss: tensor(8.1623e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9963 loss: tensor(8.1627e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9964 loss: tensor(8.1634e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9965 loss: tensor(8.1642e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9966 loss: tensor(8.1653e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9967 loss: tensor(8.1670e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9968 loss: tensor(8.1695e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9969 loss: tensor(8.1730e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9970 loss: tensor(8.1779e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9971 loss: tensor(8.1847e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9972 loss: tensor(8.1945e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9973 loss: tensor(8.2079e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9974 loss: tensor(8.2269e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9975 loss: tensor(8.2537e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9976 loss: tensor(8.2918e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9977 loss: tensor(8.3456e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9978 loss: tensor(8.4211e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9979 loss: tensor(8.5255e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9980 loss: tensor(8.6667e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9981 loss: tensor(8.8512e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9982 loss: tensor(9.0799e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9983 loss: tensor(9.3412e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9984 loss: tensor(9.6010e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9985 loss: tensor(9.8011e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9986 loss: tensor(9.8731e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9987 loss: tensor(9.7722e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9988 loss: tensor(9.5201e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9989 loss: tensor(9.2074e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9990 loss: tensor(8.9458e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9991 loss: tensor(8.8004e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9992 loss: tensor(8.7635e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9993 loss: tensor(8.7745e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9994 loss: tensor(8.7609e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9995 loss: tensor(8.6781e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9996 loss: tensor(8.5307e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9997 loss: tensor(8.3738e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9998 loss: tensor(8.2767e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch: 9999 loss: tensor(8.2780e-05, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = train(10000, net, features_temp, labels_temp, criterion, optimizer, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "44cd992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.  0.  2.]\n",
      " [ 1.  2.  1.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [14.  2. 14.  2.]\n",
      " [15.  2. 15.  2.]\n",
      " [16.  2. 16.  2.]\n",
      " [17.  2. 17.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 0.  2.  0.  2.]\n",
      " [ 1.  2.  1.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 7.  2.  7.  2.]\n",
      " [ 0.  2.  0.  2.]\n",
      " [ 1.  2.  1.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]\n",
      " [13.  2. 13.  2.]\n",
      " [ 3.  2.  3.  2.]\n",
      " [ 5.  2.  5.  2.]\n",
      " [ 8.  2.  8.  2.]\n",
      " [ 9.  2.  9.  2.]\n",
      " [10.  2. 10.  2.]\n",
      " [11.  2. 11.  2.]\n",
      " [12.  2. 12.  2.]]\n",
      "Epoch = 0 test_acc = 1.000  test_rmse = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39771/3030192740.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_target_torch = torch.tensor(torch.from_numpy(np.array(labels_temp)).float())\n",
      "/tmp/ipykernel_39771/3030192740.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_target_torch = torch.tensor(torch.from_numpy(np.array(test_target)).float())\n"
     ]
    }
   ],
   "source": [
    "#net = net.to(device)\n",
    "N_epochs = 10000\n",
    "\n",
    "labels_temp = np.array(labels_temp)\n",
    "#train_data_torch = torch.from_numpy(features_temp).float()\n",
    "#train_target_torch = torch.from_numpy(labels_temp).float()\n",
    "train_target_torch = torch.tensor(torch.from_numpy(np.array(labels_temp)).float())\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def validate(net, test_data, test_target, i):\n",
    "    \n",
    "    test_data_torch = torch.from_numpy(features_test).float()\n",
    "    #test_target_torch = torch.from_numpy(labels_test).float()\n",
    "    test_target_torch = torch.tensor(torch.from_numpy(np.array(test_target)).float())\n",
    "\n",
    "    test_pred = np.rint(net(test_data_torch).detach().numpy())\n",
    "    if i % 500 == 0:\n",
    "        print(np.concatenate((test_pred, test_target_torch.detach().numpy()), axis=1))\n",
    "    #test_accuracy = (test_target_torch.detach().numpy() == test_pred).float().mean().detach().numpy()\n",
    "    test_accuracy = (test_target_torch.detach().numpy() == test_pred).mean()\n",
    "\n",
    "    #test_rmse = ((test_pred-test_target_torch)**2).mean().sqrt().detach().numpy()\n",
    "    test_rmse = (np.sqrt((test_pred-test_target_torch.detach().numpy())**2).mean())\n",
    "\n",
    "    return test_accuracy, test_rmse\n",
    "\n",
    "for i in range(1):\n",
    "    #pred = net(train_data_torch)\n",
    "    #loss = criterion(pred, train_target_torch)\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        #train_accuracy, train_rmse = validate(net, features_temp, labels_temp)\n",
    "        test_accuracy, test_rmse = validate(net, features_test, labels_test, i)\n",
    "        #print(f'Epoch = {i} loss={loss} train_acc = {train_accuracy:.3f} test_acc = {test_accuracy:.3f} train_rmse = {train_rmse:.3f}  test_rmse = {test_rmse:.3f}')         \n",
    "        print(f'Epoch = {i} test_acc = {test_accuracy:.3f}  test_rmse = {test_rmse:.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "af476f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 2.]\n"
     ]
    }
   ],
   "source": [
    "preds = net(torch.from_numpy(features_test[3]).float()).detach().numpy()\n",
    "print(np.rint(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5fdda9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9992, grad_fn=<UnbindBackward0>)\n",
      "tensor(2.0004, grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for p in preds:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0aed387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3626e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
